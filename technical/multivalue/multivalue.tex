% Natural Language Toolkit Technical Report:
% Multiple Return Values
%
% Copyright (C) 2001 University of Pennsylvania
% Author: Edward Loper <edloper@gradient.cis.upenn.edu>
% URL: <http://nltk.sf.net>
% For license information, see LICENSE.TXT
%
% $Id$

\documentclass[11pt]{article}
\usepackage{fullpage}

\begin{document}
\title{Alternative Outputs\\
\Large Natural Language Processing Toolkit: Technical Report}
\author{Edward Loper}
\maketitle

% From the info file:
% Many processing modules can find more than one "possible" or
% "reasonable" result.  This report disucsses a set of conventions for
% these situations.

% Things to talk about:
%   - what are AO's used for?
%      - 1-input/1-output, multi-in/multi-out, etc.
%      - threading
%        - with probabilities (independence?)
%        - with 
%   - ProbablisticMixIn
%   - interfaces: parse, parse_n, parse_dist
%   - procedure names

%============= INTRODUCTION =============%
\section{Introduction}

  Many NLP algorithms can generate multiple ``possible'' outputs for a
  given input.  For example, a parser might produce several different
  syntax trees for a single sentence.  Since this pattern is so
  common, we have decided to adopt standards interfaces for encoding
  it in NLTK processing classes.  This techincal report explains and
  justifies these interfaces.

  Note that this document is concerned with algorithms that generate a
  variable number of \emph{mutually exclusive} possibilities for a
  single output value.  In particular, it is not meant to address
  tasks that generate multiple output values.  For example, this
  document does \emph{not} address what methods should be used to
  return the list of (overlapping) classes generated by a
  multiple-category text classifier.

  We will use the term \emph{alternative outputs} to refer to any set
  of mutually exclusive possibilities for a single output value.  A
  processing class that generates alternative outputs is an
  \emph{alternative output class}, or \emph{AO class} for short.

%============= ALTERNATIVE OUTPUTS =============%
\section{Alternative Output Types}

  Many AO classes can estimate information about the likelihood of
  their output alternatives.  We define three types of AO class, based
  on what kind of likelihood information they can estimate about each
  alternative:

  \begin{description}
    \item An \emph{AO-unordered class} has no information about the
    likelihood of each alternative.

    \item An \emph{AO-ordered class} can estimate the relative
    ordering of the alternative's likelihoods; however, it does not
    have direct information about the likelihood of any given
    alternative.

    \item An \emph{AO-distribution class} can estimate the probability
    of each alternative.
  \end{description}

  Other types of AO class might occasionally prove useful.  For
  example, we could define a type of AO class that generates a partial
  ordering of alternatives; or a type of AO class that generates
  likelihood estimates that are not probabilities.  However, in the
  interest of keeping our interfaces simple, we choose to restrict
  ourselves to these three types.  We believe that these types will be
  sufficient for NLTK.

%============= USE CASES =============%
\section{Use Cases}

  Before deciding what interfaces AO classes should implement, it is
  important to consider how they will be used.  This section describes
  and categorizes the different ways that we expect AO classes to be
  used.  First, we will examine the different ways that a single AO
  class might be used; then, we will examine typical ways of combining
  multiple AO classes.

  \subsection{AO Class Use Cases}

    

In section (?), we defined three different types of AO class

    An AO class can map a single input to a set of alternative
    outputs.  Depending on how we intend to use the task, we might
    want different kinds of information about this set.

    The kinds of information the task can recieve depend on what
    information we have about the outputs' relative likelihood.  The
    following sections list the types of information we might want,
    given different amounts of information about output likelihoods.

    \subsubsection{Alternative Sets}

      If the 

      \begin{description}
        \item[any] We wish to have a single alternative.
        \item[all] We want all alternatives
        \item[any $n$] We wish to have at most $n$ alternatives.
      \end{description}

    \subsubsection{Alternative Lists}

      \begin{description}
        \item[best]
        \item[sorted]
        \item[best $n$]
      \end{description}

      (worst, worst $n$)

    \subsubsection{Alternative Distributions}
% 1. we want the best answer
% 2. we want the best n answers
% 3. we want the probability of a given answer
% 4. 


      There are four foo:

      \begin{description}
        \item[best prob]
        \item[sorted+prob]
        \item[best $n$+prob]
      \end{description}


    \subsubsection{Complex Outputs}

      We might want P's on each element of a list of outputs..  But
      too bad! :)

    what info we want: best, best n, best n w/ probs, pdist    

  \subsection{Multiple-Task}

%============= PROBABILITY =============%
\section{Modelling Probability}
  \section{Probability Distributions}

    one way to represent probs is pdists.

  \section{ProbablisticMixIn}

    another way is probablistic mixins.

%============= METHODS =============%
\section{Alternative Output Methods}
% - parse_n
% - parse_dist

  \subsection{Method Names}

  We considered a number of different names\ldots

\end{document}