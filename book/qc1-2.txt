p222 ok to make into a paragraph

p223 "'names' corpus" -> "Names Corpus"

p225 13up "Movie Reviews corpus" -> "Movie Reviews Corpus"

p231 This is meant to be introducing the terms.  The remainder of 
    the paragraph is describing how these three models work in
    general terms.  I recommend the following rewording to make this
    clear:

       Another solution is to assign scores to all of the possible
       sequences of part-of-speech tags, and to choose the sequence
       whose overall score is highest. This is the approach taken by
       <emphasis role="strong">Hidden Markov Models</emphasis>.
       Hidden Markov Models are similar to consecutive classifiers in
       that they look at both the inputs and the history of predicted
       tags. However, rather than simply finding the single best tag
       for a given word, they generate a probability distribution over
       tags. These probabilities are then combined to calculate
       probability scores for tag sequences, and the tag sequence with
       the highest probability is chosen. Unfortunately, the number of
       possible tag sequences is quite large. Given a tag set with 30
       tags, there are about 600 trillion
       (30<superscript>10</superscript>) ways to label a 10-word
       sentence.  In order to avoid considering all these possible
       sequences separately, Hidden Markov Models require that the
       feature extractor only look at the most recent tag (or the most
       recent <emphasis>n</emphasis> tags, where
       <emphasis>n</emphasis> is fairly small). Given that
       restriction, it is possible to use dynamic programming (Section
       4.7) to efficiently find the most likely tag sequence. In
       particular, for each consecutive word index
       <emphasis>i</emphasis>, a score is computed for each possible
       current and previous tag.  This same basic approach is taken by
       two more advanced models, called <emphasis
       role="strong">Maximum Entropy Markov Models</emphasis> and
       <emphasis role="strong">Linear-Chain Conditional Random Field
       Models</emphasis>; but different algorithms are used to find
       scores for tag sequences.

p232 8up "nps_chat corpus" -> "NPS Chat Corpus"

p233 "data set" -> "dataset" (at least 7 times in chapter 6)

p234 Change the paragraph "We let words..." to start:

       In our RTE feature detector (Example 6.7), we let words...

p241 Append the following sentence to the paragraph preceeding example
      6-9 (i.e., the paragraph starting "For example, Figure 6-5 shows.."):

      Example 6-9 demonstrates how to calculate the entropy
      of a list of labels.

p245 Change the sentence "This process is illustrated in
      Figure 6-7" to say "This process is illustrated in Figures
      6-7 and 6-8."

p246 ELE and Heldout Estimation should be boldface, and not quoted.
     Add following to end of paragraph (where `` marks cw):
     The ``nltk.probability`` module provides support for a wide variety of smoothing techniques.

p254 Add "the Recognizing Textual Entailment competitions" to this list

p255 5d "names corpus" -> "Names Corpus"

p255 11d "senseval corpus" -> "Senseval 2 Corpus"
     20d "Senseval corpus" -> "Senseval 2 Corpus"

p255 Set in roman, and capitalize "Q": ynQuestion

p256 q9 "Prepositional Phrase Attachment corpus" -> "PP Attachment Corpus"
     "PP attachment corpus" -> "PP Attachment Corpus"

p260 6up "CoNLL-2000 chunking corpus" -> "CoNLL-2000 Chunking Corpus"

p267 18up, 2up "CoNLL 2000 corpus" -> "CoNLL-2000 Chunking Corpus"

p269 14up "CoNLL 2000 corpus" -> "CoNLL-2000 Chunking Corpus"

p275 root node of syntax tree in example (4) s/b boldface

p278 the requested URLs are added to p282

p280 3up "conll2002 Dutch corpus" -> "Dutch section of the CoNLL 2002 Named Entity Corpus"

p282 new paragraph at end of 7.8:
     "For more information on the Getty and Alexandria gazetteers, see
     http://en.wikipedia.org/wiki/Getty_Thesaurus_of_Geographic_Names and
     http://www.alexandria.ucsb.edu/gazetteer/ "

p282 4up "CoNLL corpus" -> "CoNLL-2000 Chunking Corpus"
     "Inspect the CoNLL corpus" -> "Inspect the data"

p283 ex 8 "CoNLL corpus" -> "CoNLL Chunking Corpus"

p284 1d "CoNLL corpus" -> "CoNLL Chunking Corpus"
     
     ex 16 "Penn Treebank" -> "Penn Treebank Corpus sample"
           "Treebank corpus" -> "corpus"

p285 hope we can avoid the widowed lines

p290 non-terminals in the tree diagrams s/b boldface

p293 non-terminals s/b boldface

p302 non-terminals s/b boldface

p302 [?] Delete example (11) and the sentence immediately before it
p303 [?] Delete from top down to and including example (13).
     (I don't think this material elucidates the method;
     it also uses the =>* notation which is not defined afaik) 

p311 1up "Penn Treebank corpus" -> "Penn Treebank Corpus"

p312 14up "Prepositional Phrase Attachment Corpus" -> "PP Attachment Corpus"

p313 9d "Sinica Treebank Corpus" s/b roman

p316 change year of Bresnan and Hay citation from 2006 to 2008

p318 delete this unfinished bullet point 

p320 ex 16 "Prepositional Phrase Attachment Corpus" -> "PP Attachment Corpus" 

p321 ex 22 "Prepositional Phrase Attachment Corpus" -> "PP Attachment Corpus"
     ex 28 "Treebank corpus sample" -> "Penn Treebank Corpus sample"
     
p328 non-terminals s/b boldface

p329 non-terminals s/b boldface

p332 Fig 9-1 s/b smaller scale

pp334ff directed graphs should be smaller

p351 truncate lines at right margin (no wrapping)

p365 ex (9) alignment and size

p381 ex (29) garbled content
     - bottom right s/b "IV[SEM=<\X.bark>]"
     - remove middle node labeled ">]"
     - non-terminals s/b boldface

p393 Fig 10-5 add a frame around screenshot?

p403 11up "TIMIT corpus of read speech" -> "TIMIT Corpus"

p404 12d "TIMIT corpus" -> "TIMIT Corpus"

p404 delete "an", to leave "has internal structure"

p405 ok not to have comma after the word "variables"

p405 1d "TIMIT corpus" -> "TIMIT Corpus"
     1u "TIMIT corpus" -> "TIMIT Corpus"

p406 11d "TIMIT corpus" -> "TIMIT Corpus"

p409 ok not to have comma after the word "window"

p411 agree that GNU WGet should not be italicized

p411 "We can enter this in MSWord," -> "We can key in such text using MSWord"

p412 "... parts-of-speech as the set difference between used_pos and legal_pos."

p413 ok to delete note about Beautiful Soup package

p417 problem with coordinate structure -- split into two sentences as follows:
     - delete comma after "(SQL)"
     - change comma after "file storage" to period
     - change "and allows" to "It also allows" at start of next sentence

p421 change quoted words "verb" and "noun" to cw, and remove quotes

p429 "conventions for resource discovery on the Web."
     -> "conventions for finding, sharing, and managing information." 

p433 1d, 2d delete braces around BNC and TLG

p433 add URL http://www.python.org/doc/lib/markup.html

p435 adopt proposed replacement text

p440 Add: "Contributions in the following areas are particularly encouraged:"

p443ff Bracketted author year information in bibliography entries is
     redundant and looks rather ugly -- can we omit this?
     First author's name should be formatted as "Lastname, Firstname"
     
p444 "Ca" -> "CA" (California)

p444 Replace Bresnan and Hay citation with published version: (italicize "give")

     Joan Bresnan and Jennifer Hay.
       Gradient grammar: An effect of animacy on the syntax of *****give*****
       in New Zealand and American English. Lingua 118: 245Ð59, 2008  
