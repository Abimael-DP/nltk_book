.. -*- mode: rst -*-
.. include:: ../definitions.rst

.. standard global imports

    >>> from __future__ import division
    >>> import nltk, re, pprint

.. TODO: More Abney references

.. _chap-chunk:

===================================
7. Extracting Information from Text
===================================

Two fundamental tasks in language processing are segmentation and labeling.
Recall that tokenization `segments`:em: a sequence of characters into tokens,
while tagging `labels`:em: each token.  However, segmentation and labeling
are generic operations and can be used for a variety of more sophisticated
language processing tasks.  The goal of this chapter is to answer the
following questions:

1. How can we use segmentation and labeling to probe the structure and meaning of text?

2. What are some robust methods for identifying the entities and relationships described in a text?

3. Which corpora are appropriate for this work, and how do we use them for training and evaluating our models?

Along the way, we'll see how we can do segmentation and labeling at the level of phrases.



.. _sec-information-extraction:

----------------------
Information Extraction
----------------------

Information comes in many shapes and sizes. One important form is
`structured data`:dt:, where there is a regular and predictable
organization of facts. For example, we might be interested in the
relation between companies and locations. Given a particular company,
we would like to be able to identify the locations in which it does
business; conversely, given a location, we would like to discover
which companies do business in that location. If our data is in tabular
form, such as the little example in tab-db-locations_, then
answering these queries is straightforward.

.. table:: tab-db-locations
   
   ==================== ====================
   OrgName              LocationName        
   ==================== ====================
   Omnicom              New York            
   DDB Needham          New York            
   Kaplan Thaler Group  New York            
   BBDO South           Atlanta             
   Georgia-Pacific      Atlanta             
   ==================== ====================

   Locations data

Assuming the data in  ``Locations`` is a table within a relational database,  the
question ex-ie1_ can be translated into the SQL query ex-ie2_.

.. _ex-ie1:
.. ex::
   Which organizations operate in Atlanta?

.. _ex-ie2:
.. ex:: 
   ``"select OrgName from locations where LocationName = 'Atlanta'"``

When executed, ex-ie2_ will return the required values:

.. table:: tab-db-answers

   +--------------------+
   | OrgName            |
   +====================+
   |BBDO South          |
   +--------------------+
   |Georgia-Pacific     |
   +--------------------+

   Companies that operate in Atlanta

Things are more tricky if we try to get similar information out of
text. For example, consider the
following snippet (extracted from the IEER corpus, document 'NYT19980315.0085').

.. _ex-ie4:
.. ex::
    The fourth Wells account moving to another agency is the packaged
    paper-products division of Georgia-Pacific Corp., which arrived at
    Wells only last fall. Like Hertz and the History Channel, it is
    also leaving for an Omnicom-owned agency, the BBDO South unit of
    BBDO Worldwide.  BBDO South in Atlanta, which handles corporate
    advertising for Georgia-Pacific, will assume additional duties for
    brands like Angel Soft toilet tissue and Sparkle paper towels,
    said Ken Haldin, a spokesman for Georgia-Pacific in Atlanta.

If you read through ex-ie4_, you will glean the information required
to answer ex-ie1_. But how do we get a machine to understand enough
about ex-ie4_ to return the answers in tab-db-answers_?  This is
obviously a much harder task. Unlike tab-db-locations_, ex-ie4_
contains no structure that links organization names with
location names. As we will see in chap-semantics_, one
approach to this problem involves building a very general
representation of meaning.  Here we take a different approach, and
decide in advance that we are only going to look for very specific kinds of
information in text, such as the relation between an organization and
the locations it operates in. In other words, rather than trying to
use text like ex-ie4_ to answer ex-ie1_ directly, we first convert the `unstructured
data`:dt: of natural language sentences into the structured data of
tab-db-locations_. Then we reap the benefits of powerful query
tools such as SQL. This method of getting meaning from text is
called `Information Extraction`:dt:.

Information Extraction has many applications, including
business intelligence, resume harvesting, media analysis, sentiment detection,
patent search, and email scanning. A
particularly important area of current research involves the attempt
to extract structured data out of electronically-available scientific
literature, especially in the domain of biology and medicine.


Information Extraction Architecture
-----------------------------------

fig-ie-architecture_ shows the architecture for a simple information
extraction system.  It begins by processing a document using several
of the procedures we discussed in chap-words_ and chap-tag_: first,
the raw text of the document is split into sentences, using a sentence
segmenter; and each sentence is further subdivided into words using a
tokenizer.  Next, each sentence is tagged with part-of-speech tags,
which will prove very helpful in the next step, `entity
detection`:dt:.  In this step, we search for mentions of potentially
interesting entities in each sentence.  Finally, we use `relation
detection`:dt: to search for likely relations between different
entities in the text.

.. XXX check scale on this figure:

.. _fig-ie-architecture:
.. figure:: ../images/ie-architecture.png
   :scale: 25:32:30

   Simple Pipeline Architecture for an Information Extraction System.
   This system takes the raw text of a document as its input, and 
   generates a list of ``(entity, relation, entity)`` tuples as its
   output.  For example, given a document that indicates that the
   company Georgia-Pacific is located in Atlanta, it might generate
   the tuple ``([ORG: 'Georgia-Pacific'] 'in' [LOC: 'Atlanta'])``.

To perform the first three tasks, we can define a simple function that
simply connects together NLTK's default sentence segmenter
ie-segment_, word tokenizer ie-tokenize_, and part-of-speech tagger
ie-postag_:

    >>> def ie_preprocess(document):
    ...    # Segment the document into sentences.
    ...    sentences = nltk.sent_tokenize(document) # [_ie-segment]
    ... 
    ...    # Tokenize each sentence.
    ...    sentences = [nltk.word_tokenize(sent) for sent in sentences] # [_ie-tokenize]
    ... 
    ...    # Part-of-speech tag each sentence
    ...    sentences = [nltk.pos_tag(sent) for sent in sentences] # [_ie-postag]

.. _sec-chunking:

----------------
Entity Detection
----------------

In `entity detection`:dt:, we search for and label mentions of
entities that might participate in interesting relations with one
another.  Typically, these will be definite noun phrases such as  `the
Knights Who Say Ni`:lx:, or proper names such as `Monty
Python`:lx:. 

.. XXX say something about the standard sorts of MUC entities

In some tasks it is useful to also consider nouns or noun
chunks without determiners, and these do not necessarily refer to
entities in the same way as definite ``NP``\ s and proper names.

.. XXX We can either restrict attention to `proper nouns`:dt:, which
.. are typically easier to identify; or we can also consider pronouns
.. and common nouns, in which case we may need to do some work to
.. determine what they actually refer to.

The basic technique we will use for entity detection is
`chunking`:dt:, which finds and labels multi-token sequences, as
illustrated in fig-chunk-segmentation_.  The smaller boxes show the
word-level tokenization and part-of-speech tagging, while the large
boxes show higher-level chunking.  Each of these larger boxes is
called a `chunk`:dt:.

.. _fig-chunk-segmentation:
.. figure:: ../images/chunk-segmentation.png
   :scale: 25:30:30

   Segmentation and Labeling at both the Token and Chunk Levels

Like tokenization, chunking can skip over material in the input.
Tokenization omits white space (and sometimes punctuation characters).
Chunking uses only a subset of the tokens and leaves others out.  Also
like tokenization, the sequences generated by a chunker may not
overlap.

In the following sections we will explore chunking in some depth, beginning
with the definition and representation of chunks.  We will see regular
expression and n-gram approaches to chunking, and will develop and
evaluate chunkers using the CoNLL-2000 chunking corpus.

Chunkers
--------

We will begin by considering the task of `noun phrase chunking`:dt:,
or `NP-chunking`:dt:, where we search for chunks corresponding to
individual noun phrases.  For example, here is some Wall Street
Journal text with ``NP``\ -chunks marked using brackets:

.. _ex-wsj-nx:
.. ex::
  [ The/DT market/NN ] for/IN [ system-management/NN software/NN ]
  for/IN [ Digital/NNP ] [ 's/POS hardware/NN ] is/VBZ fragmented/JJ
  enough/RB that/IN [ a/DT giant/NN ] such/JJ as/IN [ Computer/NNP
  Associates/NNPS ] should/MD do/VB well/RB there/RB ./.

As we can see, ``NP``\ -chunks are often smaller pieces than complete
noun phrases.  For example, `the market for system-management software
for Digital's hardware`:lx: is a single noun phrase (containing two
nested noun phrases), but it is captured in ``NP``\ -chunks by the
simpler chunk `the market`:lx:.  One of the motivations for this
difference is that ``NP``\ -chunks are defined so as not contain
other``NP``\ -chunks embedded within them.  Consequently, any
prepositional phrases or subordinate clauses that modify a nominal
will not be included in the corresponding ``NP``\ -chunk, since they
almost certainly contain further noun phrases.

One of the most useful sources of information for ``NP``\ -chunking is
part-of-speech tags.  This is one of the main motivations for
performing part-of-speech tagging in our information extraction
system.  We demonstrate this approach using an example sentence that
has been part-of-speech tagged in code-chunkex_.  In order to create an
``NP``\ -chunker, we will first define a `grammar`:dt:, consisting of rules
that indicate how sentences should be chunked.  In this case, we will
define a very simple grammar with a single regular-expression rule
chunkex-grammar_.  This rule says that an NP chunk should be formed
whenever the chunker finds an optional determiner (DT) followed by any
number of adjectives (JJ) and then a noun (NN).  Using this grammar,
we create a chunk parser chunkex-cp_, and test it on our example
sentence chunkex-test_.  The result is a tree, which we can either
print chunkex-print_, or display graphically chunkex-draw_.

.. pylisting:: code-chunkex
   :caption:
        Example of a Simple Regular Expression Based NP Chunker.

   >>> sentence = [("the", "DT"), ("little", "JJ"), ("yellow", "JJ"), # [_chunkex-sent]
     ... ("dog", "NN"), ("barked", "VBD"), ("at", "IN"),  ("the", "DT"), ("cat", "NN")]

   >>> grammar = "NP: {<DT>?<JJ>*<NN>}" # [_chunkex-grammar]

   >>> cp = nltk.RegexpParser(grammar) # [_chunkex-cp]
   >>> result = cp.parse(sentence) # [_chunkex-test]
   >>> print result # [_chunkex-print]
   (S
     (NP the/DT little/JJ yellow/JJ dog/NN)
     barked/VBD
     at/IN
     (NP the/DT cat/NN))
   >>> result.draw() # [_chunkex-draw] # doctest: +SKIP

   .. tree:: (S (NP (DT the) (JJ little) (JJ yellow) (NN dog))
              (VBD barked) (IN at) (NP (DT the) (NN cat)))

.. note:: Remember that our program samples assume you
   begin your interactive session or your program with: ``import nltk, re, pprint``

Tag Patterns
------------

A `tag pattern`:dt: is a sequence of part-of-speech tags delimited
using angle brackets, e.g. ``<DT><JJ><NN>``.  Tag patterns are
the same as the regular expression patterns we have already seen,
except for two differences that make them easier to use for chunking.
First, angle brackets group their contents into atomic
units, so "``<NN>+``" matches one or more repetitions of the tag
``NN``; and "``<NN|JJ>``" matches ``NN`` or ``JJ``.  Second, the period wildcard operator is
constrained not to cross tag delimiters, so that "``<N.*>``" matches
any single tag starting with ``N``, e.g. ``NN``, ``NNS``.

Now, consider the following noun phrases from the Wall Street
Journal::

  another/DT sharp/JJ dive/NN
  trade/NN figures/NNS
  any/DT new/JJ policy/NN measures/NNS
  earlier/JJR stages/NNS
  Panamanian/JJ dictator/NN Manuel/NNP Noriega/NNP

.. TODO: how are they to view this CoNLL data?

We can match these using a slight refinement of the first tag pattern
above: ``<DT>?<JJ.*>*<NN.*>+``.  This will chunk any sequence
of tokens beginning with an optional determiner ``DT``, followed by
zero or more adjectives of any type ``JJ.*`` (including relative
adjectives like ``earlier/JJR``), followed by one or more nouns of any
type ``NN.*``.  However, it is easy to find many more difficult examples which
this rule will not cover::

  his/PRP$ Mansion/NNP House/NNP speech/NN
  the/DT price/NN cutting/VBG
  3/CD %/NN to/TO 4/CD %/NN
  more/JJR than/IN 10/CD %/NN
  the/DT fastest/JJS developing/VBG trends/NNS
  's/POS skill/NN

.. note:: |TRY|
   Try to come up with tag patterns to cover these further cases.
   Now test them out using the graphical interface
   ``nltk.app.chunkparser()``.  Continue to refine your
   tag patterns with the help of the feedback given by
   the system.

Chunking with Regular Expressions
---------------------------------

The chunker begins with a flat structure in which no tokens are
chunked.  Patterns are applied in turn, successively updating the
chunk structure.  Once all of the patterns have been applied, the
resulting chunk structure is returned.  code-chunker1_ shows a
simple chunk grammar consisting of two patterns.  The first pattern
matches an optional determiner or possessive pronoun (recall that
``|`` indicates disjunction), zero or more adjectives, then a
noun. The second rule matches one or more proper nouns.  We also
define some tagged tokens to be chunked, and run the chunker on this input.

.. pylisting:: code-chunker1
   :caption: Simple Noun Phrase Chunker

   grammar = r"""
     NP: {<DT|PP\$>?<JJ>*<NN>}   # chunk determiner/possessive, adjectives and nouns
         {<NNP>+}                # chunk sequences of proper nouns
   """
   cp = nltk.RegexpParser(grammar)
   sentence = [("Rapunzel", "NNP"), ("let", "VBD"), ("down", "RP"),
                    ("her", "PP$"), ("long", "JJ"), ("golden", "JJ"), ("hair", "NN")]
   >>> print cp.parse(sentence)
   (S
     (NP Rapunzel/NNP)
     let/VBD
     down/RP
     (NP her/PP$ long/JJ golden/JJ hair/NN))

.. note:: The ``$`` symbol is a special character in regular
          expressions, and therefore needs to be escaped with the
          backslash ``\`` in order to match the tag ``PP$``.


If a tag pattern matches at overlapping locations, the first
match takes precedence.  For example, if we apply a rule that matches
two consecutive nouns to a text containing three consecutive nouns,
then only the first two nouns will be chunked:

    >>> nouns = [("money", "NN"), ("market", "NN"), ("fund", "NN")]
    >>> grammar = "NP: {<NN><NN>}  # Chunk two consecutive nouns"
    >>> cp = nltk.RegexpParser(grammar)
    >>> print cp.parse(nouns)
    (S (NP money/NN market/NN) fund/NN)

Once we have created the chunk for `money market`:lx:, we have
removed the context that would have permitted `fund`:lx: to be
included in a chunk.  This issue would have been avoided with
a more permissive chunk rule, e.g. ``NP: {<NN>+}``.

Exploring Text Corpora
----------------------

In sec-tagged-corpora_ we saw how we could interrogate
a tagged corpus.  We can use a chunker to do the same work with less
effort, as follows:

    >>> cp = nltk.RegexpChunker('CHUNK: {<V.*> <TO> <V.*>}')
    >>> brown = nltk.corpus.brown
    >>> for sent in brown.tagged_sents():
    ...     tree = cp.parse(sent)
    ...     for subtree in tree.subtrees():
    ...         if subtree.node == 'CHUNK': print subtree
    ...
    (CHUNK combined/VBN to/TO achieve/VB)
    (CHUNK continue/VB to/TO place/VB)
    (CHUNK serve/VB to/TO protect/VB)
    (CHUNK wanted/VBD to/TO wait/VB)
    (CHUNK allowed/VBN to/TO place/VB)
    (CHUNK expected/VBN to/TO become/VB)
    ...
    (CHUNK seems/VBZ to/TO overtake/VB)
    (CHUNK want/VB to/TO buy/VB)

.. note:: |TRY|
   Encapsulate the above example inside a function that takes a chunk
   string such as ``'CHUNK: {<V.*> <TO> <V.*>}'`` as its parameter.
   Now search for other patterns, such as four
   or more nouns in a row, e.g. ``'NOUNS: {<N.*>{4,}}``

Chinking, Splitting and Merging
-------------------------------

Sometimes it is easier to define what we *don't* want to include in a
chunk than it is to define what we *do* want to include.  In these
cases, it may be easier to build a chunker using a method called
`chinking`:dt:.  We can define a `chink`:dt: to be a sequence
of tokens that is not included in a chunk [Abney1996PST]_.
In the following example, ``barked/VBD at/IN`` is a chink::

  [ the/DT little/JJ yellow/JJ dog/NN ] barked/VBD at/IN [ the/DT cat/NN ]

Chinking is the process of removing a sequence of tokens from a
chunk.  If the sequence of tokens spans an entire chunk, then the
whole chunk is removed; if the sequence of tokens appears in the
middle of the chunk, these tokens are removed, leaving two chunks
where there was only one before.  If the sequence is at the beginning
or end of the chunk, these tokens are removed, and a smaller chunk
remains.  These three possibilities are illustrated in tab-chinking-example_.

.. table:: tab-chinking-example

   ============  ===================  ==================  ================
                 Entire chunk         Middle of a chunk   End of a chunk
   ============  ===================  ==================  ================
   *Input*       [a/DT little/JJ      [a/DT little/JJ     [a/DT little/JJ
                 dog/NN]              dog/NN]             dog/NN]

   *Operation*   Chink "DT JJ NN"     Chink "JJ"          Chink "NN"

   *Pattern*     "}DT JJ NN{"         "}JJ{"              "}NN{"

   *Output*      a/DT little/JJ       [a/DT] little/JJ    [a/DT little/JJ]
                 dog/NN               [dog/NN]            dog/NN
   ============  ===================  ==================  ================

   Three chinking rules applied to the same chunk

In the following grammar (code-chinker_), we put the entire sentence into a single
chunk, then excise the chink:

.. pylisting:: code-chinker
   :caption: Simple Chinker

   grammar = r"""
     NP:
       {<.*>+}          # Chunk everything
       }<VBD|IN>+{      # Chink sequences of VBD and IN
     """
   sentence = [("the", "DT"), ("little", "JJ"), ("yellow", "JJ"), 
          ("dog", "NN"), ("barked", "VBD"), ("at", "IN"),  ("the", "DT"), ("cat", "NN")]
   cp = nltk.RegexpParser(grammar)
   >>> print cp.parse(sentence)
   (S
     (NP the/DT little/JJ yellow/JJ dog/NN)
     barked/VBD
     at/IN
     (NP the/DT cat/NN))
   >>> from nltk.corpus import conll2000
   >>> test_sents = conll2000.chunked_sents('test.txt', chunk_types=('NP',))
   >>> print nltk.chunk.accuracy(cp, test_sents)
   0.581041433607

Two other rules for forming chunks are splitting and merging.
A permissive chunking rule might put
`the cat the dog chased`:lx: into a single ``NP`` chunk
because it does not detect that determiners introduce new chunks.
For this we would need a rule to split an ``NP`` chunk
prior to any determiner, using a pattern like: ``"NP: <.*>}{<DT>"``.
Conversely, we can craft rules to merge adjacent chunks under
particular circumstances, e.g. ``"NP: <NN>{}<NN>"``.

A chunk grammar can use any number of chunking, chinking, splitting
and merging patterns in any order.

Multiple Chunk Types
--------------------

So far we have only developed ``NP`` chunkers.  However, it can also
be useful to find other chunk types, including ``PP`` chunks, ``VP``
chunks, and proper noun chunks.  Here is an example of a chunked
sentence that contains ``NP``, ``VP``, and ``PP`` chunk types.

    >>> from nltk.corpus import conll2000
    >>> print conll2000.chunked_sents('train.txt')[99]
    (S
      (PP Over/IN)
      (NP a/DT cup/NN)
      (PP of/IN)
      (NP coffee/NN)
      ,/,
      (NP Mr./NNP Stone/NNP)
      (VP told/VBD)
      (NP his/PRP$ story/NN)
      ./.)

Now we can set up a multi-stage chunk grammar, as shown in
code-multistage-chunker_.  It has a stage for each of the chunk types.

.. pylisting:: code-multistage-chunker
   :caption: A Multistage Chunker

   cp = nltk.RegexpParser(r"""
     NP: {<DT>?<JJ>*<NN.*>+}    # noun phrase chunks
     VP: {<TO>?<VB.*>}          # verb phrase chunks
     PP: {<IN>}                 # prepositional phrase chunks
     """)
   >>> from nltk.corpus import conll2000
   >>> example = conll2000.chunked_sents('train.txt')[99]
   >>> print cp.parse(example.flatten(), trace=1)
   # Input:
    <IN>  <DT>  <NN>  <IN>  <NN>  <,>  <NNP>  <NNP>  <VBD>  <PRP$>  <NN>  <.> 
   # noun phrase chunks:
    <IN> {<DT>  <NN>} <IN> {<NN>} <,> {<NNP>  <NNP>} <VBD>  <PRP$> {<NN>} <.> 
   # Input:
    <IN>  <NP>  <IN>  <NP>  <,>  <NP>  <VBD>  <PRP$>  <NP>  <.> 
   # verb phrase chunks:
    <IN>  <NP>  <IN>  <NP>  <,>  <NP> {<VBD>} <PRP$>  <NP>  <.> 
   # Input:
    <IN>  <NP>  <IN>  <NP>  <,>  <NP>  <VP>  <PRP$>  <NP>  <.> 
   # prepositional phrase chunks:
   {<IN>} <NP> {<IN>} <NP>  <,>  <NP>  <VP>  <PRP$>  <NP>  <.> 
   (S
     (PP Over/IN)
     (NP a/DT cup/NN)
     (PP of/IN)
     (NP coffee/NN)
     ,/,
     (NP Mr./NNP Stone/NNP)
     (VP told/VBD)
     his/PRP$
     (NP story/NN)
     ./.)

Chunking vs Parsing
-------------------

Chunking is akin to parsing, which will be discussed in chap-parse_,
in the sense that it can be used to build hierarchical structure over
text.  There are several important differences, however.  First, as
noted above, chunking is not exhaustive, and typically ignores some
items in the surface string. In fact, chunking is sometimes called
`partial parsing`:dt:. Second, where parsing constructs nested
structures that are arbitrarily deep, chunking creates structures of
fixed depth (typically depth 2).  These chunks often correspond to the
lowest level of grouping identified in the full parse tree. This is
illustrated in ex-parsing-chunking_ below, which shows an ``NP`` chunk
structure and a completely parsed counterpart:

.. _ex-parsing-chunking:
.. ex::
  .. ex::
     .. tree:: (S (NP (CD one) (JJ congressional) (NN aide)) (WP who) (VBD attended)
                     (NP (DT the) (JJ two-hour) (NN meeting)) (VBD said) \.\.\. )

  .. ex::
     .. tree:: (S (NP (CD one) (NBAR (NBAR (JJ congressional) (NN aide)) (SBAR (WP who) (VP (VBD attended)
                     (NP (DT the) (JJ two-hour) (NN meeting)))))) (VP (VBD said) \.\.\.) )

A significant motivation for chunking is its robustness and efficiency
relative to parsing.  As we will see in chap-parse_, parsing has 
problems with robustness,
given the difficulty in gaining broad coverage while minimizing
ambiguity.  Parsing is also relatively inefficient: the time taken to
parse a sentence grows with the cube of the length of the sentence,
while the time taken to chunk a sentence only grows linearly.

Representing Chunks: Tags vs Trees
----------------------------------

As befits their intermediate status between tagging and parsing, chunk
structures can be represented using either tags or trees.  The most
widespread file representation uses so-called `IOB tags`:dt:.  In this
scheme, each token is tagged with one of three special chunk tags,
``I`` (inside), ``O`` (outside), or ``B`` (begin).  A token is tagged
as ``B`` if it marks the beginning of a chunk.  Subsequent tokens
within the chunk are tagged ``I``.  All other tokens are tagged ``O``.
The ``B`` and ``I`` tags are suffixed with the chunk type,
e.g. ``B-NP``, ``I-NP``.  Of course, it is not necessary to specify a
chunk type for tokens that appear outside a chunk, so these are just
labeled ``O``. An example of this scheme is shown in fig-chunk-tagrep_.

.. _fig-chunk-tagrep:
.. figure:: ../images/chunk-tagrep.png
   :scale: 25:30:30

   Tag Representation of Chunk Structures

IOB tags have become the standard way to represent chunk structures in
files, and we will also be using this format.  Here is an example of
how the information in fig-chunk-tagrep_ would appear in a file::

  We PRP B-NP
  saw VBD O
  the DT B-NP
  little JJ I-NP
  yellow JJ I-NP
  dog NN I-NP

.. Give example with a verb group?

In this representation, there is one token per line, each with
its part-of-speech tag and its chunk tag.  We will see later that this
format permits us to represent more than one chunk type, so long as
the chunks do not overlap.  

As we saw earlier, chunk structures can also be represented using
trees.  These have the benefit that each chunk is a constituent that
can be manipulated directly.  An example is shown in fig-chunk-treerep_.

.. _fig-chunk-treerep:
.. figure:: ../images/chunk-treerep.png
   :scale: 25:30:30

   Tree Representation of Chunk Structures

|nopar|
|NLTK| uses trees for its internal representation of chunks, and
provides methods for reading and writing such trees to the IOB
format.  By now you should understand what chunks are, and how they
are represented.  In the next section, you will see how to build a
simple chunker.



















----------------------------------
Developing and Evaluating Chunkers
----------------------------------

Now you have a taste of what chunking can do, but we have not
explained how to carry out a quantitative evaluation of chunkers.  For
this, we need to get access to a corpus that has been annotated not
only with parts-of-speech, but also with chunk information.  We will
begin by looking at the mechanics of converting IOB format into an
|NLTK| tree, then at how this is done on a larger scale using a
chunked corpus directly.  We will see how to use the corpus to score
the accuracy of a chunker, then look some more flexible ways to
manipulate chunks.  Our focus throughout will be on scaling up the
coverage of a chunker.

Developing Chunkers
-------------------

Creating a good chunker usually requires several rounds of
development and testing, during which existing rules are refined and
new rules are added.  In order to diagnose any problems, it often
helps to trace the execution of a chunker, using its ``trace`` argument.
The tracing output shows the rules that are
applied, and uses braces to show the chunks that are created at each
stage of processing.
In code-chunker2_, two chunk patterns are applied to the input
sentence.  The first rule finds all sequences of three tokens whose
tags are ``DT``, ``JJ``, and ``NN``, and the second rule finds any
sequence of tokens whose tags are either ``DT`` or ``NN``.  We
set up two chunkers, one for each rule ordering, and test them on
the same input.

.. pylisting:: code-chunker2
   :caption: Two Noun Phrase Chunkers Having Identical Rules in Different Orders

   sentence = [("The", "DT"), ("enchantress", "NN"), ("clutched", "VBD"),
                   ("the", "DT"), ("beautiful", "JJ"), ("hair", "NN")]
   cp1 = nltk.RegexpParser(r"""
     NP: {<DT><JJ><NN>}      # Chunk det+adj+noun
         {<DT|NN>+}          # Chunk sequences of NN and DT
     """)
   cp2 = nltk.RegexpParser(r"""
     NP: {<DT|NN>+}          # Chunk sequences of NN and DT
         {<DT><JJ><NN>}      # Chunk det+adj+noun
     """)

   >>> print cp1.parse(sentence, trace=1)
   # Input:
    <DT>  <NN>  <VBD>  <DT>  <JJ>  <NN> 
   # Chunk det+adj+noun:
    <DT>  <NN>  <VBD> {<DT>  <JJ>  <NN>}
   # Chunk sequences of NN and DT:
   {<DT>  <NN>} <VBD> {<DT>  <JJ>  <NN>}
   (S
     (NP The/DT enchantress/NN)
     clutched/VBD
     (NP the/DT beautiful/JJ hair/NN))
   >>> print cp2.parse(sentence, trace=1)
   # Input:
    <DT>  <NN>  <VBD>  <DT>  <JJ>  <NN> 
   # Chunk sequences of NN and DT:
   {<DT>  <NN>} <VBD> {<DT>} <JJ> {<NN>}
   # Chunk det+adj+noun:
   {<DT>  <NN>} <VBD> {<DT>} <JJ> {<NN>}
   (S
     (NP The/DT enchantress/NN)
     clutched/VBD
     (NP the/DT)
     beautiful/JJ
     (NP hair/NN))

Observe that when we chunk material that is already partially chunked,
the chunker will only create chunks that do not partially overlap
existing chunks.  In the case of ``cp2``, the second rule
did not find any chunks, since all chunks that matched
its tag pattern overlapped with existing chunks.  As you can see,
you need to be careful to put chunk rules in the right order. 

You may have noted that we have added explanatory comments, preceded
by ``#``, to each of our tag rules. Although it is not strictly
necessary to do this, it's a helpful reminder of what a rule is meant
to do, and it is used as a header line for the output of a rule
application when tracing is on.

You might want to test out some of your rules on a corpus. One option
is to use the Brown corpus. However, you need to remember that the
Brown tagset is different from the Penn Treebank tagset that we
have been using for our examples so far in this chapter (see
``nltk.help.brown_tagset()`` and ``nltk.help.upenn_tagset()``
for details).  Because the Brown tagset
uses ``NP`` for proper nouns, in this example we have followed Abney
in labeling noun chunks as ``NX``.

    >>> grammar = (r"""
    ...    NX: {<AT|AP|PP\$>?<JJ.*>?<NN.*>}  # Chunk article/numeral/possessive+adj+noun
    ...        {<NP>+}                       # Chunk one or more proper nouns                   
    ... """)
    >>> cp = nltk.RegexpParser(grammar)
    >>> sent = nltk.corpus.brown.tagged_sents(categories='news')[112]
    >>> print cp.parse(sent)
    (S
      (NX His/PP$ contention/NN)
      was/BEDZ
      denied/VBN
      by/IN
      (NX several/AP bankers/NNS)
      ,/,
      including/IN
      (NX Scott/NP Hudson/NP)
      of/IN
      (NX Sherman/NP)
      ,/,
      (NX Gaynor/NP B./NP Jones/NP)
      of/IN
      (NX Houston/NP)
      ,/,
      (NX J./NP B./NP Brady/NP)
      of/IN
      (NX Harlingen/NP)
      and/CC
      (NX Howard/NP Cox/NP)
      of/IN
      (NX Austin/NP)
      ./.)

Reading IOB Format and the CoNLL 2000 Corpus
--------------------------------------------

Using the ``corpora`` module we can load Wall Street Journal
text that has been tagged then chunked using the IOB notation.  The
chunk categories provided in this corpus are ``NP``, ``VP`` and ``PP``.  As we
have seen, each sentence is represented using multiple lines, as shown
below::

  he PRP B-NP
  accepted VBD B-VP
  the DT B-NP
  position NN I-NP
  ...

A conversion function ``chunk.conllstr2tree()`` builds a tree
representation from one of these multi-line strings.  Moreover, it
permits us to choose any subset of the three chunk types to use.  The
example below produces only ``NP`` chunks:

.. doctest-ignore::
    >>> text = '''
    ... he PRP B-NP
    ... accepted VBD B-VP
    ... the DT B-NP
    ... position NN I-NP
    ... of IN B-PP
    ... vice NN B-NP
    ... chairman NN I-NP
    ... of IN B-PP
    ... Carlyle NNP B-NP
    ... Group NNP I-NP
    ... , , O
    ... a DT B-NP
    ... merchant NN I-NP
    ... banking NN I-NP
    ... concern NN I-NP
    ... . . O
    ... '''
    >>> nltk.chunk.conllstr2tree(text, chunk_types=('NP',)).draw()

.. tree:: (S (NP (PRP he))
             (VBD accepted)
             (NP (DT the) (NN position))
             (IN of)
             (NP (NN vice) (NN chairman))
             (IN of)
             (NP (NNP Carlyle) (NNP Group))
             (, ,)
             (NP (DT a) (NN merchant) (NN banking) (NN concern))
             (. .))
   :scale: 80:80:50


We can use the |NLTK| corpus module to access a larger amount of chunked
text.  The CoNLL 2000 corpus contains 270k words of Wall Street
Journal text, divided into "train" and "test" portions, annotated with
part-of-speech tags and chunk tags in the IOB format.  We can access
the data using an NLTK corpus reader called ``conll2000``.  Here is an
example that reads the 100th sentence of the "train" portion of the corpus:

    >>> print nltk.corpus.conll2000.chunked_sents('train.txt')[99]
    (S
      (PP Over/IN)
      (NP a/DT cup/NN)
      (PP of/IN)
      (NP coffee/NN)
      ,/,
      (NP Mr./NNP Stone/NNP)
      (VP told/VBD)
      (NP his/PRP$ story/NN)
      ./.)


|nopar|
This  showed three chunk types, for ``NP``, ``VP`` and ``PP``.
We can also select which chunk types to read:

    >>> print nltk.corpus.conll2000.chunked_sents('train.txt', chunk_types=('NP',))[99]
    (S
      Over/IN
      (NP a/DT cup/NN)
      of/IN
      (NP coffee/NN)
      ,/,
      (NP Mr./NNP Stone/NNP)
      told/VBD
      (NP his/PRP$ story/NN)
      ./.)


Simple Evaluation and Baselines
-------------------------------

Armed with a corpus, it is now possible to carry out some simple evaluation.
We start off by establishing a baseline for the trivial chunk parser
``cp`` that creates no chunks:

    >>> from nltk.corpus import conll2000
    >>> cp = nltk.RegexpParser("")
    >>> print nltk.chunk.accuracy(cp, conll2000.chunked_sents('train.txt', chunk_types=('NP',)))
    0.440845995079

This indicates that more than a third of the words are tagged with
``O`` (i.e., not in an ``NP`` chunk).  Now let's try a naive regular
expression chunker that looks for tags (e.g., ``CD``, ``DT``, ``JJ``,
etc.) beginning with letters that are typical of noun phrase tags:

    >>> grammar = r"NP: {<[CDJNP].*>+}"
    >>> cp = nltk.RegexpParser(grammar)
    >>> print nltk.chunk.accuracy(cp, conll2000.chunked_sents('train.txt', chunk_types=('NP',)))
    0.874479872666

As you can see, this approach achieves pretty good results. In
order to develop a more data-driven approach, let's define a function
``chunked_tags()`` that takes some chunked data
and sets up a conditional frequency distribution (code-chunker3_).
For each tag, it counts up the number of times the tag
occurs inside an ``NP`` chunk (the ``True`` case, where ``chtag`` is
``B-NP`` or ``I-NP``), or outside a chunk (the ``False`` case, where
``chtag`` is ``O``).  It returns a list of those tags that occur
inside chunks more often than outside chunks.

.. pylisting:: code-chunker3
   :caption: Capturing the conditional frequency of NP Chunk Tags

   def chunked_tags(train):
       """Generate a list of tags that tend to appear inside chunks"""
       cfdist = nltk.ConditionalFreqDist()
       for t in train:
           for word, tag, chtag in nltk.chunk.tree2conlltags(t):
               if chtag == "O":
                   cfdist[tag].inc(False)
               else:
                   cfdist[tag].inc(True)
       return [tag for tag in cfdist.conditions() if cfdist[tag].max() == True]
   >>> train_sents = conll2000.chunked_sents('train.txt', chunk_types=('NP',))
   >>> print chunked_tags(train_sents)
   ['PRP$', 'WDT', 'JJ', 'WP', 'DT', '#', '$', 'NN', 'FW', 'POS',
   'PRP', 'NNS', 'NNP', 'PDT', 'RBS', 'EX', 'WP$', 'CD', 'NNPS', 'JJS', 'JJR']

The next step is to convert this list of tags into a tag pattern.  To
do this we need to "escape" all non-word characters, by preceding them
with a backslash.  Then we need to join them into a disjunction.  This
process would convert a tag list ``['NN', 'NN\$']`` into the tag pattern
``<NN|NN\$>``.  The ``baseline_chunker()`` function in code-chunker4_ does this work, and returns a
regular expression chunker:

.. pylisting:: code-chunker4
   :caption: Deriving a Regexp Chunker from Training Data

   def baseline_chunker(train):
       chunk_tags = [re.sub(r'(\W)', r'\\\1', tag)
                     for tag in chunked_tags(train)]
       grammar = 'NP: {<%s>+}' % '|'.join(chunk_tags)
       return nltk.RegexpParser(grammar)

|nopar|
The final step is to train this chunker and test its accuracy (this
time on the "test" portion of the corpus, i.e., data not seen during training):

   >>> from nltk.corpus import conll2000
   >>> train_sents = conll2000.chunked_sents('train.txt', chunk_types=('NP',))
   >>> test_sents  = conll2000.chunked_sents('test.txt', chunk_types=('NP',))
   >>> cp = baseline_chunker(train_sents)
   >>> print nltk.chunk.accuracy(cp, test_sents)
   0.914262194736


Evaluating Chunk Parsers
------------------------

An easy way to evaluate a chunk parser is to take some already chunked
text, strip off the chunks, rechunk it, and compare the result with
the original chunked text.  The ``ChunkScore.score()`` function takes
the correctly chunked sentence as its first argument, and the newly
chunked version as its second argument, and compares them.  It reports
the fraction of actual chunks that were found (recall), the fraction
of hypothesized chunks that were correct (precision), and the
F-score (see sec-evaluation_).

During evaluation of a chunk parser, it is useful to flatten a chunk
structure into a tree consisting only of a root node and leaves:

    >>> correct = nltk.chunk.tagstr2tree(
    ...    "[ the/DT little/JJ cat/NN ] sat/VBD on/IN [ the/DT mat/NN ]")
    >>> print correct.flatten()
    (S the/DT little/JJ cat/NN sat/VBD on/IN the/DT mat/NN)

We run a chunker over this flattened data, and compare the
resulting chunked sentences with the originals, as follows:


    >>> grammar = r"NP: {<PRP|DT|POS|JJ|CD|N.*>+}"
    >>> cp = nltk.RegexpParser(grammar)
    >>> sentence = [("the", "DT"), ("little", "JJ"), ("cat", "NN"),
    ... ("sat", "VBD"), ("on", "IN"), ("the", "DT"), ("mat", "NN")]
    >>> chunkscore = nltk.chunk.ChunkScore()
    >>> guess = cp.parse(correct.flatten())
    >>> chunkscore.score(correct, guess)
    >>> print chunkscore
    ChunkParse score:
        Precision: 100.0%
        Recall:    100.0%
        F-Measure: 100.0%

``ChunkScore`` is a class for scoring chunk parsers.  It can be used
to evaluate the output of a chunk parser, using precision, recall,
f-measure, missed chunks, and incorrect chunks.  It can also be used
to combine the scores from the parsing of multiple texts.  This is
quite useful if we are parsing a text one sentence at a time.  The
following program listing shows a typical use of the ``ChunkScore``
class.  In this example, ``chunkparser`` is being tested on each
sentence from the Wall Street Journal tagged files.

    >>> grammar = r"NP: {<DT|JJ|NN>+}"
    >>> cp = nltk.RegexpParser(grammar)
    >>> chunkscore = nltk.chunk.ChunkScore()
    >>> for fileid in nltk.corpus.treebank_chunk.fileids()[:5]:
    ...     for chunk_struct in nltk.corpus.treebank_chunk.chunked_sents(fileid):
    ...         test_sent = cp.parse(chunk_struct.flatten())
    ...         chunkscore.score(chunk_struct, test_sent)
    >>> print chunkscore
    ChunkParse score:
        Precision:  42.3%
        Recall:     29.9%
        F-Measure:  35.0%

The overall results of the evaluation can be viewed by printing the
``ChunkScore``.  Each evaluation metric is also returned by an
accessor method: ``precision()``, ``recall``, ``f_measure``,
``missed``, and ``incorrect``.  The ``missed`` and ``incorrect``
methods can be especially useful when trying to improve the
performance of a chunk parser.  Here are the missed chunks:

.. doctest-ignore::
    >>> from random import shuffle
    >>> missed = chunkscore.missed()
    >>> shuffle(missed)
    >>> print missed[:10]
    [(('A', 'DT'), ('Lorillard', 'NNP'), ('spokeswoman', 'NN')),
     (('even', 'RB'), ('brief', 'JJ'), ('exposures', 'NNS')),
     (('its', 'PRP$'), ('Micronite', 'NN'), ('cigarette', 'NN'), ('filters', 'NNS')),
     (('30', 'CD'), ('years', 'NNS')),
     (('workers', 'NNS'),),
     (('preliminary', 'JJ'), ('findings', 'NNS')),
     (('Medicine', 'NNP'),),
     (('Consolidated', 'NNP'), ('Gold', 'NNP'), ('Fields', 'NNP'), ('PLC', 'NNP')),
     (('its', 'PRP$'), ('Micronite', 'NN'), ('cigarette', 'NN'), ('filters', 'NNS')),
     (('researchers', 'NNS'),)]

Here are the incorrect chunks:

.. doctest-ignore::
    >>> incorrect = chunkscore.incorrect()
    >>> shuffle(incorrect)
    >> print incorrect[:10]
    [(('New', 'JJ'), ('York-based', 'JJ')),
     (('Micronite', 'NN'), ('cigarette', 'NN')),
     (('a', 'DT'), ('forum', 'NN'), ('likely', 'JJ')),
     (('later', 'JJ'),),
     (('preliminary', 'JJ'),),
     (('New', 'JJ'), ('York-based', 'JJ')),
     (('resilient', 'JJ'),),
     (('group', 'NN'),),
     (('the', 'DT'),),
     (('Micronite', 'NN'), ('cigarette', 'NN'))]

.. Note: By default, only the first 100 missed chunks and the first
   100 incorrect chunks will be remembered by the ``ChunkScore``.  You
   can tell ``ChunkScore`` to record more chunk examples with the
   ``max_fp_examples`` (maximum false positive examples) and the
   ``max_fn_examples`` (maximum false negative examples) keyword
   arguments to the ``ChunkScore`` constructor:

    >>> chunkscore = nltk.chunk.ChunkScore(max_fp_examples=1000,
    ...                                    max_fn_examples=1000)

Training N-Gram Chunkers
------------------------

Our approach to chunking has been to try to detect structure based on
the part-of-speech tags.  We have seen that the IOB format represents
this extra structure using another kind of tag.  The question arises
as to whether we could use the same *n*-gram tagging methods we saw in
chap-tag_, applied to a different vocabulary. In this case,
rather than trying to determine the correct part-of-speech tag, given
a word, we are trying to determine the correct chunk tag, given a
part-of-speech tag.

The first step is to get the ``word,tag,chunk`` triples from the
CoNLL 2000 corpus and map these to ``tag,chunk`` pairs:

    >>> from nltk.corpus import conll2000
    >>> chunk_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(chtree)]
    ...              for chtree in conll2000.chunked_sents('train.txt')]

We will now train two *n*-gram taggers over this data.  To start off,
we train and score a `unigram chunker`:dt: on the above data, just as
if it was a tagger:

    >>> train_set, test_set = chunk_data[200:], chunk_data[:200]
    >>> unigram_chunker = nltk.UnigramTagger(train_set)
    >>> print 'Accuracy:', unigram_chunker.evaluate(test_set)
    Accuracy: 0.749227373068

This score reflects the tagging accuracy of our chunker |mdash| i.e.,
the percentage of IOB tags that the tagger correctly predicted.  To
find the f-measure score for this n-gram chunker, we can use a
``ChunkScore`` object, as shown in code-unigram-chunkscore_

.. pylisting:: code-unigram-chunkscore
    :caption:
        A function used to evaluate the n-gram chunkers, by 
        constructing an appropriate ``ChunkScore`` object.  Before
        the sentences can be scored, they must be converted from
        tagged sequences to chunk trees, on lines unigram-chunkscore1_
        and unigram-chunkscore2_.

    def eval_tagging_chunker(chunker):
        chunkscore = nltk.chunk.ChunkScore()
        for test_sent in test_set:
            guess_sent = chunker.tag(nltk.tag.untag(test_sent))
            chunkscore.score(nltk.chunk.conlltags2tree(test_sent), # [_unigram-chunkscore1]
                             nltk.chunk.conlltags2tree(guess_sent)) # [_unigram-chunkscore2]
        print 'Accuracy: %.1f%%' % (100*chunker.evaluate(test_set))
        print chunkscore

    >>> eval_tagging_chunker(unigram_chunker)
    Accuracy: 74.9%
    ChunkParse score:
        Precision:  73.0%
        Recall:     86.2%
        F-Measure:  79.1%

This chunker does reasonably well, achieving an
overall f-measure score of 79%.  Let's look at some of 
the errors it makes.  Consider the opening phrase of the first
sentence of the CONLL chunking data, here shown with part-of-speech
tags:

  Confidence/NN in/IN the/DT pound/NN is/VBZ widely/RB expected/VBN
  to/TO take/VB another/DT sharp/JJ dive/NN

We can try out the unigram chunker on this first sentence by creating
some "tokens" using ``[t for t,c in chunk_data[0]]``, then running
our chunker over them using ``list(unigram_chunker.tag(tokens))``.
The unigram chunker only looks at the tags, and tries to add chunk
tags.  Here is what it comes up with:

  NN/I-NP IN/B-PP DT/B-NP NN/I-NP VBZ/B-VP RB/O VBN/I-VP TO/B-PP
  VB/I-VP DT/B-NP JJ/I-NP NN/I-NP

Notice that it tags all instances of ``NN`` with ``I-NP``, because
nouns usually do not appear at the beginning of noun phrases in
the training data.  Thus, the first noun ``Confidence/NN`` is
tagged incorrectly.  However, ``pound/NN`` and ``dive/NN`` are
correctly tagged as ``I-NP``; they are not in the initial position
that should be tagged ``B-NP``.  The chunker incorrectly tags
``widely/RB`` as ``O``, and it incorrectly tags the
infinitival ``to/TO`` as ``B-PP``, as if it was a preposition starting a
prepositional phrase.

.. [Why these problems might go away if we look at the previous chunk tag?]

Now let's run a bigram chunker:

    >>> bigram_chunker = nltk.BigramTagger(chunk_data, backoff=unigram_chunker)
    >>> eval_tagging_chunker(bigram_chunker)
    Accuracy: 87.6%
    ChunkParse score:
        Precision:  80.6%
        Recall:     87.3%
        F-Measure:  83.8%

We can run the bigram chunker over the same sentence as before
using ``list(bigram_chunker.tag(tokens))``.
Here is what it comes up with:

  NN/B-NP IN/B-PP DT/B-NP NN/I-NP VBZ/B-VP RB/I-VP VBN/I-VP TO/I-VP
  VB/I-VP DT/B-NP JJ/I-NP NN/I-NP

This is 100% correct.

Training Classifier-Based Chunkers
----------------------------------

Both the regular-expression based chunkers and the n-gram chunkers
that we have seen so far decide what chunks they should create
entirely based on part of tags.  However, sometimes part of speech
tags are insufficient to determine how a sentence should be chunked.
For example, consier the following two statements:

.. ex::
  .. ex:: Joey/NN sold/VBD the/DT farmer/NN rice/NN ./.
  .. ex:: Nick/NN broke/VBD my/DT computer/NN monitor/NN ./.

Despite the fact that these two sentences have the same part of speech
tags, they are chunked differently: in the first sentence, "the
farmer" and "rice" are seperate chunks, while in the second sentence,
"the computer monitor" is a single chunk.  Clearly, we need to make
use of information about the content of the words, in addition to just
their part of speech tags, if we wish to maximize chunking
performance.

One way that we can incorporate information about the content of words
is to use a classifier-based tagger to chunk the sentence.  Like the
n-gram chunker considered in the previous section, this
classifier-based chunker will work by assigning IOB tags to the words
in a sentence, and then converting those tags to chunks.  For the
classifier-based tagger itself, we will use the same approach that we
used in sec-supervised-classification_ to build a part-of-speech tagger.

The basic code for the classifier-based NP chunker is shown in
code-classifier-chunker_.  It consists of two classes.  The first
class, consec-chunk-tagger_, is almost identical to the
``ConsecutivePosTagger`` class from code-consecutive-pos-tagger_.
The only two differences are that it calls a different feature
extractor consec-use-fe_; and thta it uses a MaxentClassifier rather
than a NaiveBayesClassifier consec-use-maxent_.  The second class,
consec-chunker_, is basically a wrapper around the tagger class that
turns it into a chunker.  During training, this second class maps the
chunk trees in the training corpus into tag sequences; and in the
``parse()`` method, it converts the tag sequence provided by the
tagger back into a chunk tree.

.. pylisting:: code-classifier-chunker
   :caption: Noun Phrase Chunking with a Consecutive Classifier

   class ConsecutiveNPChunkTagger(nltk.TaggerI): # [_consec-chunk-tagger]
   
       def __init__(self, train_sents):
           train_set = []
           for tagged_sent in train_sents:
               untagged_sent = nltk.tag.untag(tagged_sent)
               history = []
               for i, (word, tag) in enumerate(tagged_sent):
                   featureset = npchunk_features(untagged_sent, i, history) # [_consec-use-fe]
                   train_set.append( (featureset, tag) )
                   history.append(tag)
           self.classifier = nltk.MaxentClassifier.train( # [_consec-use-maxent]
               train_set, algorithm='megam', trace=0)
       
       def tag(self, sentence):
           history = []
           for i, word in enumerate(sentence):
               featureset = npchunk_features(sentence, i, history)
               tag = self.classifier.classify(featureset)
               history.append(tag)
           return zip(sentence, history)
   
   class ConsecutiveNPChunker(nltk.ChunkParserI): # [_consec-chunker]
       def __init__(self, train_sents):
           tagged_sents = [[((w,t),c) for (w,t,c) in
                            nltk.chunk.tree2conlltags(sent)]
                           for sent in train_sents]
           self.tagger = ConsecutiveNPChunkTagger(tagged_sents)
   
       def parse(self, sentence):
           return nltk.chunk.conlltags2tree(self.tagger.tag(sentence))

The only piece left to fill in is the feature extractor.  We begin by
defining a simple feature extractor, which just provides current
part-of-speech tag.  Using this feature extractor, our
classifier-based chunker is very similar to the unigram chunker, as is
reflected in its performance:

    >>> def npchunk_features(sentence, i, history):
    ...     word, pos = sentence[i]
    ...     return {"pos": pos}
    >>> def score_chunker(chunker):
    ...     chunkscore = nltk.chunk.ChunkScore()
    ...     for test_sent in test_sents:
    ...         guess_sent = chunker.parse(test_sent.leaves())
    ...         chunkscore.score(test_sent, guess_sent)
    ...     print chunkscore
    >>> score_chunker(ConsecutiveNPChunker(train_sents))
    ChunkParse score:
        Precision:  77.6%
        Recall:     85.3%
        F-Measure:  81.2%

We can also add a feature for the previous part-of-speech tag.  Adding this
feature allows the classifier to model interactions between adjacent
tags, and results in a chunker that is closely related to the bigram
chunker.

    >>> def npchunk_features(sentence, i, history):
    ...     word, pos = sentence[i]
    ...     if i == 0:
    ...         prevword, prevpos = "<START>", "<START>"
    ...     else:
    ...         prevword, prevpos = sentence[i-1]
    ...     return {"pos": pos, "prevpos": prevpos}
    >>> score_chunker(ConsecutiveNPChunker(train_sents))
    ChunkParse score:
        Precision:  79.5%
        Recall:     85.5%
        F-Measure:  82.4%

Next, we'll try adding a feature for the current word, since we
hypothesized that word content should be useful for chunking.  We find
that this feature does indeed improve the chunker's performance, by
over 2.5 percentage points (which corresponds to a 7% reduction in the
error rate).

    >>> def npchunk_features(sentence, i, history):
    ...     word, pos = sentence[i]
    ...     if i == 0:
    ...         prevword, prevpos = "<START>", "<START>"
    ...     else:
    ...         prevword, prevpos = sentence[i-1]
    ...     return {"pos": pos, "word": word, "prevpos": prevpos}
    >>> score_chunker(ConsecutiveNPChunker(train_sents))
    ChunkParse score:
        Precision:  81.2%
        Recall:     87.1%
        F-Measure:  84.1%

Finally, we can try extending the feature extractor with a variety of
additional features, such as lookahead features chunk-fe-lookahead_,
paired features chunk-fe-paired_, and complex contextual features
chunk-fe-complex_.  This last feature, ``tags-since-dt``, creates a
string describing the set of all part-of-speech tags that have been
encountered since the most recent determiner.

    >>> def npchunk_features(sentence, i, history):
    ...     word, pos = sentence[i]
    ...     if i == 0:
    ...         prevword, prevpos = "<START>", "<START>"
    ...     else:
    ...         prevword, prevpos = sentence[i-1]
    ...     return {"pos": pos, 
    ...             "word": word, 
    ...             "prevpos": prevpos,
    ...             "nextpos": nextpos, # [_chunk-fe-lookahead]
    ...             "prevpos+pos": ""%s+%s" % (prevpos, pos),  # [_chunk-fe-paired]
    ...             "pos+nextpos": "%s+%s" % (pos, nextpos),
    ...             "tags-since-dt": tags_since_dt(sentence, i)}  # [_chunk-fe-complex]

    >>> def tags_since_dt(sentence, i):
    ...     tags = set()
    ...     for word, pos in sentence[:i]:
    ...         if pos == 'DT':
    ...             tags = set()
    ...         else:
    ...             tags.add(pos)
    ...     return '+'.join(sorted(tags))

    >>> score_chunker(ConsecutiveNPChunker(train_sents))
    ChunkParse score:
        Precision:  86.6%
        Recall:     89.3%
        F-Measure:  87.9%

.. note:: |TRY|
   Try adding different features to the feature extractor function
   ``npchunk_features``, and see if you can further improve the
   performace of the NP chunker.

.. _sec-recursion-in-linguistic-structure:

---------------------------------
Recursion in Linguistic Structure
---------------------------------

Building Nested Structure with Cascaded Chunkers
------------------------------------------------

So far, our chunk structures have been relatively flat.  Trees consist
of tagged tokens, optionally grouped under a chunk node such as
``NP``.  However, it is possible to build chunk structures of
arbitrary depth, simply by creating a multi-stage chunk grammar.
These stages are processed in the order
that they appear.  The patterns in later stages can refer to a mixture
of part-of-speech tags and chunk types.  code-cascaded-chunker_ has
patterns for noun phrases, prepositional phrases, verb phrases, and
sentences.
This is a four-stage chunk grammar, and can be used to create
structures having a depth of at most four.

.. pylisting:: code-cascaded-chunker
   :caption: A Chunker that Handles NP, PP, VP and S

   grammar = r"""
     NP: {<DT|JJ|NN.*>+}       # Chunk sequences of DT, JJ, NN
     PP: {<IN><NP>}            # Chunk prepositions followed by NP
     VP: {<VB.*><NP|PP|S>+$}   # Chunk rightmost verbs and arguments/adjuncts
     S:  {<NP><VP>}            # Chunk NP, VP
     """
   cp = nltk.RegexpParser(grammar)
   sentence = [("Mary", "NN"), ("saw", "VBD"), ("the", "DT"), ("cat", "NN"),
       ("sit", "VB"), ("on", "IN"), ("the", "DT"), ("mat", "NN")]

   >>> print cp.parse(sentence)
   (S
     (NP Mary/NN)
     saw/VBD
     (S
       (NP the/DT cat/NN)
       (VP sit/VB (PP on/IN (NP the/DT mat/NN)))))

Unfortunately this result misses the ``VP`` headed by `saw`:lx:.  It has
other shortcomings too.  Let's see what happens when we apply this
chunker to a sentence having deeper nesting.

    >>> sentence = [("John", "NNP"), ("thinks", "VBZ"), ("Mary", "NN"),
    ...     ("saw", "VBD"), ("the", "DT"), ("cat", "NN"), ("sit", "VB"),
    ...     ("on", "IN"), ("the", "DT"), ("mat", "NN")]
    >>> print cp.parse(sentence)
    (S
      (NP John/NNP)
      thinks/VBZ
      (NP Mary/NN)
      saw/VBD
      (S
        (NP the/DT cat/NN)
        (VP sit/VB (PP on/IN (NP the/DT mat/NN)))))

The solution to these problems is to get the chunker to loop over its
patterns: after trying all of them, it repeats the process.
We add an optional second argument ``loop`` to specify the number
of times the set of patterns should be run:

    >>> cp = nltk.RegexpParser(grammar, loop=2)
    >>> print cp.parse(sentence)
    (S
      (NP John/NNP)
      thinks/VBZ
      (S
        (NP Mary/NN)
        (VP
          saw/VBD
          (S
            (NP the/DT cat/NN)
            (VP sit/VB (PP on/IN (NP the/DT mat/NN)))))))

This cascading process enables us to create deep structures.  However,
creating and debugging a cascade is quite difficult, and there comes
a point where it is more effective to do full parsing (see chap-parse_).
Also, the cascading process can only produce trees of fixed depth
(no deeper than the number of stages in the cascade), and this is
insufficient for complete syntactic analysis.

Trees
-----

A `tree`:dt: is a set of connected labeled nodes, each reachable
by a unique path from a distinguished root node.  Here's an
example of a tree (note that they are standardly drawn upside-down): 

.. ex::
  .. tree:: (S (NP Alice) (VP (V chased) (NP the rabbit)))

We use a 'family' metaphor to talk about the
relationships of nodes in a tree: for example, ``S`` is the
`parent`:dt: of ``VP``; conversely ``VP`` is a `child`:dt:
of ``S``.  Also, since ``NP`` and ``VP`` are both
children of ``S``, they are also `siblings`:dt:.
For convenience, there is also a text format for specifying
trees: 

.. doctest-ignore::
      (S 
         (NP Alice)
         (VP 
            (V chased)
            (NP 
               (Det the)
               (N rabbit))))

Although we will focus on syntactic trees, trees can be used to encode
`any`:em: homogeneous hierarchical structure that spans a sequence
of linguistic forms (e.g. morphological structure, discourse structure).
In the general case, leaves and node values do not have to be strings.

In |NLTK|, we create a tree by giving a node label and a list of children:

    >>> tree1 = nltk.Tree('NP', ['Alice'])
    >>> print tree1
    (NP Alice)
    >>> tree2 = nltk.Tree('NP', ['the', 'rabbit'])
    >>> print tree2
    (NP the rabbit)

We can incorporate these into successively larger trees as follows:

    >>> tree3 = nltk.Tree('VP', ['chased', tree2])
    >>> tree4 = nltk.Tree('S', [tree1, tree3])
    >>> print tree4
    (S (NP Alice) (VP chased (NP the rabbit)))

Here are some of the methods available for tree objects:

    >>> print tree4[1]
    (VP chased (NP the rabbit))
    >>> tree4[1].node
    'VP'
    >>> tree4.leaves()
    ['Alice', 'chased', 'the', 'rabbit']
    >>> tree4[1][1][1]
    'rabbit'

The bracketed representation for complex trees can be difficult to read.
In these cases, the ``draw`` method can be very useful. 
It opens a new window, containing a graphical representation
of the tree.  The tree display window allows you to zoom in and out;
to collapse and expand subtrees; and to print the graphical
representation to a postscript file (for inclusion in a document).

    >>> tree3.draw()                           # doctest: +SKIP

.. image:: ../images/parse_draw.png
   :scale: 70

Tree Traversal
--------------

It is standard to use a recursive function to traverse a tree.
The listing in code-traverse_ demonstrates this.  Note that
we have used "duck typing" to detect that ``t`` is a tree (i.e.
``t.node`` is defined).

.. pylisting:: code-traverse
   :caption: A Recursive Function to Traverse a Tree
   
   def traverse(t):
       try:
           t.node
       except AttributeError:
           print t,
       else:
           # Now we know that t.node is defined
           print '(', t.node,
           for child in t:
               traverse(child)
           print ')',

    >>> t = nltk.Tree('(S (NP Alice) (VP chased (NP the rabbit)))')
    >>> traverse(t)
    ( S ( NP Alice ) ( VP chased ( NP the rabbit ) ) )



------------------------
Named Entity Recognition
------------------------

When performing information extraction, we're often most interested in
`named entities`:dt:, proper noun phrases that denote specific types
of individuals such as organizations, persons, dates, and so on. Thus,
we might use the following |XML| annotations to mark-up the named
entities in ex-ie5_:

.. ex::
   .. _ex-ie5:
   .. ex:: ... said William Gale, an economist at the Brookings Institution,
      the research group in Washington. 

   .. _ex-ie6:
   .. ex:: ... said <ne type='PERSON'>William Gale</ne>, an economist at
      the <ne type='ORGANIZATION'>Brookings Institution</ne>,
      the research group in <ne type='LOCATION'>Washington<ne>. 

How do we go about identifying named entities?  One option would be
to look up each word in an appropriate list of names.
For example, in the case of locations, we could use the
Alexandria Gazetteer or the Getty Gazetteer.  However, doing this
blindly runs into problems, as shown in fig-locations_.

.. _fig-locations:
.. figure:: ../images/locations.png
   :scale: 25:25:30

   Location Detection by Simple Lookup for a News Story

Observe that the gazetteer has good coverage of locations in many countries,
and incorrectly finds locations like Sanchez in the Dominican Republic.
Of course we could omit such locations from the gazetteer, but then we won't
be able to identify them when they do appear in a document.

It gets even harder in the case of names for people or organizations.
Any list of such names will probably have poor coverage. New organizations
come into existence every day, so if we are trying to deal
with contemporary newswire or blog entries, it is unlikely that
we will be able to recognize many of the entities using gazetteer lookup. 

Another major source of difficulty is caused by the fact that many
named entity terms are ambiguous. Thus
`May`:lx: and `North`:lx: are likely to be parts of named entities for DATE
and LOCATION, respectively, but could both be part of a PERSON;
conversely `Christian Dior`:lx: looks like a PERSON but is more
likely to be of type ORGANIZATION. A term like `Yankee`:lx: will be
ordinary modifier in some contexts, but will be marked as an entity of
type ORGANIZATION in the phrase `Yankee infielders`:lx:.

Another challenge is posed by multi-part names like 
`Stanford University`:lx:, and by names that contain other names
such as `Cecil H. Green Library`:lx: and `Escondido Village Conference
Service Center`:lx:. In named entity recognition, therefore, we need
to be able to identify the beginning and end of multi-token
sequences.  

Named entity recognition is a task that is well-suited to the type of
classifier-based approach that we saw for noun phrase chunking.  In
particular, we can build a tagger that labels each word in a sentence
using the IOB format, where chunks are labeled by their appropriate type.
Here is part of the CONLL 2002 (``conll2002``) Dutch training data::

    Eddy N B-PER
    Bonte N I-PER
    is V O
    woordvoerder N O
    van Prep O
    diezelfde Pron O
    Hogeschool N B-ORG
    . Punc O

In this representation, there is one token per line, each with its
part-of-speech tag and its named entity tag.  Based on this training
corpus, we can construct a tagger that can be used to label new
sentences; and use the ``nltk.chunk.conlltags2tree()`` function to
convert the tag sequences into a chunk tree.  

NLTK provides two default named entity chunkers: one of which labels
all named entities as ``NE``\ , and the other of which labels them
with category labels such as PERSON, ORGANIZATION, and GPE (for
"Geopolitical Entity," which includes countries, states, cities,
etc.).  Both chunkers can be accessed using the function
``nltk.ne_chunk()``:

    >>> sent = nltk.corpus.treebank.tagged_sents()[22]
    >>> print nltk.ne_chunk(sent) # doctest: +SKIP
    (S
      The/DT
      (GPE U.S./NNP)
      is/VBZ
      one/CD
      ...
      according/VBG
      to/TO
      (PERSON Brooke/NNP T./NNP Mossman/NNP)
      ...)
    >>> print nltk.ne_chunk(sent, binary=True) # doctest: +SKIP
    (S
      The/DT
      (NE U.S./NNP)
      is/VBZ
      one/CD
      ...
      according/VBG
      to/TO
      (NE Brooke/NNP T./NNP Mossman/NNP)
      ...)

|nopar| Both chunkers are trained based on the ACE-2 corpus.  This
corpus is not freely available, but a licence to use the corpus can be
purchased from the Linguistic Data Consortium (catalog id LDC2003T11).

-------------------
Relation Extraction
-------------------

When named entities have been identified in a text, we then want to extract
relations that hold between them. As indicated earlier, we will
typically be looking for relations between specified types of
named entity. One way of approaching this task is to initially look for all
triples of the form *X*, |alpha|, *Y*, where *X* and *Y* are named entities
of the required types, and |alpha| is the string of words that
intervenes between *X* and *Y*. We can then use regular expressions to
pull out just those instances of |alpha| that express the relation
that we are looking for. The following example searches for strings
that contain the word `in`:lx:. The special character expression
``(?!\b.+ing\b)`` is a negative lookahead condition that allows us to
disregard strings such as `success in supervising the transition
of`:lx:, where `in`:lx: is followed by a gerundive verb.

    >>> IN = re.compile(r'.*\bin\b(?!\b.+ing\b)')
    >>> for doc in nltk.corpus.ieer.parsed_docs('NYT_19980315'):
    ...     for rel in nltk.sem.extract_rels('ORG', 'LOC', doc, pattern = IN):
    ...         print nltk.sem.show_raw_rtuple(rel)
    [ORG: 'WHYY'] 'in' [LOC: 'Philadelphia']
    [ORG: 'McGlashan &AMP; Sarrail'] 'firm in' [LOC: 'San Mateo']
    [ORG: 'Freedom Forum'] 'in' [LOC: 'Arlington']
    [ORG: 'Brookings Institution'] ', the research group in' [LOC: 'Washington']
    [ORG: 'Idealab'] ', a self-described business incubator based in' [LOC: 'Los Angeles']
    [ORG: 'Open Text'] ', based in' [LOC: 'Waterloo']
    [ORG: 'WGBH'] 'in' [LOC: 'Boston']
    [ORG: 'Bastille Opera'] 'in' [LOC: 'Paris']
    [ORG: 'Omnicom'] 'in' [LOC: 'New York']
    [ORG: 'DDB Needham'] 'in' [LOC: 'New York']
    [ORG: 'Kaplan Thaler Group'] 'in' [LOC: 'New York']
    [ORG: 'BBDO South'] 'in' [LOC: 'Atlanta']
    [ORG: 'Georgia-Pacific'] 'in' [LOC: 'Atlanta']

Searching for the keyword works `in`:lx: reasonably well,
though it will also retrieve false positives such as ``[ORG: House
Transportation Committee] , secured the most money in the [LOC: New
York]``; there is unlikely to be simple string-based method of
excluding filler strings such as this.

.. TODO fix processing of tagged corpora
.. 

 As shown above, the ``conll2002`` Dutch corpus contains not just named entity
 annotation but also part-of-speech tags. In principle, this allows us
 to devise patterns that are sensitive to these tags.

.. doctest-ignore::
     >>> vnv = """
     ... (
     ... is/V|
     ... was/V|
     ... werd/V|
     ... wordt/V
     ... )
     ... .*
     ... van/Prep
     ... """
     >>> VAN = re.compile(vnv, re.VERBOSE)
     >>> for r in nltk.sem.extract_rels('PER', 'ORG', corpus='conll2002-ned', pattern=VAN): 
     ...     print show_tuple(r)



.. This is too weak to include:

    Message Understanding
    ---------------------
    
    A message understanding system
    will extract salient chunks of text from a news story and populate a
    database.
    
    .. figure:: ../images/chunk-muc.png
       :scale: 60
    
       The Message Understanding Process (from Abney 1996)
    
    Consider the units that have been selected in this process:
    a name (``Garcia Alvarado``), a verb cluster (``was killed``),
    a locative prepositional phrase (``on his vehicle``).  These
    are examples of ``NP``, ``VP`` and ``PP`` chunks.


----------
Conclusion
----------

In this chapter we have explored efficient and robust methods that can
identify linguistic structures in text.  Using only part-of-speech
information for words in the local context, a "chunker" can
successfully identify simple structures such as noun phrases and verb
groups.  We have seen how chunking methods extend the same lightweight
methods that were successful in tagging.  The resulting structured
information is useful in information extraction tasks and in the
description of the syntactic environments of words.  The latter will
be invaluable as we move to full parsing.

There are a surprising number of ways to chunk a sentence using
regular expressions.  The patterns can add, shift and remove chunks in
many ways, and the patterns can be sequentially ordered in many ways.
One can use a small number of very complex rules, or a long sequence
of much simpler rules.  One can hand-craft a collection of rules, and
one can write programs to analyze a chunked corpus to help in the
development of such rules.  The process is painstaking, but generates
very compact chunkers that perform well and that transparently encode
linguistic knowledge.

It is also possible to chunk a sentence using the techniques of n-gram
tagging.  Instead of assigning part-of-speech tags to words, we assign
IOB tags to the part-of-speech tags.  Bigram tagging turned out to be
particularly effective, as it could be sensitive to the chunk tag on
the previous word.  This statistical approach requires far less effort
than rule-based chunking, but creates large models and delivers few
linguistic insights.

Like tagging, chunking cannot be done perfectly.  For example, as
pointed out by [Abney1996PST]_, we cannot correctly analyze the structure
of the sentence *I turned off the spectroroute* without knowing the
meaning of *spectroroute*; is it a kind of road or a type of device?
Without knowing this, we cannot tell whether *off* is part of a
prepositional phrase indicating direction (tagged ``B-PP``), or
whether *off* is part of the verb-particle construction *turn off*
(tagged ``I-VP``).

A recurring theme of this chapter has been `diagnosis`:dt:.  The simplest
kind is manual, when we inspect the tracing output of a chunker and
observe some undesirable behavior that we would like to fix.
Sometimes we discover cases where we cannot hope to get the correct
answer because the part-of-speech tags are too impoverished and do not
give us sufficient information about the lexical item.  A second
approach is to write utility programs to analyze the training data,
such as counting the number of times a given part-of-speech tag occurs
inside and outside an ``NP`` chunk.  A third approach is to evaluate the
system against some gold standard data to obtain an overall
performance score.  We can even use this to parameterize the system,
specifying which chunk rules are used on a given run, and tabulating
performance for different parameter combinations.  Careful use of
these diagnostic methods permits us to optimize the performance of our
system.  We will see this theme emerge again later in chapters dealing
with other topics in natural language processing.

---------------
Further Reading
---------------

Consult |NLTK-URL| for further materials on this chapter.
For more examples of chunking with |NLTK|, please see the
Chunking HOWTO at |NLTK-HOWTO-URL|.

The popularity of chunking is due in great part to pioneering work by
Abney e.g., [Abney1996PST]_. Abney's Cass chunker is described in
``http://www.vinartus.net/spa/97a.pdf``.

The word `chink`:dt: initially meant a sequence of stopwords,
according to a 1975 paper by Ross and Tukey [Abney1996PST]_.

The IOB format (or sometimes  `BIO Format`:dt:) was developed for
``NP`` chunking by [Ramshaw1995TCU]_, and was used for the shared ``NP``
bracketing task run by the *Conference on Natural Language Learning*
(|CoNLL|) in 1999.  The same format was
adopted by |CoNLL| 2000 for annotating a section of Wall Street
Journal text as part of a shared task on ``NP`` chunking.

Section 13.5 of [JurafskyMartin2008]_ contains a discussion of chunking.
Chapter 22 covers information extraction, including named entity recognition.

.. Alexandria Gazetteer: http://www.alexandria.ucsb.edu/gazetteer

.. Getty Gazetteer

.. Other topics that use an IE approach: anaphora resolution
.. [Mitkov2002]_, question answering [Pasca2003]_.

---------
Exercises
---------

#. |easy| The IOB format categorizes tagged tokens as ``I``,
   ``O`` and ``B``.  Why are three tags necessary?  What
   problem would be caused if we used ``I`` and ``O`` tags
   exclusively?

#. |easy| Write a tag pattern to match noun phrases containing plural head nouns,
   e.g. "many/JJ researchers/NNS", "two/CD weeks/NNS", "both/DT new/JJ positions/NNS".
   Try to do this by generalizing the tag pattern that handled singular
   noun phrases.

#. |easy|
   Pick one of the three chunk types in the CoNLL corpus.
   Inspect the CoNLL corpus and try to observe any patterns in the POS tag sequences
   that make up this kind of chunk.  Develop a simple chunker using
   the regular expression chunker ``nltk.RegexpParser``.
   Discuss any tag sequences that are difficult to chunk reliably.

#. |easy|
   An early definition of *chunk* was the material that occurs between chinks.
   Develop a chunker that starts by putting the whole sentence in a single
   chunk, and then does the rest of its work solely by chinking.
   Determine which tags (or tag sequences) are most likely to make up chinks
   with the help of your own utility program.  Compare the performance and
   simplicity of this approach relative to a chunker based entirely on
   chunk rules.

#. |soso| Write a tag pattern to cover noun phrases that contain gerunds,
   e.g. "the/DT receiving/VBG end/NN", "assistant/NN managing/VBG editor/NN".
   Add these patterns to the grammar, one per line.  Test your work using
   some tagged sentences of your own devising.

#. |soso| Write one or more tag patterns to handle coordinated noun phrases,
   e.g. "July/NNP and/CC August/NNP",
   "all/DT your/PRP$ managers/NNS and/CC supervisors/NNS",
   "company/NN courts/NNS and/CC adjudicators/NNS".

#. |soso| Carry out the following evaluation tasks for
   any of the chunkers you have developed earlier.
   (Note that most chunking corpora contain some internal
   inconsistencies, such that any reasonable rule-based approach
   will produce errors.)

   a) Evaluate your chunker on 100 sentences from a chunked corpus,
      and report the precision, recall and F-measure.
   b) Use the ``chunkscore.missed()`` and ``chunkscore.incorrect()``
      methods to identify the errors made by your chunker.  Discuss.
   c) Compare the performance of your chunker to the baseline chunker
      discussed in the evaluation section of this chapter.

#. |soso|
   Develop a chunker for one of the chunk types in the CoNLL corpus using a
   regular-expression based chunk grammar ``RegexpChunk``.  Use any
   combination of rules for chunking, chinking, merging or splitting.

#. |soso| Sometimes a word is incorrectly tagged, e.g. the head noun in
   "12/CD or/CC so/RB cases/VBZ".  Instead of requiring manual correction of
   tagger output, good chunkers are able to work with the erroneous
   output of taggers.  Look for other examples of correctly chunked
   noun phrases with incorrect tags.

#. |soso|
   The bigram chunker scores about 90% accuracy.
   Study its errors and try to work out why it doesn't get 100% accuracy.
   Experiment with trigram chunking.  Are you able to improve the performance any more?

#. |hard|
   Apply the n-gram and Brill tagging methods to IOB chunk tagging.
   Instead of assigning POS tags to words, here we will assign IOB tags
   to the POS tags.  E.g. if the tag ``DT`` (determiner) often occurs
   at the start of a chunk, it will be tagged ``B`` (begin).  Evaluate
   the performance of these chunking methods relative to the regular
   expression chunking methods covered in this chapter.

#. |hard|
   We saw in chap-tag_ that it is possible to establish
   an upper limit to tagging performance by looking for ambiguous n-grams,
   n-grams that are tagged in more than one possible way in the training data.
   Apply the same method to determine an upper bound on the performance
   of an n-gram chunker.

#. |hard|
   Pick one of the three chunk types in the CoNLL corpus.  Write functions
   to do the following tasks for your chosen type:

   a) List all the tag sequences that occur with each instance of this chunk type.
   b) Count the frequency of each tag sequence, and produce a ranked list in
      order of decreasing frequency; each line should consist of an integer (the frequency)
      and the tag sequence.
   c) Inspect the high-frequency tag sequences.  Use these as the basis for
      developing a better chunker.

#. |hard|
   The baseline chunker presented in the evaluation section tends to
   create larger chunks than it should.  For example, the
   phrase:
   ``[every/DT time/NN] [she/PRP] sees/VBZ [a/DT newspaper/NN]``
   contains two consecutive chunks, and our baseline chunker will
   incorrectly combine the first two: ``[every/DT time/NN she/PRP]``.
   Write a program that finds which of these chunk-internal tags
   typically occur at the start of a chunk, then
   devise one or more rules that will split up these chunks.
   Combine these with the existing baseline chunker and
   re-evaluate it, to see if you have discovered an improved baseline.

#. |hard|
   Develop an ``NP`` chunker that converts POS-tagged text into a list of
   tuples, where each tuple consists of a verb followed by a sequence of
   noun phrases and prepositions,
   e.g. ``the little cat sat on the mat`` becomes ``('sat', 'on', 'NP')``...

#. |hard|
   The Penn Treebank contains a section of tagged Wall Street Journal text
   that has been chunked into noun phrases.  The format uses square brackets,
   and we have encountered it several times during this chapter.
   The Treebank corpus can be accessed using:
   ``for sent in nltk.corpus.treebank_chunk.chunked_sents(fileid)``.  These are flat trees,
   just as we got using ``nltk.corpus.conll2000.chunked_sents()``.

   a) The functions ``nltk.tree.pprint()`` and ``nltk.chunk.tree2conllstr()``
      can be used to create Treebank and IOB strings from a tree.
      Write functions ``chunk2brackets()`` and ``chunk2iob()`` that take a single
      chunk tree as their sole argument, and return the required multi-line string
      representation.
   b) Write command-line conversion utilities ``bracket2iob.py`` and ``iob2bracket.py``
      that take a file in Treebank or CoNLL format (resp) and convert it to the other
      format.  (Obtain some raw Treebank or CoNLL data from the NLTK Corpora, save it
      to a file, and then use ``for line in open(filename)`` to access it from Python.)

#. |hard|
   An n-gram chunker can use information other than the current
   part-of-speech tag and the `n-1`:math: previous chunk tags.
   Investigate other models of the context, such as
   the `n-1`:math: previous part-of-speech tags, or some combination of
   previous chunk tags along with previous and following part-of-speech tags.

#. |hard|
   Consider the way an n-gram tagger uses recent tags to inform its tagging choice.
   Now observe how a chunker may re-use this sequence information.  For example,
   both tasks will make use of the information that nouns tend to follow adjectives
   (in English).  It would appear that the same information is being maintained in
   two places.  Is this likely to become a problem as the size of the rule sets grows?
   If so, speculate about any ways that this problem might be addressed.

.. include:: footer.rst



.. Not used anymore:
    Identifying the boundaries of specific types of word sequences is also
    required when we want to recognize pieces of syntactic
    structure. Suppose for example that as a preliminary to named entity
    recognition, we have decided that it would be useful to just pick out
    noun phrases from a piece of text. To carry this out in a complete
    way, we would probably want to use a proper syntactic parser. But
    parsing can be quite challenging and computationally expensive |mdash|
    is there an easier alternative? The answer is Yes: we can look for
    sequences of part-of-speech tags in a tagged text, using one or more
    patterns that capture the typical ingredients of a noun phrase. 
    
