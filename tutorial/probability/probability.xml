<?xml version="1.0"?>
<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.2//EN"
"../../docbook/sgml/docbook/xml-dtd-4.2/docbookx.dtd" [
<!-- Base URL for the reference & tutorial documentation -->
<!ENTITY refdoc "../../api/public">
<!ENTITY tutdoc "..">

<!-- Index -->
<!ENTITY index SYSTEM "index.xml">

<!-- Copyright & License -->
<!ENTITY copyright SYSTEM "../copyright.xml">

<!-- Prompts for Python code samples -->
<!ENTITY prompt "<prompt>&gt;</prompt><prompt>&gt;</prompt><prompt>&gt;</prompt>">
<!ENTITY prompt2 "<prompt>...</prompt>">
]>

<article>
  <articleinfo>
    <author><firstname>Edward</firstname><surname>Loper</surname></author>
    <authorinitials>edl</authorinitials>
    <title>NLTK Tutorial: Probability</title>
    &copyright;
  </articleinfo>

  <section id="basics"> <title> Experiments and Samples </title>

    <para> The <literal>nltk.probability</literal> module can be used
    to model probablistic phenomena.  Most probablistic phenomena can
    be thought of as experiments.  An
    <glossterm>experiment</glossterm> is any process which leads to a
    well-defined outcome.  For example, rolling a die is an experiment
    whose possible outcomes are 1, 2, 3, 4, 5, and 6.
    </para>
    
    <para> A <glossterm>sample</glossterm> is any possible outcome of
    a given experiment.  In <literal>nltk.probability</literal>, any
    immutable Python value or object can be a sample.  Typical samples
    are strings, integers, <literal>Tokens</literal>, and tuples.  We
    can use a simple Python procedure to define the experiment of
    rolling a die; its samples are 1, 2, 3, 4, 5, and 6: </para>

<programlisting><![CDATA[
    >>> import random
    >>> def roll():
    ...     return random.choice( [1, 2, 3, 4, 5, 6] )
    >>> roll()
    4
    >>> roll()
    1
]]></programlisting>

  </section> <!-- Experiments and Samples -->

  <section id="FreqDist"> <title> Frequency Distributions </title>

    <para> A <glossterm>frequency distribution</glossterm> records the
    number of times each outcome of an experiment has occured.  For
    example, a frequency distribution could be used to record the
    frequency of each word type in a document.  Frequency
    distributions are encoded by the <ulink
    url="&refdoc;/nltk.probability.FreqDist-class.html"
    ><literal>FreqDist</literal></ulink> class, which is defined by
    the <ulink url="&refdoc;/nltk.probability-module.html"
    ><literal>nltk.probability</literal> module</ulink>. </para>

    <section id="FreqDist.constructing"> 
      <title> Constructing a Frequency Distribution </title>

      <para> The <ulink
      url="&refdoc;/nltk.probability.FreqDist-class.html#__init__"
      ><literal>FreqDist</literal> constructor</ulink> creates a new
      empty frequency distribution: </para>

<programlisting><![CDATA[
    >>> freq_dist = FreqDist()
    <FreqDist with 0 outcomes>
]]></programlisting>

      <para> Frequency distributions are generally initialized by
      repeatedly running an experiment, and incrementing the count for
      a sample every time it is an outcome of the experiment.  For
      example, the following code will produce a frequency
      distribution that records how often each word type occurs in a
      text: </para>

<programlisting><![CDATA[
    >>> freq_dist = FreqDist()
    >>> for token in document['SUBTOKENS']:
    ...     freq_dist.inc(token['TEXT'])
]]></programlisting>

    </section> <!-- Constructing a FreqDist -->

    <section id="FreqDist.using"> 
      <title> Using a Frequency Distribution </title>

      <para> Once we construct a frequency distribution that records
      the outcomes of an experiment, we can use it to examine a number
      of interesting properties of the experiment.  This section
      describes the most important accessors that are defined for
      frequency distributions. </para>

      <para> We can find the number of times a given sample occured
      with the <ulink url="&refdoc;/nltk.probability.FreqDist-class.html#count"
      ><literal>count</literal></ulink> method: 

<programlisting><![CDATA[
    # How many times did "the" occur?
    >>> freq_dist.count('the')
    6
]]></programlisting>
</para>

      <para> The <ulink url="&refdoc;/nltk.probability.FreqDist-class.html#freq"
      ><literal>freq</literal></ulink> method returns the frequency of
      a given sample: 

<programlisting><![CDATA[
    # What was the frequency of the word "the"?
    >>> freq_dist.freq('the')
    0.012
]]></programlisting>
</para>

      <para> We can find the total number of sample outcomes recorded
      by a frequency distribution with the <ulink
      url="&refdoc;/nltk.probability.FreqDist-class.html#N"
      ><literal>N</literal></ulink> method: 

<programlisting><![CDATA[
    # How many word tokens were counted? 
    >>> freq_dist.N()
    500
]]></programlisting>
</para>

      <para> The <ulink
      url="&refdoc;/nltk.probability.FreqDist-class.html#samples"
      ><literal>samples</literal></ulink> method returns a list of all
      samples that have been recorded as outcomes by a frequency
      distribution: 

<programlisting><![CDATA[
    # What word types were encountered? 
    >>> freq_dist.samples()
    ['happy', 'but', 'the', 'in', 'of', ...]
]]></programlisting>
</para>

      <para> We can find the sample with the greatest number of
      outcomes with the <ulink
      url="&refdoc;/nltk.probability.FreqDist-class.html#max"
      ><literal>max</literal></ulink> method:

<programlisting><![CDATA[
    >>> freq_dist.max()
    # What was the most common word? 
    'the'
]]></programlisting>
</para>

      <para> See the reference documentation for <ulink
      url="&refdoc;/nltk.probability.FreqDist-class.html"
      ><literal>FreqDistI</literal></ulink> for more information on
      how to use frequency distributions.</para>
    </section> <!-- Using Frequency Distributions -->

    <section id="FreqDist.example"> 
      <title> Example: Word Lengths </title>

      <para> In this section, we use a <literal>FreqDist</literal> to
      examine the distribution of word lengths in a corpus.  In
      particular, we find the distribution of word lengths for... </para>

      <itemizedlist>
        <listitem><para>All words in a corpus.</para></listitem>
        <listitem><para>Words that end in vowels.  </para></listitem>
        <listitem><para>Words following words that end in
        vowels.</para></listitem>
      </itemizedlist>

      <para> In each case, we construct a frequency distribution whose
      samples are word lengths; and plot the results. </para>

      <para> To begin, we import the classes we'll be using, and
      load a corpus from a text file:</para>

<programlisting><![CDATA[
    >>> from nltk.tokenizer import WhitespaceTokenizer 
    >>> from nltk.probability import FreqDist 
    >>> from nltk.draw.plot import Plot 

    >>> corpus = Token(TEXT=open('corpus.txt').read())
    >>> WhitespaceTokenizer().tokenize(corpus) 
]]></programlisting>

      <section id="FreqDist.example.question1">
        <title> All words in a corpus </title>

        <para> To find the first distribution, we examine each token
        in the corpus, and find the length of its text.  This length
        is the "outcome" for our experiment, so we use
        <literal>inc()</literal> to increment its count in a frequency
        distribution. </para>

<programlisting><![CDATA[
    # What is the distribution of word lengths in a corpus? 
    >>> freq_dist = FreqDist()
    >>> for token in corpus['SUBTOKENS']:
    ...     freq_dist.inc(len(token['TEXT']))
]]></programlisting>

        <para> To plot the results, we first create a sorted list of
        all word lengths that were encountered in the document.  We
        then construct a list of points, where the x coordinate is the
        word length, and the y coordinate is the frequency with which
        that word length is used: </para>

<programlisting><![CDATA[
    # Plot the results. 
    >>> wordlens = freq_dist.samples() 
    >>> wordlens.sort()
    >>> points = [(l, freq_dist.freq(l)) for l in wordlens]
    >>> Plot(points)
]]></programlisting>
        
        <!-- <note> <para> We are currently using a fairly simple class to
        plot functions.  We will likely replace it with a more
        advanced plotting system in the future. </para> </note> -->

      </section> <!-- Question 1 -->

      <section id="FreqDist.example.question2">
        <title> Words ending in vowels  </title>

        <para> For
        the second distribution, we only care about word lengths for
        words that end in vowels.  This specification of which word
        lengths we care about is known as a
        <glossterm>condition</glossterm>.  In the next section, we
        will explore ways of encoding the frequency distributions for
        a single experiment under a variety of related
        conditions. </para>

        <para> To find the second distribution, we examine each token
        in the corpus.  If it ends in a vowel, then we increment the
        count for its length in a frequency distribution. </para>

<programlisting><![CDATA[
    # For this example, we define vowels as "a", "e", "i", "o", and "u" 
    >>> VOWELS = ('a', 'e', 'i', 'o', 'u')

    # What is the distribution of word lengths for words that 
    # end in vowels? 
    >>> freq_dist = FreqDist()
    >>> for token in corpus['SUBTOKENS']:
    ...     if token['TEXT'][-1].lower() in VOWELS:
    ...         freq_dist.inc(len(token['TEXT']))

    # Plot the results 
    >>> wordlens = freq_dist.samples() 
    >>> wordlens.sort()
    >>> points = [(l, freq_dist.freq(l)) for l in wordlens]
    >>> Plot(points)
]]></programlisting>
      </section> <!-- Question 2 -->

      <section id="FreqDist.example.question3">
        <title> Words following words ending in vowels </title>

        <para> For the third distribution, we only care about word
        lengths for words following words that end in vowels.  We can
        use a boolean variable, <literal>ended_in_vowel</literal>, to
        keep track of this condition.  Initially, its value is zero;
        and after we examine each token, we update its value for use
        with the next token. </para>

<programlisting><![CDATA[
    # What is the distribution of word lengths for words following
    # words that end in vowels? 
    >>> ended_in_vowel = 0 # Did the last word end in a vowel?
    >>> freq_dist = FreqDist()
    >>> for token in corpus['SUBTOKENS']:
    ...     if ended_in_vowel: 
    ...         freq_dist.inc(len(token['TEXT']))
    ...     ended_in_vowel = token['TEXT'][-1].lower() in VOWELS 

    # Plot the results 
    >>> wordlens = freq_dist.samples() 
    >>> wordlens.sort()
    >>> points = [(l, freq_dist.freq(l)) for l in wordlens]
    >>> Plot(points)
]]></programlisting>

      </section> <!-- Question 3 -->
    </section> <!-- FreqDist Example -->
  </section> <!-- Frequency Distributions -->

  <section id="ConditionalFreqDist"> 
    <title> Conditional Frequency Distributions </title>
    
    <para> A <glossterm>condition</glossterm> specifies the context in
    which an experiment is performed.  Often, we are interested in the
    effect that conditions have on the outcome for an experiment.  For
    example, we might want to examine how the distribution of a word's
    length (the outcome) is affected by the word's initial letter (the
    condition).  Conditional frequency distributions provide a tool
    for exploring this type of question. </para>

    <para> A <glossterm>conditional frequency distribution</glossterm>
    is a collection of frequency distributions for the same
    experiment, run under different conditions.  The individual
    frequency distributions are indexed by the condition.  Conditional
    frequency distributions are represented using the <ulink
    url="&refdoc;/nltk.probability.ConditionalFreqDist-class.html"
    ><literal>ConditionalFreqDist</literal></ulink> class, which is
    defined by the
    <ulink url="&refdoc;/nltk.probability-module.html"
    ><literal>nltk.probability</literal> module</ulink>. </para>

    <para> The <ulink
    url="&refdoc;/nltk.probability.ConditionalFreqDist-class.html#__init__"
    ><literal>ConditionalFreqDist</literal> constructor</ulink> creates
    a new empty conditional frequency distribution: </para>

<programlisting><![CDATA[
    >>> cfdist = ConditionalFreqDist() 
    <ConditionalFreqDist with 0 conditions>
]]></programlisting>

    <para> To access the frequency distribution for a condition, use
    the <ulink
    url="&refdoc;/nltk.probability.ConditionalFreqDist-class.html#__getitem__">indexing
    operator</ulink>: </para>

<programlisting><![CDATA[
    >>> cfdist['a']
    <FreqDist with 0 outcomes>

    # Record the word lengths of some words starting with 'a'
    >>> for word in 'apple and arm'.split():
    ...     cfdist['a'].inc(len(word))

    # Of words starting with 'a', how many are 3 characters long?
    >>> cfdist['a'].freq(3)
    0.66667
]]></programlisting>

    <para> There is no need to explicitly specify the set of
    conditions used by a conditional frequency distribution.  Whenever
    you use the indexing operator to access the frequency distribution
    for a new condition, <literal>ConditionalFreqDist</literal>
    automatically creates a new empty <literal>FreqDist</literal> for
    it.  To list the conditions which have been accessed for a
    conditional frequency distribution, use the <ulink
    url="&refdoc;/nltk.probability.ConditionalFreqDist-class.html#conditions"
    ><literal>conditions</literal></ulink> method: </para>

<programlisting><![CDATA[
    >>> cfdist.conditions()
    ['a']
]]></programlisting>

    <section id="ConditionalFreqDist.initial_letter"> 
      <title> Example: Conditioning on a Word's Initial Letter </title>

      <para> In this section, we use a
      <literal>ConditionalFreqDist</literal> to examine how the
      distribution of a word's length is affected by the word's
      initial letter.  To begin, we import the classes we'll be using,
      load a corpus from a text file, and create an empty
      <literal>ConditionalFreqDist</literal>:</para>

<programlisting><![CDATA[
    >>> from nltk.tokenizer import WhitespaceTokenizer 
    >>> from nltk.probability import ConditionalFreqDist 
    >>> from nltk.draw.plot import Plot 

    >>> corpus = Token(TEXT=open('corpus.txt').read())
    >>> WhitespaceTokenizer().tokenize(corpus) 

    >>> cfdist = ConditionalFreqDist()
]]></programlisting>

      <para> We then examine each token in the corpus, and determine
      its initial letter (the condition) and its word length (the
      outcome).  We use the indexing operator to access the frequency
      distribution for the condition, and use the
      <literal>inc()</literal> method to increment its count for the
      outcome. </para>

<programlisting><![CDATA[
    # How does initial letter affect word length?
    >>> for token in corpus['SUBTOKENS']:
    ...     outcome = len(token['TEXT'])
    ...     condition = token['TEXT'][0].lower()
    ...     cfdist[condition].inc(outcome)
]]></programlisting>

      <para> We can construct a plot to show the frequency of various
      word lengths (outcomes) for a given intial letter (condition):
      </para>

<programlisting><![CDATA[
    # Plot the distribution of word lengths for words starting with 'a'
    >>> wordlens = cfdist['a'].samples() 
    >>> wordlens.sort()
    >>> points = [(l, cfdist['a'].freq(l)) for l in wordlens]
    >>> Plot(points)
]]></programlisting>

      <para> We can also construct a plot to show how the frequency of
      a word length (outcome) depends on the initial letter
      (condition): </para>

<programlisting><![CDATA[
    # Plot the frequency of 3-letter-words for each initial letter. 
    >>> conditions = cfdist.conditions() 
    >>> conditions.sort() 
    >>> points = [(ord(c), cfdist[c].freq(3)) for c in conditions] 
    >>> Plot(points)
]]></programlisting>

    </section> <!-- Example -->

    <section id="ConditionalFreqDist.predict"> 
      <title> Prediction </title>

      <para> Conditional frequency distributions are often used for
      prediction.  <glossterm>Prediction</glossterm> is the problem of
      deciding a likely outcome for a given run of an experiment.  The
      decision of which outcome to predict is usually based on the
      context in which the experiment is performed.  For example, we
      might try to predict a word's text (outcome), based on the text
      of the word that it follows (context). </para>

      <para> To predict the outcomes of an experiment, we first
      examine a representative <glossterm>training corpus</glossterm>,
      where the context and outcome for each run of the experiment are
      known.  When presented with a new run of the experiment, we
      simply choose the outcome that occured most frequently for the
      experiment's context. </para>

      <para> We can use a <literal>ConditionalFreqDist</literal> to
      find the most frequent occurance for each context.  First, we
      record each outcome in the training corpus, using the context
      that the experiment was run under as the condition.  Then, we
      can access the frequency distribution for a given context with
      the indexing operator, and use the <literal>max()</literal>
      method to find the most likely outcome. </para>

      <section id="ConditionalFreqDist.predict.example">
        <title> Example: Predicting Words </title>

        <para> In this section, we use a
        <literal>ConditionalFreqDist</literal> to predict a word's
        text, based on the text of the word that it follows.  To
        begin, we load a corpus from a text file, and create an empty
        <literal>ConditionalFreqDist</literal>:</para>

<programlisting><![CDATA[
    >>> from nltk.tokenizer import WhitespaceTokenizer 
    >>> from nltk.probability import ConditionalFreqDist 

    >>> corpus = Token(TEXT=open('corpus.txt').read())
    >>> WhitespaceTokenizer().tokenize(corpus)

    >>> cfdist = ConditionalFreqDist()
]]></programlisting>

        <para> We then examine each token in the corpus, and increment
        the appropriate sample's count.  We use the variable
        <literal>context</literal> to record the text of the
        preceeding word.  </para>

<programlisting><![CDATA[
    >>> context = None  # The text of the preceeding word
    >>> for token in corpus['SUBTOKENS']:
    ...     outcome = token['TEXT']
    ...     cfdist[context].inc(outcome)
    ...     context = token['TEXT']
]]></programlisting>

        <note> 
          <para> Sometimes the context for an experiment is
          unavailable, or does not exist.  For example, the first
          token in a text does not follow any word.  In these cases,
          we must decide what context to use.  For this example, we
          use <literal>None</literal> as the context for the first
          token.  Another option would be to simply discard the first
          token. </para>
        </note>

        <para> Once we have constructed a conditional frequency
        distribution for the training corpus, we can use it to find
        the most likely word for any given context: </para>

<programlisting><![CDATA[
    >>> cfdist['prediction'].max() 
    'problems'
    >>> cfdist['problems'].max() 
    'in'
    >>> cfdist['in'].max() 
    'the'
]]></programlisting>

        <para> We can set up a simple loop to generate text, by using
        the most likely token for each word as the context for the
        next word: </para>

<programlisting><![CDATA[
    >>> word = 'prediction' 
    >>> for i in range(15): 
    ...     print word, 
    ...     word = cfdist[word].max()
    prediction problems in the frequency distribution of the 
    frequency distribution of the frequency distribution of
]]></programlisting>

        <note> <para> This simple approach to text generation tends to
        get stuck in loops, as demonstrated by the text generated
        above.  A more advanced approach would be to randomly choose
        each word, with more frequent words chosen more often. </para>
        </note>

        <para> Some of the contexts that we are interested in may not
        be represented in the training corpus.  For example, if the
        training corpus does not contain the word "mango," then the
        conditional frequency distribution cannot predict which words
        are likely to follow it.  If a conditional frequency
        distribution has no information about a context, then the
        <literal>max</literal> method of that context's distribution
        returns <literal>None</literal>. </para>
        
<programlisting><![CDATA[
    >>> cfdist['mango'] 
    None
]]></programlisting>

      </section> <!-- Example -->

    </section> <!-- Predicting -->

  </section> <!-- ConditionalFreqDist -->

  <section id="ProbDist"> 
    <title> Probability Distributions </title>

    <para> A <glossterm>probability distribution</glossterm> specifies
    the likelihood of each outcome for a given experiment.  For
    example, consider the experiment defined by
    <literal>roll2</literal>: </para>

<programlisting><![CDATA[
    >>> import random
    >>> def roll2():
    ...     return (random.choice([1, 2, 3, 4, 5, 6]) +
    ...             random.choice([1, 2, 3, 4, 5, 6]))
]]></programlisting>

    <para> A probability distribution for this experiment specifies
    the probability for each of its outcomes (2-12).  The probability
    of outcome <replaceable>x</replaceable> is written
    P(<replaceable>x</replaceable>), and is equal to the proportion of
    the time that outcome will be generated, on average.  For example,
    P(2) is 1/36, since <literal>roll2</literal> generates the outcome
    2 one time in 36, on average.  The probabilities for each of
    <literal>roll2</literal>'s outcomes are: </para>

    <informaltable>
      <tgroup cols="12">
        <thead>
          <row>
            <entry>Outcome</entry>
            <entry>2</entry><entry>3</entry><entry>4</entry>
            <entry>5</entry><entry>6</entry><entry>7</entry>
            <entry>8</entry><entry>9</entry><entry>10</entry>
            <entry>11</entry><entry>12</entry>
          </row>
        </thead>
        <tbody cols="12">
          <row>
            <entry>Probability</entry>
            <entry>1/36</entry><entry>2/36</entry><entry>3/36</entry>
            <entry>4/36</entry><entry>5/36</entry><entry>6/36</entry>
            <entry>5/36</entry><entry>4/36</entry><entry>3/36</entry>
            <entry>2/36</entry><entry>1/36</entry>
          </row>
        </tbody>
      </tgroup>
    </informaltable>

    <!--    <para> To see why each outcome has the probability listed above,
    look at <literal>roll2</literal>.  Each time
    <literal>roll2</literal> is run, it generates two random numbers,
    and returns their sum.  There are 36 possible combinations of the
    two random numbers, and on average, each of those combinations
    will be chosen one time in 36.  So the probability for each
    outcome is the number of combinations that give that outcome,
    divided by 36.  For example, the outcome 2 can only be generated
    by one combination: 1+1; so its probability is 1/36.  But the
    outcome 11 can be generated by two combinations: 5+6 and 6+5; so
    its probability is 2/36. </para> -->

    <section id="ProbDist.ProbDistI">
    <title> The ProbDistI Interface </title>
    
    <para> The <ulink url="&refdoc;/nltk.probability-module.html"
    ><literal>nltk.probability</literal></ulink> module defines the
    <ulink url="&refdoc;/nltk.probability.ProbDistI-class.html"
    ><literal>ProbDistI</literal></ulink> interface for modeling
    probability distributions.  Classes that implement the probability
    distribution interface must define three methods: </para>

    <itemizedlist>
      <listitem> <para> <ulink
      url="&refdoc;/nltk.probability.ProbDistI-class.html#prob"><literal>prob</literal></ulink>
      returns the probability for a given sample. </para> </listitem>
      <listitem> <para> <ulink
      url="&refdoc;/nltk.probability.ProbDistI-class.html#max"><literal>max</literal></ulink>
      returns the sample with the greatest probability. </para>
      </listitem> <listitem> <para> <ulink
      url="&refdoc;/nltk.probability.ProbDistI-class.html#samples"><literal>samples</literal></ulink>
      returns a list of all samples that have nonzero
      probability. </para> </listitem>
    </itemizedlist>

<programlisting><![CDATA[
    >>> pdist.prob('an')
    0.04
    >>> pdist.max()
    'the'
    >>> pdist.samples()
    ['the', 'an', 'a']
]]></programlisting>

    </section> <!-- ProbDistI -->
    <section id="ProbDist.estimate">
      <title> Estimating Probabilities for an Experiment</title>

      <para> Probability distributions are often used to estimate the
      likelihood of each sample outcome for an experiment.  Typically,
      we create a frequency distribution by running the experiment on
      training data; and then use the frequency distribution to
      estimate the experiment's probability distribution. </para>

      <para> The simplest estimate for
      an experiment's probability distribution is the
      <glossterm>Maximum Likelihood Estimate</glossterm> (MLE), which
      approximates the probability for each sample as the frequency
      with which it occured in the training data: </para>

      <itemizedlist>
        <listitem>
          <para>P(<replaceable>x</replaceable>) =
	  <literal>freq_dist.freq(<replaceable>x</replaceable>)</literal></para>
        </listitem>
      </itemizedlist>

      <para> The Maximum Likelihood Estimate is implemented by the
      <ulink url="&refdoc;/nltk.probability.MLEProbDist-class.html"
      ><literal>MLEProbDist</literal></ulink> class.  The <ulink
      url="&refdoc;/nltk.probability.MLEProbDist-class.html#__init__"
      ><literal>MLEProbDist</literal> constructor</ulink> takes a
      frequency distribution, and creates the corresponding MLE
      probability distribution. </para>

<programlisting><![CDATA[
    >>> prob_dist = MLEProbDist(freq_dist)
    <MLEProbDist based on 825 outcomes>

    # P(x) = freq(x)
    >>> prob_dist.prob('the')
    0.42
    >>> freq_dist.freq('the')
    0.42
]]></programlisting>

    <section id="ProbDist.roll2">
      <title> Example: Estimating the Probability Distribution for
      <literal>roll2</literal></title>

      <para> To estimate the probability distribution of
      <literal>roll2</literal>, we first construct a frequency
      distribution: </para>
    
<programlisting><![CDATA[
    # How often does each outcome of roll2 occur?
    >>> freq_dist = FreqDist() 
    >>> for i in range(500): 
    ...     freq_dist.inc(roll2()) 
]]></programlisting>

    <para> We then use <literal>MLEProbDist</literal> to estimate
    <literal>roll2</literal>'s probability distribution: </para>
    
<programlisting><![CDATA[
    # Estimate the probability distribution of roll2
    >>> prob_dist = MLEProbDist(freq_dist) 
    <MLEProbDist based on 500 outcomes>
]]></programlisting>

    <para> Finally, we can query the probability distribution to find
    the probability for each outcome: </para>

<programlisting><![CDATA[
    # What's the likelihood that roll2 will return 2?
    >>> print prob_dist.prob(2) 
    0.02

    # What's the likelihood that roll2 will return 6?
    >>> print prob_dist.prob(6) 
    0.162
]]></programlisting>
    </section> <!-- example -->

    <section id="ProbDist.mleprobs">
      <title> Problems with MLE </title>

      <para> Although MLE is the simplest probability distribution, it
      has a tendency to over-estimate the probabilities of sample
      outcomes that only occur a few times (and to under-estimate the
      probabilities of samples that never occur).  To see this
      problem, compare the probability distribution created in the
      previous example with the actual probability distribution for
      <literal>roll2</literal>: </para>

    <informaltable>
      <tgroup cols="12">
        <thead>
          <row>
            <entry>Outcome</entry>
            <entry>2</entry><entry>3</entry><entry>4</entry>
            <entry>5</entry><entry>6</entry><entry>7</entry>
            <entry>8</entry><entry>9</entry><entry>10</entry>
            <entry>11</entry><entry>12</entry>
          </row>
        </thead>
        <tbody cols="12">
          <row>
            <entry>Estimated Probability</entry>
            <entry>0.020</entry><entry>0.050</entry><entry>0.090</entry>
            <entry>0.126</entry><entry>0.162</entry><entry>0.170</entry>
            <entry>0.126</entry><entry>0.086</entry><entry>0.108</entry>
            <entry>0.42</entry><entry>0.020</entry>
          </row>
          <row>
            <entry>Actual Probability</entry>
            <entry>0.028</entry><entry>0.056</entry><entry>0.083</entry>
            <entry>0.111</entry><entry>0.139</entry><entry>0.167</entry>
            <entry>0.139</entry><entry>0.111</entry><entry>0.083</entry>
            <entry>0.056</entry><entry>0.028</entry>
          </row>
        </tbody>
      </tgroup>
    </informaltable>

    <para> These estimation errors become especially pronounced when
    some samples occur much less frequently than others.  For example,
    if we were to estimate the probabilities of word types in a text,
    then our frequency distribution would likely contain many samples
    that only occur once; and MLE would provide poor estimates for
    these samples' probabilities. </para>

    </section> <!-- probs with mle -->    
    <section id="ProbDist.other">
      <title> Other Probability Distributions</title>

    <para> NLTK defines a number of probability distributions that can
    produce better probability estimates from frequency distributions.
    Currently, the probability module defines the following
    probability distributions: </para>

    <itemizedlist>
      <listitem> <para> <ulink
      url="&refdoc;/nltk.probability.LaplaceProbDist-class.html"
      ><literal>LaplaceProbDist</literal></ulink> </para></listitem>
      <listitem> <para> <ulink
      url="&refdoc;/nltk.probability.ELEProbDist-class.html"
      ><literal>ELEProbDist</literal></ulink> </para></listitem>
      <listitem> <para> <ulink
      url="&refdoc;/nltk.probability.LidstoneProbDist-class.html"
      ><literal>LidstoneProbDist</literal></ulink> </para></listitem>
      <listitem> <para> <ulink
      url="&refdoc;/nltk.probability.HeldoutProbDist-class.html"
      ><literal>HeldoutProbDist</literal></ulink> </para></listitem>
      <listitem> <para> <ulink
      url="&refdoc;/nltk.probability.CrossValidationProbDist-class.html"
      ><literal>CrossValidation</literal></ulink> </para></listitem>
    </itemizedlist>
    
    <para> For more information, see the "Probability Estimation
    Tutorial" (under construction), or the reference documentation for
    each probability distribution. </para>
    
      </section> <!-- other prob dists -->
      
    </section> <!-- estimating probdists -->

  </section> <!-- Probability Distributions -->

  <section id="ConditionalProbDist"> 
    <title> Conditional Probability Distributions </title>
    
    <para> A <glossterm>conditional
    probability distribution</glossterm> is a collection of
    probability distributions for the same experiment, run under
    different conditions.  The individual probability distributions
    are indexed by the condition.  Conditional probability
    distributions are useful for examining the effect that a condition
    has on an experiment's probability distribution.  For example, we
    could use a conditional probability distribution to examine how a
    word's initial letter (the condition) affects the probability
    distribution of the word's length (the outcome). </para>

    <para> The <ulink url="&refdoc;/nltk.probability-module.html"
    ><literal>nltk.probability</literal></ulink> module defines the
    <ulink
    url="&refdoc;/nltk.probability.ConditionalProbDistI-class.html"
    ><literal>ConditionalProbDistI</literal></ulink> interface for
    modeling conditional probability distributions.  Classes that
    implement the conditional probability distribution interface must
    define two methods: <literal>conditions</literal>; and the
    indexing operator. </para>
    
    <para> The <ulink
    url="&refdoc;/nltk.probability.ConditionalProbDistI-class.html#conditions"
    ><literal>conditions</literal></ulink> method
    returns a list of the conditions that are represented by the
    conditional probability distribution: </para>

<programlisting><![CDATA[
    # What are the conditions we've seen? 
    >>> cpdist.conditions()
    ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i',
     'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r',
     's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
]]></programlisting>
    
    <para> The <ulink
    url="&refdoc;/nltk.probability.ConditionalProbDistI-class.html#__getitem__"
    >indexing operator</ulink> returns the probability distribution
    for the experiment run under the given condition: </para>

<programlisting><![CDATA[
    # Get the probability distribution of word lengths for 
    # words starting with the letter "c"
    >>> cpdist['c']
    <MLEProbDist based on 87 outcomes>
    
    # Examine the probability distribution. 
    >>> cpdist['c'].samples()
    [3, 4, 5, 7, 8]
    >>> cpdist['c'].prob(3)
    0.13
]]></programlisting>

    <section id="ConditionalProbDist.creating">
      <title> Creating Conditional Probability Distributions </title>

      <para> The <ulink
      url="&refdoc;/nltk.probability.ConditionalProbDist-class.html"
      ><literal>ConditionalProbDist</literal></ulink> class is used to
      construct conditional probability distributions from conditional
      frequency distributions.  A
      <literal>ConditionalProbDist</literal> is constructed from a
      conditional frequency distribution and a
      <literal>ProbDist</literal> factory: </para>

      <itemizedlist>
        <listitem><para> The conditional frequency distribution
        specifies the frequency distribution for each
        condition. </para></listitem>
        <listitem><para> The <glossterm><literal>ProbDist</literal>
        factory</glossterm> creates the probability distribution for a
        condition, given the frequency distribution for that
        condition. </para></listitem>
      </itemizedlist>

      <para> The <literal>ProbDist</literal> factory is typically a
      probability distribution class, such as
      <literal>MLEProbDist</literal>. </para>

      <para> Conditional probability distributions are created with
      the <ulink
      url="&refdoc;/nltk.probability.ConditionalProbDist-class.html#__init__"
      ><literal>ConditionalProbDist</literal> constructor</ulink>,
      which takes a conditional frequency distribution and a
      <literal>ProbDist</literal> factory: </para>
      
<programlisting><![CDATA[
    # Construct a conditional probability distribution from
    # the conditional frequency distribution cfdist.
    >>> cpdist = ConditionalProbDist(cfdist, MLEProbDist)
    <ConditionalProbDist with 26 conditions>
]]></programlisting>

      <para> If the <literal>ProbDist</literal> factory takes
      additional arguments, then they can be supplied to the
      <literal>ConditionalProbDist</literal> constructor.  For
      example, the <literal>ELEProbDist</literal> constructor takes an
      extra argument, specifying the number of possible sample
      outcomes that are possible.  If this argument is supplied to the
      <literal>ConditionalProbDist</literal> constructor, then it will
      be passed on to <literal>ELEProbDist</literal> when it is used
      to create the probability distribution for each condition:
      </para>

<programlisting><![CDATA[
    # Convert the frequency distribution for each condition
    # to a probability distribution using the Expected
    # Likelihood estimate, with 10 possible sample outcomes 
    # for each condition.
    >>> cpdist = ConditionalProbDist(cfdist, ELEProbDist, 10)
    <ConditionalProbDist with 26 conditions>
]]></programlisting>

    </section> <!-- creating Conditional Probability Distributions -->

    <!-- Example: probability of a sentence -->
    
  </section> <!-- Conditional Probability Distributions -->

  &index;
</article>
