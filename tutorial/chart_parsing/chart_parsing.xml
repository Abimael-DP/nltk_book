<?xml version="1.0"?>
<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.2//EN"
"../../docbook/sgml/docbook/xml-dtd-4.2/docbookx.dtd" [
<!-- Base URL for the reference & tutorial documentation -->
<!ENTITY refdoc "../../api/public">
<!ENTITY tutdoc "..">

<!-- Index -->
<!ENTITY index SYSTEM "index.xml">

<!-- Copyright & License -->
<!ENTITY copyright SYSTEM "../copyright.xml">

<!-- Prompts for Python code samples -->
<!ENTITY prompt "<prompt>&gt;</prompt><prompt>&gt;</prompt><prompt>&gt;</prompt>">
<!ENTITY prompt2 "<prompt>...</prompt>">
]>

<article>
  <articleinfo>
    <author><firstname>Steven</firstname><surname>Bird</surname></author>
    <authorinitials>sb</authorinitials>
    <author><firstname>Edward</firstname><surname>Loper</surname></author>
    <authorinitials>edl</authorinitials>
    <title>NLTK Tutorial: Chart Parsing</title>
    &copyright;
  </articleinfo>

<!--  <section> <title> Introduction </title>

    <para></para>

X.1 introduction: motivation, background, history
    - why is this an interesting problem for CL?

  </section>

    <section> <title> Linguistic Overview </title>

    <para></para>

X.2 linguistic overview (for non-linguist readers)
    - how have linguists addressed the problem?
    - what are the shortcomings of the non-computational approach?

    </section>

    <section> <title> Computational Approaches to Chart Parsing </title>

    <para></para>

X.3 computational model (gentle for linguistics ugrads)
    - what are some good data structures and algorithms?
    - just pick one or two approaches, not encyclopedic
    - NLTK demo - watch the execution of the algorithm
      (screen shots to show execution, side bars to say how
       to do it)

    </section>

    <section> <title> Advanced Topics in Chart Parsing (optional) </title>

    <para></para>

X.4 advanced topics (optional)
    - other approaches, evaluation, problems
    - challenges for particular languages / language families
    - research questions

    </section>

    <section> <title> Chart Parsing in NLTK </title>

X.5 implementation
    - how does NLTK do it?
    - simple problems and worked solutions
    - suggested projects (e.g. for your MSc students)
-->

<!--  <section> <title> Chart Parsing </title>-->
   <section id="intro"> <title> Introduction </title>

    <para>The simple parsers discussed in <ulink
    url="&tutdoc;/parsing">the parsing tutorial</ulink> suffer from
    some significant problems.  The bottom-up shift-reduce parser can
    only find one parse, and it often fails to find a parse even if
    one exits.  The top-down recursive-descent parser can be very
    inefficient, since it often builds and discards the same
    sub-structure many times over; and if the grammar contains
    left-recursive rules, it can enter into an infinite loop. </para>

    <para> These completeness and efficiency problems can be addressed
    by employing a technique called <glossterm>dynamic
    programming</glossterm>, which stores intermediate results, and
    re-uses them when appropriate.  For parsing </para>

    <para>In general, a parser hypothesizes constituents based on the
    grammar and on the current state of its knowledge about the
    constituents which are already attested.  Any given constituent
    may be proposed during the search of a blind alley; there is no
    way of knowing at the time whether the constituent will be used in
    any of the final parses which are reported.  Locally, what we know
    about a constituent is the production which licenses its node and
    immediate daughter nodes (i.e. the "local tree").  Also, in the
    case of chart parsing, we know the whole subtree of this node, how
    it connects to the tokens of the sentence being parsed, and its
    span within the sentence (i.e. location).  In a chart parser,
    these three things: rule, subtree and location, are stored in a
    special structure called an edge.</para>

    <section id="edges"> <title> Edges </title>

      <para> Consider a sequence of word tokens, e.g. <emphasis>the park</emphasis>.
      The space character between the two tokens is a shared boundary.  There are
      further token boundaries at the start and end of the sequence.  We can
      make these boundaries explicit like this:
      <emphasis>&bull; the &bull; park &bull; </emphasis>.
      Now think of these bullets as nodes in a graph.  Each word can be thought
      of as an edge connecting two nodes.  In NLTK we can create edges from tokens
      as follows:</para>

<programlisting>
    <emphasis># import chart parser module: </emphasis>
    &prompt;<command> from nltk.parser.chart import * </command>

    <emphasis># create some token edges: </emphasis>
    &prompt;<command> tokens = [Token('the', Location(0)), Token('park', Location(1))] </command>
    &prompt;<command> edge0 = TokenEdge(tokens[0]) </command>
    &prompt;<command> edge1 = TokenEdge(tokens[1]) </command>

    <emphasis># now create a container for the edges: </emphasis>
    &prompt;<command> chart = Chart(Location(0,2)) </command>
    &prompt;<command> chart.insert(edge0) </command>
    &prompt;<command> chart.insert(edge1) </command>
    &prompt;<command> print chart.pp() </command>
    |[--]  .| 'the'@[0] -> * 
    |.  [--]| 'park'@[1] -> * 
</programlisting>

      <para>These edges are <literal>TokenEdge</literal>s since each edge
      correspond to exactly one token.  However, we can generalize
      the notion of an edge to span more than one token.  Consider again
      our words and boundary markers:
      <emphasis>&bull; the &bull; park &bull; </emphasis>.  In addition to
      the two token edges discussed above, we can have a third edge which connects
      the initial and final boundaries, spanning two tokens.  This edge could
      represent a noun phrase constituent.</para>

<programlisting>
    <emphasis># create a treetoken using the tokens: </emphasis>
    &prompt;<command> tree = TreeToken('NP', tokens[0], tokens[1]) </command>
    ('NP': 'the' 'park')@[0:2]

    <emphasis># get the location of this treetoken: </emphasis>
    &prompt;<command> loc = tree.loc() </command>
    @[0:2]

    <emphasis># create the corresponding grammar production: </emphasis>
    &prompt;<command> prod = CFGProduction(Nonterminal('NP'), 'the', 'park') </command>
    NP -> 'the' 'park'

    <emphasis># now construct the new edge spanning both locations and insert: </emphasis>
    &prompt;<command> edge2 = ProductionEdge(prod, tree, loc, 2) </command>
    &prompt;<command> chart.insert(edge2) </command>
    &prompt;<command> print chart.pp() </command>
    |[--]  .| 'the'@[0] -> * 
    |.  [--]| 'park'@[1] -> * 
    |[=====]| NP -> 'the' 'park' 
</programlisting>

    <warning>
      <para> The rest of this tutorial is out of date; for an up-to-date
      explanation of chart parsing, see the reference documentation
      for the <ulink url="&refdoc;/nltk.parser.chart-module.html"
      ><literal>nltk.parser.chart</literal></ulink> module, which
      defines the chart parser. </para>

      <para> You may also want to explore the chart parser graphical
      demonstration tool, which supports interactive application of
      rules and strategies to a chart parser.  The chart parser demo
      can be invoked from within Python with the following commands:
      </para>

<programlisting>
&prompt; <command> import nltk.draw.chart</command>
&prompt; <command> nltk.draw.chart.demo()</command>
</programlisting>
      
    </warning>

      <para>The purpose of an edge is to store a <emphasis>hypothesis</emphasis>
      about the syntactic structure of the sentence.  Such hypotheses may be
      either complete or partial.  A complete hypothesis is represented as an
      edge decorated with a <literal>DottedRule</literal> where the dot position is
      on the right edge of the rule.  This means that the entire right-hand side
      has been processed and that the associated <literal>TreeToken</literal> is
      complete.  A partial hypothesis is represented as an edge decorated with
      a rule where the dot position is in an internal position, e.g.
      <literal>NP -&gt; Det * N</literal>.  This means that only part of the
      right-hand side has been processed and that the associated tree is
      incomplete.  The symbol immediately to the right of the
      dot position is the next symbol (terminal or non-terminal) to be processed for
      this edge.</para>

      <para>There is a special case where edges have zero width.  Such an edge is
      actually a self-loop, starting and ending at the same index position.
      Zero-width edges represent the hypothesis that a syntactic constituent
      <emphasis>begins</emphasis> at this location.</para>

      <para>In the process of chart parsing, edges are combined with other edges to
      form new edges which are then added to the chart.  Note that nothing is ever
      removed from the chart, and nothing is ever modified once it is in the chart.
      </para>

    </section> <!-- Edges -->

    <section id="charts"> <title> Charts </title>

      <para>A chart is a set of edges and a location.  The edge set represents
      the state of a chart parser during processing, and new edges can be inserted
      into the set at any time.  Once entered, an edge cannot be modified or
      removed.  The chart also stores a location.  This represents the combined
      span of the list of input tokens.  The chart uses this information
      in order to return edges which span the entire sentence.</para>

      <para>In NLTK, a chart is implemented by the
      <ulink url="http://nltk.sourceforge.net/ref/nltk.chartparser.Chart.html">Chart</ulink>
      class.  Full details of the methods are available online.  The key
      methods to note are <literal>insert</literal> and <literal>parses</literal>.
      </para>

    </section> <!-- Charts -->

    <section id="rules"> <title> Chart Rules and Parsing Strategies </title>

      <para>The
      <ulink url="http://nltk.sourceforge.net/ref/nltk.chartparser.ChartParserStrategy.html">ChartParserStrategy</ulink>
      class encodes the list of rules used by a chart parser to specify the
      conditions under which new edges should be added to the chart.
      There are two kinds of chart rules:</para>

      <itemizedlist>
        <listitem><para>Static Rules: these search the chart for specific contexts
          where edges should be added.  The parse method will
          repeatedly invoke each static rule, until it produces no
          new edges.</para></listitem>
        <listitem><para>Edge Triggered Rules: these add new edges
          to the chart whenever certain kinds of edges are added by any chart rule.
        </para></listitem>
      </itemizedlist>

      <para>A <literal>ChartParserStrategy</literal> consists of a list of
      static rules and a list of edge triggered rules.</para>
          
      <para>Chart rules are defined using functions, which return a list of
      new edges to add to a chart.  These functions should <emphasis>not</emphasis>
      directly modify the chart (e.g., do not add the edges to the chart
      yourself; C{ChartParser} will add them for you).  Static rules
      are defined with functions of the form:</para>

<programlisting>
def static_rule(chart, grammar, basecat):
    # Decide which edges to add (if any)
    return edges
</programlisting>

      <para>where <literal>chart</literal> is the chart that the static rule should act
      upon; <literal>grammar</literal> is the grammar used by the chart parser; and
      <literal>basecat</literal> is the top-level category of the grammar (e.g. 'S').
      The function should return a list of edges.  These edges
      will be added to the chart by the chart parser.</para>
            
      <para>Edge triggered rules are defined with functions of the form:</para>

<programlisting>
def edge_triggered_rule(chart, grammar, basecat, edge):
    # Decide which edges to add (if any)
    return edges
</programlisting>

      <para>
      Where the arguments are as before, and where <literal>edge</literal> is
      the edge that triggered this rule.  As before, the function
      should return a list of edges, and these will be added to
      the chart by the chart parser.</para>

      <para>The main kinds of chart rules are enumerated and discussed below:</para>

      <section id="rules.init"> <title> Chart Initialization </title>

        <para>The first step in parsing a tokenized sentence is to initialize
        the chart with word edges.  For each lexical rule which expands to a given
        word, a corresponding edge is created.  This edge hosts a complete
        dotted rule (e.g. <literal>Det -&gt; 'the' *</literal>), a simple treetoken
        containing the syntactic structure, and a location equal to the location
        of the original token.</para>

      </section> <!-- Chart Initialization -->

      <section id="rules.fr"> <title> Fundamental Rule </title>

        <para>
        The most important way that edges are combined is known as the
        <emphasis>Fundamental Rule</emphasis>.  Suppose that an edge
        <replaceable>e<subscript>1</subscript></replaceable> has a dotted
        rule whose next symbol is <replaceable>X</replaceable>.  Suppose that
        a second edge <replaceable>e<subscript>2</subscript></replaceable>,
        immediately to the right of
        <replaceable>e<subscript>1</subscript></replaceable>,
        represents a complete <replaceable>X</replaceable> constituent.
        Then the Fundamental Rule states that we must add a new edge
        <replaceable>e<subscript>3</subscript></replaceable> spanning both
        <replaceable>e<subscript>1</subscript></replaceable> and
        <replaceable>e<subscript>2</subscript></replaceable>, in which
        the dot is moved one position to the right.  In other words,
        <replaceable>e<subscript>1</subscript></replaceable> was looking for
        an <replaceable>X</replaceable> to its right, which it found on
        <replaceable>e<subscript>2</subscript></replaceable>, and we record
        this fact on <replaceable>e<subscript>3</subscript></replaceable>.
        </para>

        <para>The <literal>Edge</literal> class has a
        <ulink url="http://nltk.sourceforge.net/ref/nltk.chartparser.Edge.html#FR"
        ><literal>FR</literal></ulink> method which applies the fundamental
        rule to a pair of edges.  The operation of the rule is
        accomplished in four lines:</para>

<programlisting>
def FR(self, edge):
    loc = self._loc.union(edge.loc())
    dr = self._drule.shift()
    tree = TreeToken(self._tree.node(), *(self._tree.children() + (edge.tree(),)))
    return Edge(dr, tree, loc)                                                       
</programlisting>

        <para>First we create a new location which is the union of the locations
        of the two existing edges.  Next we create a new dotted rule, just the same
        as the existing one but with the dot position shifted one to the right.
        Next we take the existing tree <literal>self._tree</literal>, break it
        apart, and incorporate the tree from the other edge.  Finally, we construct
        a new edge from the new dotted rule, new tree, and new location.</para>

        <para>This rule is called many times by
        <literal>chartparser.FR()</literal>, as it considers all pairs of
        adjacent edges and all grammar rules.</para>

<programlisting>
def FR(chart, grammar, basecat):
    added = []
    for edge in chart.edges(): # try every edge
        if not edge.complete(): # only do incomplete ones
            for edge2 in chart.complete_edges(): # next edge complete?
                if (edge.drule().next() == edge2.drule().lhs() and
                    edge.end() == edge2.start()):
                    new_edge = edge.FR(edge2)
                    added += [new_edge]
    return added
</programlisting>

    </section> <!-- Fundamental Rule -->

    <section id="rules.td"> <title> Top Down Initialization </title>

      <para>Top down parsing is initialized by creating a zero-width
      (or self-loop) edges at the leftmost position in the chart.
      For every grammar rule whose left-hand side is the base category
      of the grammar, we create the corresponding dotted rule with the
      dot position at the start of the right-hand side.</para>

<programlisting>
def TD_init(chart, grammar, basecat):
    added = []
    loc = chart.loc().start_loc()
    for rule in grammar:
        if rule.lhs() == basecat:
            drule = rule.drule()
            new_edge = Edge(drule, TreeToken(drule.lhs()), loc)
            added += [new_edge]
    return added
</programlisting>
      

    </section> <!-- Top Down Initialization -->

    <section id="rules.td2"> <title> The Top Down Edge-Triggered Rule </title>

      <para>Whenever a chart contains an incomplete edge, with an incomplete
      rule having <replaceable>X</replaceable> as the next symbol (to the right
      of the dot), we know that
      the parser is expecting to find an <replaceable>X</replaceable>
      constituent immediately to the right.  The top-down edge-triggered
      rule looks for all incompleted edges expecting an
      <replaceable>X</replaceable> and, for each grammar rule having
      <replaceable>X</replaceable> on its left-hand side, creates a zero-width
      edge containing this rule.
      </para>

<programlisting>
def TD_edge(chart, grammar, basecat, edge):
    "Top-down init (edge triggered rule)"
    added = []
    for rule in grammar:
        if not edge.complete() and rule.lhs() == edge.drule().next():
            new_edge = edge.self_loop_end(rule)
            added += [new_edge]
    return added
</programlisting>

    </section> <!-- The Top Down Edge-Triggered Rule -->

    <section id="rules.bu"> <title> Bottom Up Initialization </title>

      <para>A bottom up parser builds syntactic structure starting from the
      words in the input.  For each word, it must consider which grammar rules
      apply.  The bottom up initialization step involves inserting zero-width
      edges for all words which could be at the left corner of a phrase.</para>

<programlisting>
def BU_init(chart, grammar, basecat):
    added = []
    for edge in chart.edges():
        for rule in grammar:
            if edge.drule().lhs() == rule[0]:
                new_edge = edge.self_loop_start(rule)
                added += [new_edge]
    return added
</programlisting>

    </section> <!-- Bottom Up Initialization -->

    <section id="rules.strategies"> <title> Chart Parser Strategies </title>

      <para>Chart parsers use the various rules described above in order
      to emulate top down, bottom up or hybrid parsers.  A policy about
      what chart rule to apply when is called a
      <emphasis>rule-invocation stratagy</emphasis>.  (Note that the rules
      being invoked here are chart rules, not grammar rules.)</para>

      <para>NLTK defines basic stratagies using instances of the
      <ulink url="http://nltk.sourceforge.net/ref/nltk.chartparser.ChartParserStrategy.html">ChartParserStrategy</ulink>
      class.  Chart rules, whether static or edge-triggered, are defined as
      functions (some are listed above), and then these are passed to the
      <literal>ChartParserStrategy</literal> class.  The initializer takes
      two arguments: a list of static rules and a list of edge-triggered rules.
      Here are the definitions of the top down and bottom up strategies:</para>

<programlisting>
TD_STRATEGY = ChartParserStrategy([TD_init, FR], [TD_edge])
BU_STRATEGY = ChartParserStrategy([BU_init, FR], [])
</programlisting>

    </section> <!-- Parsing Strategies -->

    <section id="using"> <title> Creating and Using Chart Parsers </title>

      <para>Here is a simple chart parser, which makes use of
      <literal>grammar</literal> and <literal>lexicon</literal>
      as defined earlier in this tutorial.</para>

<programlisting>
cp = ChartParser(grammar, lexicon, 'S', strategy = BU_STRATEGY)
cp.parse(WSTokenizer().tokenize(sent))
for parse in cp.parses():
    print parse.pp()
</programlisting>

      <para>The result of running this parser on the sentence
      <emphasis>I saw a man in the park with a telescope</emphasis>
      is the following set of trees:</para>

<programlisting>
('S':
  ('NP': 'I')
  ('VP':
    ('V': 'saw')
    ('NP':
      ('Det': 'a')
      ('N': 'man')
      ('PP':
        ('P': 'in')
        ('NP': ('Det': 'the') ('N': 'park'))))
    ('PP':
      ('P': 'with')
      ('NP': ('Det': 'a') ('N': 'telescope')))))@[0w:10w]

('S':
  ('NP': 'I')
  ('VP':
    ('V': 'saw')
    ('NP': ('Det': 'a') ('N': 'man'))
    ('PP':
      ('P': 'in')
      ('NP':
        ('Det': 'the')
        ('N': 'park')
        ('PP':
          ('P': 'with')
          ('NP': ('Det': 'a') ('N': 'telescope')))))))@[0w:10w]

('S':
  ('NP': 'I')
  ('VP':
    ('V': 'saw')
    ('NP': ('Det': 'a') ('N': 'man'))
    ('PP': ('P': 'in') ('NP': ('Det': 'the') ('N': 'park')))
    ('PP':
      ('P': 'with')
      ('NP': ('Det': 'a') ('N': 'telescope')))))@[0w:10w]

('S':
  ('NP': 'I')
  ('VP':
    ('V': 'saw')
    ('NP':
      ('Det': 'a')
      ('N': 'man')
      ('PP':
        ('P': 'in')
        ('NP':
          ('Det': 'the')
          ('N': 'park')
          ('PP':
            ('P': 'with')
            ('NP': ('Det': 'a') ('N': 'telescope'))))))))@[0w:10w]
</programlisting>

      <para>To see the corresponding chart, use the function
      <literal>Chart.chart().draw()</literal>.</para>

      <note><para>Note that some edges
      are duplicated because they contain different trees.  In order
      for a chart parser to have polynomial complexity the trees
      corresponding to an edge must be stored in a distributed way...
      </para></note>

    </section> <!-- Creating and Using Chart Parsers -->

    <section id="demo"> <title> The Tk Interface </title>

      <note><para>To be written.</para></note>

      <para>Please see the
      <ulink url="http://nltk.sourceforge.net/ref/nltk.draw.chart.html">nltk.draw.chart</ulink>
      module.</para>

    </section> <!-- The Tk Interface -->

  </section> <!-- Chart Parsing -->
</section> <!-- Intro -->
<!-- </section>  Chart Parsing in NLTK -->

  &index;
</article>
