<!-- This material has been taken out of the tagging tutorial, since it probably belongs in the writing_classes tutorial.
Steven Bird, 2004-03-16 -->


  <section id="impl"> <title> Tagging: A Closer Look </title>

    <para> In the next five sections, we will discuss how each of the
    taggers introduced in the previous section are implemented.  This
    discussion serves several purposes: </para>

    <itemizedlist>
      <listitem>
        <para> It demonstrates how to write classes implementing the
        interfaces defined by NLTK. </para>
      </listitem>
      <listitem>
        <para> It provides you with a better understanding of the
        algorithms and data structures underlying each approach to
        tagging. </para>
      </listitem>
      <listitem>
        <para> It gives you a chance to see some of the code used to
        implement NLTK.  We have tried hard to ensure that the
        implementation of every class in NLTK is easy to understand.
        </para>
      </listitem>
    </itemizedlist>

    <para> Before you read this section, you may wish to read the
    tutorial "<ulink url="&tutdoc;/writing_classes/index.html">
    Writing Classes For NLTK"</ulink>, which describes how to create
    classes that interface with the toolkit. </para>

  </section> <!-- Tagging: A Closer Look -->

  <section id="sequentialtagger"> <title> Sequential Taggers </title>

    <para> The four taggers discussed in this tutorial are implemented
    as sequential taggers.  A <glossterm>sequential tagger</glossterm>
    is a tagger that: </para>

    <orderedlist>
      <listitem><para> Assigns tags to one token at a time, starting
      with the first token of the text, and proceeding in sequential
      order. </para> </listitem>
      <listitem><para> Decides which tag to assign a token on the
      basis of that token, the tokens that preceed it, and the
      predicted tags for the tokens that preceed it. </para>
      </listitem>
    </orderedlist>

    <para> To capture this commonality, we define a common base class,
    <ulink url="&refdoc;/nltk.tagger.SequentialTagger-class.html"
    ><literal>SequentialTagger</literal></ulink>.  This base class
    defines <literal>tag</literal> using a new method,
    <ulink url="&refdoc;/nltk.tagger.SequentialTagger-class.html#tag_next"
    ><literal>tag_next</literal></ulink>, which returns the appropriate
    tag for the next token.  However,
    <literal>SequentialTagger</literal> does not implement this new
    method itself.  Instead, each tagger subclass provides its own
    implementation. </para>

    <para> In addition to capturing the commonality between the four
    taggers, the <literal>SequentialTagger</literal> class has another
    advantage: it will allow us to define
    <literal>BackoffTagger</literal> in such a way that each subtagger
    can use the predictions made by the other taggers as context for
    deciding which tags to assign.  See <xref
    linkend="backoff_impl"></xref> for more
    details.</para>

    <section id="sequentialtagger.tag_next"> <title> SequentialTagger.tag_next </title>

      <para> The <ulink
      url="&refdoc;/nltk.tagger.SequentialTagger-class.html#tag_next"
      ><literal>tag_next</literal></ulink> method decides which tag to
      assign a token, given the list of tagged tokens that preceeds
      it.  It takes two arguments: a list of tagged tokens preceeding
      the token to be tagged, and the token to be tagged; and it
      returns the appropriate tag for that token. </para>

    </section> <!-- tag_next -->

    <section id="sequentialtagger.tag"> <title> SequentialTagger.tag </title>

      <para> The implementation of the <literal>tag</literal> method
      is relatively streight forward.  It simply loops through the
      untagged text, calling <literal>tag_next</literal> for each
      token.  It uses the result of each call to
      <literal>tag_next</literal> to create a tagged version of that
      token, and collects these together to form the tagged
      text. </para>

<programlisting>
    <command>def tag(self, text):</command>
        tagged_text = []

        for token in text:
            tag = self.next_tag(tagged_text, token)
            tagged_token = Token(TaggedType(token.type(), tag), token.loc())
            tagged_text.append(tagged_token)

        return tagged_text
</programlisting>

    </section> <!-- tag -->

    <section id="sequentialtagger.impl"> <title> The SequentialTagger Implementation </title>

      <para> The complete listing for
      <literal>SequentialTagger</literal> is: </para>

      <figure><title>The SequentialTagger Implementation</title>
<programlisting>
<command>class SequentialTagger(TaggerI):</command>

    <command>def next_tag(self, tagged_tokens, next_token):</command>
        assert 0, "next_tag not defined by SequentialTagger subclass"

    <command>def tag(self, text):</command>
        tagged_text = []

        <emphasis># Tag each token, in sequential order.</emphasis>
        for token in text:
            <emphasis># Get the tag for the next token.</emphasis>
            tag = self.next_tag(tagged_text, token)

            <emphasis># Use tag to build a tagged token, and add it to tagged_text.</emphasis>
            tagged_token = Token(TaggedType(token.type(), tag), token.loc())
            tagged_text.append(tagged_token)

        return tagged_text
</programlisting>
      </figure>
      
      <para> Note that SequentialTagger requires that subclasses
      define the <literal>tag_next</literal> method; otherwise, the
      <literal>assert</literal> statement will raise an
      exception when the user tries to tag a text. </para>

    </section>

    <section id="sequentialtagger.subclasses"> <title> Subclasses </title>

      <para> The next four sections show how the
      <literal>SequentialTagger</literal> base class can be used to
      define <literal>NN_CD_Tagger</literal>,
      <literal>UnigramTagger</literal>,
      <literal>NthOrderTagger</literal>, and
      <literal>BackoffTagger</literal>.</para>

    </section> <!-- Subclasses -->

  </section> <!-- SequentialTagger -->

  <section id="nncd_impl"> <title> NN_CD_Tagger </title>

    <para> <literal>NN_CD_Tagger</literal> assigns the tag
    <literal>"CD"</literal> to any token whose type appears to be a
    number; and <literal>"NN"</literal> to any other token.  It uses a
    simple regular expression to test whether a token's type is a
    number:</para>

<programlisting>
    r'^[0-9]+(.[0-9]+)?$'
</programlisting>

    <para> This regular expression matches one or more digits, followed
    by an optional period and one or more digits (e.g.,
    "<literal>12</literal>" or "<literal>732.42</literal>").  Note the
    use of "<literal>^</literal>" (which matches the beginning of a
    string) and "<literal>$</literal>" (which matches the end of a
    string) to ensure that the regular expression will only match
    complete token types. </para>

    <para> Since <literal>NN_CD_Tagger</literal> is a subclass of
    <literal>SequentialTagger</literal>, it just needs to define the
    <literal>next_tag</literal> method.  In the case of
    <literal>NN_CD_Tagger</literal>, the <literal>next_tag</literal>
    method is quite simple: </para>

<programlisting>
    <command>def next_tag(self, tagged_tokens, next_token):</command>
        if re.match(r'^[0-9]+(.[0-9]+)?$', next_token.type()):
            return 'CD'
        else:
            return 'NN'
</programlisting>

    <para> Since <literal>NN_CD_Tagger</literal>s are stateless, and
    have no customization parameters, the <ulink
    url="&refdoc;/nltk.tagger.NN_CD_Tagger-class.html#__init__"
    ><literal>NN_CD_Tagger constructor</literal></ulink> is empty:
    </para>

<programlisting>
    <command>def __init__(self):</command> pass
</programlisting>

    <para> The complete listing for the
    <literal>NN_CD_Tagger</literal> class is:</para>

    <figure><title>The NN_CD_Tagger Implementation</title>
<programlisting> 
<command>class NN_CD_Tagger(SequentialTagger):</command>

    <command>def __init__(self):</command> pass

    <command>def next_tag(self, tagged_tokens, next_token):</command>
        <emphasis># Assign the 'CD' tag for numbers; and 'NN' for anything else.</emphasis>
        if re.match(r'^[0-9]+(.[0-9]+)?$', next_token.type()):
            return 'CD'
        else:
            return 'NN'
</programlisting>
    </figure>

    <para> Note that <literal>NN_CD_Tagger</literal> does
    <emphasis>not</emphasis> define <literal>tag</literal>.  When the
    <literal>tag</literal> method is called, the definition given by
    <literal>SequentialTagger</literal> will be used. </para>

  </section> <!-- NN_CD_Tagger -->

  <section id="unigram_impl"> <title> UnigramTagger </title>

    <para> <literal>UnigramTagger</literal> tags each token with the
    tag that is most likely to go with the token's type.  It uses a
    training corpus to decide which tag is most likely for each type.
    In particular, it assumes that the tag that occurs most frequently
    with a type is the most likely tag for that type.  For example, if
    the training corpus contains the word "track" as a noun 18 times,
    and as a verb 7 times, then it will assign the noun tag to any
    tokens whose type is "track." 
        <footnote> <para> We considered using a conditional
        probability distribution, instead of a conditional frequency
        distribution.  However, for most probability distributions,
        the maximum probability sample is always equal to the maximum
        frequency sample in the underlying frequency distributions.
        We decided that the additional complexity involved in using
        <literal>ConditionalProbDist</literal> was not justified. </para>
        </footnote></para>

    <para> UnigramTagger uses a <literal>ConditionalFreqDist</literal>
    to record the most likely tag for each type.  
        <footnote><para>See the <ulink
        url="&tutdoc;/probability/index.html">probability
        tutorial</ulink> for information about constructing and using
        frequency distributions.</para> </footnote>
    The <ulink url="&refdoc;/nltk.tagger.UnigramTagger-class.html#train"
    ><literal>train</literal></ulink> method constructs this
    conditional frequency distribution from a training corpus. </para>

    <section id="unigram_impl.training"> <title> Training the Unigram Tagger </title>

      <para> Tagging is a prediction problem.  In particular, the
      outcome we are interested in is the tag; and the context that we
      will use to predict the outcome is the token's type.  So we will
      construct a <literal>ConditionalFreqDist</literal> whose samples
      are tags, and whose conditions are token types: </para>

<programlisting>
    <command>def train(self, tagged_tokens):</command>
        for token in tagged_tokens:
            outcome = token.type().tag()
            context = token.type().base()
            self._freqdist[context].inc(outcome)
</programlisting>

    </section> <!-- Training -->

    <section id="unigram_impl.tagging"> <title> Tagging with the Unigram Tagger </title>
      
      <para> To find the most likely tag for a given token, we can use
      the the <ulink
      url="&refdoc;/nltk.probability.ConditionalFreqDist-class.html#__getitem__">indexing
      operator</ulink> to access the <literal>FreqDist</literal> for
      the appropriate context; and use the <ulink
      url="&refdoc;/nltk.probability.FreqDist-class.html#max"
      ><literal>max</literal></ulink> method to find the most likely
      outcome for that frequency distribution.  For example, we could
      find the most likely tag for the base type "bank" as
      follows:</para>

<programlisting>
    &prompt;<command> freqdist['bank'].max()</command>
    'NN'
</programlisting>

      <para> The <literal>next_tag</literal> method must decide which
      tag is most likely for a given token.  It simply consults the
      tagger's conditional frequency distribution to find the tag that
      is most likely for the tokens's type. </para>

<programlisting>
    <command>def next_tag(self, tagged_tokens, next_token):</command>
        context = next_token.type()
        return self._freqdist[context].max()
</programlisting>

      <note> <para> If a context was not encountered in the training
      corpus, then the frequency distribution for that context will be
      empty; so <literal>max()</literal> will return
      <literal>None</literal>.  Thus, <literal>next_tag</literal> will
      return <literal>None</literal> as for any token whose type was
      not encountered in the training corpus. </para> </note>
      
    </section> <!-- Tagging Words -->

    <section id="unigram_impl.init"> <title> Initializing the Unigram Tagger </title>

      <para> The constructor for <literal>UnigramTagger</literal>
      simply initializes <literal>self._freqdist</literal> with a new
      conditional frequency distribution.  </para>

<programlisting>
    <command>def __init__(self):</command>
        self._freqdist = probability.ConditionalFreqDist()
</programlisting>

    </section> <!-- Initializing the UnigramTagger -->

    <section id="unigram_impl.impl"><title>The UnigramTagger Implementation</title>

      <para> The complete listing for the
      <literal>UnigramTagger</literal> class is:</para>
      
      <figure><title>The UnigramTagger Implementation</title>
<programlisting> 
<command>class UnigramTagger(TaggerI):</command>
class UnigramTagger(SequentialTagger):
    <command>def __init__(self):</command>
        self._freqdist = ConditionalFreqDist()
    
    <command>def train(self, tagged_tokens):</command>
        for token in tagged_tokens:
            context = token.type().base()
            feature = token.type().tag()
            self._freqdist[context].inc(feature)

    <command>def next_tag(self, tagged_tokens, next_token):</command>
        context = next_token.type()
        return self._freqdist[context].max()
</programlisting>
      </figure>
    </section> <!-- UnigramTagger Implementation -->
  </section> <!-- UnigramTagger -->

  <section id="nthorder_impl" xreflabel="NthOrderTagger"> 
    <title> NthOrderTagger </title>

    <para> The <literal>NthOrderTagger</literal> is a generalization
    of the <literal>UnigramTagger</literal>.  Instead of using the
    token's base type as a context, it uses a tuple consisting of the
    token's base type and the tags of the <replaceable>n</replaceable>
    preceding tokens.  This generalization creates two new
    issues. </para>

    <para> First, we must decide how to handle the first
    <replaceable>n</replaceable> tokens, since they do not have
    <replaceable>n</replaceable> preceding tokens.  

    <literal>NthOrderTagger</literal> simply uses the tags that are
    available.  For example, in a 3rd order tagger, the context of the
    second token will contain only the token's type and the first
    token's tag.  Another option would be to simply ignore the first
    <replaceable>n</replaceable> tokens.  As it turns out, which
    approach we take will not have much of an impact, since
    <replaceable>n</replaceable> (the order of the tagger) is
    generally much less than
    <replaceable>n<subscript>train</subscript></replaceable> (the
    number of training samples). </para>

    <para> The second issue is that, when tagging a text, we do not
    have access the the actual tags of the
    <replaceable>n</replaceable> preceding tokens.  However, we do
    have access to our predicted values for these tags.
    <literal>NthOrderTagger</literal> uses these predicted tags, since
    they are likely to be correct.  Assuming that our predictions are
    good, the use of predicted tags instead of actual tags will have a
    relatively minor impact on performance. </para>

    <section id="nthorder_impl.init"> <title> Initializing the Nth Order Tagger</title>

      <para> Having addressed these two issues, we can examine the
      implementation of the <literal>NthOrderTagger</literal>.  The
      constructor simply records <replaceable>n</replaceable>, and
      constructs a new conditional frequency distribution: </para>

<programlisting>
    <command>def __init__(self, n):</command>
        self._n = n
        self._freqdist = probability.ConditionalFreqDist()
</programlisting>

    </section> <!-- NthOrderTagger Constructor -->

    <section id="nthorder_impl.train"> <title> Training the Nth Order Tagger </title>

      <para> To train the <literal>NthOrderTagger</literal>, we
      examine each token, and increment the count of the tag for the
      appropriate context.  For contexts, we use a tuple consisting of
      the <replaceable>n</replaceable> previous tags and the current
      token's base type.  We use a variable called
      <literal>prev_tags</literal> to record the rpevious
      <replaceable>n</replaceable> tags; and update it after examining
      each token. </para>

<programlisting>
    <command>def train(self, tagged_tokens):</command>
        <emphasis># prev_tags is a list of the previous n tags that we've assigned.</emphasis>
        prev_tags = []
        
        for token in tagged_tokens:
            context = tuple(prev_tags + [token.type().base()])
            feature = token.type().tag()
            self._freqdist[context].inc(feature)

            <emphasis># Update prev_tags</emphasis>
            prev_tags.append(token.type().tag())
            if len(prev_tags) == (self._n+1):
                del prev_tags[0]
</programlisting>

    </section> <!-- NthOrderTagger.train -->

    <section id="nthorder_impl.tag"> <title> Tagging with the Nth Order Tagger </title>

      <para> As with the <literal>UnigramTagger</literal>, we can find
      the most likely tag for each token by using the
      <literal>max</literal> method for the frequency distribution
      with the appropriate context.  But instead of using each token's
      base type as a context, we use a tuple consisting of the
      <replaceable>n</replaceable> previous predicted tags and the
      token's base type. </para>

<programlisting>
    <command>def next_tag(self, tagged_tokens, next_token):</command>
        <emphasis># Find the tags of the n previous tokens.</emphasis>
        prev_tags = []
        start = max(len(tagged_tokens) - self._n, 0)
        for token in tagged_tokens[start:]:
            prev_tags.append(token.type().tag())

        <emphasis># Return the most likely tag for the token's context.</emphasis>
        context = tuple(prev_tags + [next_token.type()])
        return self._freqdist[context].max()
</programlisting>

    </section> <!-- NthOrderTagger.tag -->

    <section id="nthorder_impl.impl"><title>The NthOrderTagger Implementation</title>

      <para> The complete listing for the
      <literal>NthOrderTagger</literal> class is:</para>
      
      <figure><title>The NthOrderTagger Implementation</title>
<programlisting> 
<command>class NthOrderTagger(SequentialTagger):</command>
    <command>def __init__(self, n):</command>
        self._n = n
        self._freqdist = CFFreqDist()

    <command>def train(self, tagged_tokens):</command>
        <emphasis># prev_tags is a list of the previous n tags that we've assigned.</emphasis>
        prev_tags = []
        
        for token in tagged_tokens:
            context = tuple(prev_tags + [token.type().base()])
            feature = token.type().tag()
            self._freqdist[context].inc(feature)

            <emphasis># Update prev_tags</emphasis>
            prev_tags.append(token.type().tag())
            if len(prev_tags) == (self._n+1):
                del prev_tags[0]

    <command>def next_tag(self, tagged_tokens, next_token):</command>
        <emphasis># Find the tags of the n previous tokens.</emphasis>
        prev_tags = []
        start = max(len(tagged_tokens) - self._n, 0)
        for token in tagged_tokens[start:]:
            prev_tags.append(token.type().tag())

        <emphasis># Return the most likely tag for the token's context.</emphasis>
        context = tuple(prev_tags + [next_token.type()])
        return self._freqdist[context].max()
</programlisting>
      </figure>

    </section> <!-- NthOrderTagger Implementation -->

  </section> <!-- NthOrderTagger -->

  <section id="backoff_impl" xreflabel="BackoffTagger"> 
    <title> BackoffTagger </title>

    <para> The <literal>BackoffTagger</literal> is used to combine the
    results of a list of <glossterm>subtaggers</glossterm>.  For each
    token to be tagged, the <literal>BackoffTagger</literal> consults
    each subtagger, in order.  Each token is assigned the first
    non-<literal>None</literal> tag returned by a subtagger for that
    token.  If all of the subtaggers return the tag
    <literal>None</literal> for a token, then
    <literal>BackoffTagger</literal> will assign it the tag
    <literal>None</literal>. </para>

    <section id="backoff_impl.init"> <title> Initializing a Backoff Tagger </title>

    <para> The <literal>BackoffTagger</literal> constructor simply
    records the list of subtaggers. </para>

<programlisting>
    <command>def __init__(self, subtaggers):</command>
        self._taggers = subtaggers
</programlisting>

    </section> <!-- Initializing a BackoffTagger -->

    <section id="backoff_impl.tag"> <title> Tagging with the Backoff Tagger </title>

      <para> The implementation of <literal>BackoffTagger</literal> is
      relatively straight-forward.  Its <literal>next_tag</literal>
      method simply calls each subtagger's <literal>next_tag</literal>
      method, in order; and returns the first
      non-<literal>None</literal> tag produced by a subtagger. </para>

<programlisting>
    <command>def next_tag(self, tagged_tokens, next_token):</command>
        for subtagger in self._subtaggers:
            tag = subtagger.next_tag(tagged_tokens, next_token)
            if tag is not None:
                return tag

        <emphasis># Default to None if all subtaggers return None. </emphasis>
        return None
</programlisting>    
    
    </section> <!-- BackoffTagger tagging -->

    <section id="backoff_impl.impl"><title>The BackoffTagger Implementation</title>

      <para> The complete listing for the
      <literal>BackoffTagger</literal> class is:</para>
      
      <figure><title>The BackoffTagger Implementation</title>
<programlisting> 
<command>class BackoffTagger(SequentialTagger):</command>
    <command>def __init__(self, subtaggers):</command>
        self._subtaggers = subtaggers

    <command>def next_tag(self, tagged_tokens, next_token):</command>
        for subtagger in self._subtaggers:
            tag = subtagger.next_tag(tagged_tokens, next_token)
            if tag is not None:
                return tag

        <emphasis># Default to None if all subtaggers return None. </emphasis>
        return None
</programlisting>
      </figure>
    </section> <!-- BackoffTagger impl -->
  </section> <!-- BackoffTagger -->

