<?xml version="1.0"?>
<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.1//EN" [
<!ENTITY prompt "<prompt>&gt;</prompt><prompt>&gt;</prompt><prompt>&gt;</prompt>">
<!ENTITY prompt2 "<prompt>...</prompt>">
]>

<article>
  <articleinfo>
    <author><firstname>Steven</firstname><surname>Bird</surname></author>
    <authorinitials>sb</authorinitials>
    <author><firstname>Edward</firstname><surname>Loper</surname></author>
    <authorinitials>edl</authorinitials>
    <title>NLTK Tutorial: Parsing</title>
  </articleinfo>

  <section> <title> Introduction </title>

    <note> <!-- === NOTE === -->
      <para>Write a real introduction. :)</para>

      <para>The introduction should include definitions of:
      <glossterm>constituant</glossterm>, <glossterm>syntax
      tree</glossterm>, etc.  This discussion can be at a pretty high
      level.  Depending on how much background we want to have, this
      section might have subsections... </para>
    </note>

    <para> Sentences have internal structure.  Describe structure
    (hierarchical, etc).  NLTK provides us with classes for
    representing syntax trees.  It also provides us with an interface
    for deriving this structure.  This is called
    <glossterm>parsing</glossterm>. </para>

  </section> <!-- Introduction -->

  <section> <title> Grammars and Lexicons </title>

    <para>A <glossterm>grammar</glossterm> is a formal specification
    for the structure of well-formed
    sentences in some language.  At present, only context-free grammars (CFGs) can be
    represented in NLTK.  A CFG consists of a set of context-free rules.  Context-free
    rules have the form <literal>X -&gt; Y</literal> where <literal>X</literal> is
    a non-terminal, and <literal>Y</literal> is a list of terminals and non-terminals.
    <literal>X</literal> and <literal>Y</literal> are known as the left-hand side and
    right-hand side respectively.
    </para>

    <para>
    In the simplest case, non-terminals and terminals are just Python
    strings.  However, it is possible to use any immutable Python object as a
    non-terminal or terminal.
    </para>

    <note><para>The NLTK chart parser makes two additional assumptions about rules.
    First, if a terminal symbol occurs on the right hand side of a rule, it must
    be the only element on the right hand side.  Second, terminal symbols must
    be Python strings, for they are matched against the <literal>type</literal>
    attribute of a token.  Thus, the form of "lexical rules" must be
    <literal>N -&gt; 'cat'</literal>.  Using rules like
    <literal>NP -&gt; 'the' N</literal> will produce unintended results
    (either <literal>the</literal> will be treated as the name of a non-terminal,
    of <literal>N</literal> will be ignored).  In general, this limitation on the
    form of lexical rules does not pose any problems.
    </para></note>

    <para>A grammar can be represented as a tuple of rules, while a lexicon
    can be represented as a tuple of lexical rules.  The only class we need
    to define then is <literal>Rule</literal>.

    </para>

    <section> <title> Rules </title>

      <para>The <ulink url="http://nltk.sourceforge.net/ref/nltk.rule.html">
      <literal>nltk.rule</literal></ulink> module defines the
      <ulink url="http://nltk.sourceforge.net/ref/nltk.rule.Rule.html">
      <literal>Rule</literal></ulink> class, which is used to represent
      context free rules.  A <literal>Rule</literal> consists of a
      left-hand side and a right-hand side.</para>

      <itemizedlist>
        <listitem><para>The left-hand side is a single non-terminal, which
        may be any Python object.  In the simplest case it is just a string
        (e.g. "NP" or "VP").
        </para></listitem>

        <listitem><para>The right-hand side is a tuple of non-terminals and
        terminals, which may be any Python object.  In the simplest case
        these are strings (e.g. "Det", "the").
        </para></listitem>
      </itemizedlist>

      <note><para>For the NLTK chart parser, the right-hand side of a rule must
      be either a tuple of non-terminals, or a tuple consisting of exactly one
      terminal (e.g. ("the",))</para></note>

      <para><literal>Rule</literal>s are created with the
      <ulink url="http://nltk.sourceforge.net/ref/nltk.rule.Rule.html#__init__">
      <literal>Rule constructor</literal></ulink>, which takes a left-hand side
      and a right-hand side:</para>

<programlisting>
<emphasis># A typical grammar rule S -&gt; NP VP:</emphasis>
&prompt;<command> rule1 = Rule('S', ('NP', 'VP'))</command>
S -> NP VP

<emphasis># A typical lexical rule Det -&gt; 'the':</emphasis>
&prompt;<command> rule2 = Rule('Det', ('the',))</command>
Det -> the
</programlisting>

      <para>A <literal>Rule</literal>'s left-hand side and right-hand
      side are accessed with
      the <ulink url="http://nltk.sourceforge.net/ref/nltk.rule.Rule.html#lhs">
      <literal>lhs</literal></ulink>
      and <ulink url="http://nltk.sourceforge.net/ref/nltk.rule.Rule.html#rhs">
      <literal>rhs</literal></ulink> methods:
      </para>

<programlisting>
&prompt;<command> rule1.lhs()</command>
'S'

&prompt;<command> rule2.rhs()</command>
('the',)
</programlisting>

      <para> A <literal>Rule</literal>'s right-hand side can also be accessed with
      standard sequence operators: </para>

<programlisting>
&prompt;<command> rule1[0]</command>
'NP'

&prompt;<command> rule2[1]</command>
IndexError: tuple index out of range

&prompt;<command> len(rule1)</command>
2

&prompt;<command> 'the' in rule2</command>
1

&prompt;<command> for cat in rule1: </command>
&prompt2;<command>     print cat</command>
NP
VP
</programlisting>

    </section> <!-- Rules -->

    <section> <title> Building Grammars and Lexicons from Rules </title>

    <para>Grammars and Lexicons can easily be built up from
    <literal>Rule</literal>s as shown in the following examples:</para>

<programlisting>
<emphasis># A simple grammar:</emphasis>
<command>
grammar = (
    Rule('S',('NP','VP')),
    Rule('NP',('Det','N')),
    Rule('NP',('Det','N', 'PP')),
    Rule('VP',('V','NP')),
    Rule('VP',('V','PP')),
    Rule('VP',('V','NP', 'PP')),
    Rule('VP',('V','NP', 'PP', 'PP')),
    Rule('PP',('P','NP'))
)
</command>

<emphasis># A simple lexicon:</emphasis>
<command>
lexicon = (
    Rule('NP',('I',)),
    Rule('Det',('the',)),
    Rule('Det',('a',)),
    Rule('N',('man',)),
    Rule('V',('saw',)),
    Rule('P',('in',)),
    Rule('P',('with',)),
    Rule('N',('park',)),
    Rule('N',('telescope',))
)
</command>
</programlisting>

    </section> <!-- Building Grammars and Lexicons from Rules -->

    <section> <title> Dotted Rules </title>

      <para>The <ulink url="http://nltk.sourceforge.net/ref/nltk.rule.html">
      <literal>nltk.rule</literal></ulink> module defines the
      <ulink url="http://nltk.sourceforge.net/ref/nltk.rule.DottedRule.html">
      <literal>DottedRule</literal></ulink> class, which is used to represent
      the dotted rules used by a chart parser.  A <literal>DottedRule</literal>
      consists of a left-hand side, a right-hand side, and the dot position.</para>

      <para><literal>DottedRule</literal>s are created with the
      <ulink url="http://nltk.sourceforge.net/ref/nltk.rule.DottedRule.html#__init__">
      <literal>DottedRule constructor</literal></ulink>, which takes a left-hand side,
      a right-hand side, and a position:</para>

<programlisting>
<emphasis># A dotted rule with position 0 (default value omitted):</emphasis>
&prompt;<command> dr1 = DottedRule('S', ('NP', 'VP'))</command>
S -> * NP VP

<emphasis># A dotted rule with position 0 (default value supplied):</emphasis>
&prompt;<command> dr1 = DottedRule('S', ('NP', 'VP'), 0)</command>
S -> * NP VP

<emphasis># A dotted rule with position 1:</emphasis>
&prompt;<command> dr2 = DottedRule('S', ('NP', 'VP'), 1)</command>
S -> NP * VP

<emphasis># A dotted rule with position 2:</emphasis>
&prompt;<command> dr3 = DottedRule('S', ('NP', 'VP'), 2)</command>
S -> NP VP *
</programlisting>

    <para>Another way to construct a <literal>DottedRule</literal> is from
    a <literal>Rule</literal>.  The <literal>Rule</literal> class has a
    <ulink url="http://nltk.sourceforge.net/ref/nltk.rule.Rule.html#drule">
    <literal>drule</literal></ulink> member function which returns the
    dotted version of the rule (with position 0).
    </para>

<programlisting>
&prompt;<command> rule1 = Rule('S', ('NP', 'VP'))</command>
&prompt;<command> rule1.drule()</command>
S ->  * NP VP
</programlisting>

    <para><literal>DottedRule</literal> inherits the member functions of
    <literal>Rule</literal>.  In addition, it defines
    <ulink url="http://nltk.sourceforge.net/ref/nltk.rule.DottedRule.html#pos">
    <literal>pos</literal></ulink> which returns the dot position,
    <ulink url="http://nltk.sourceforge.net/ref/nltk.rule.DottedRule.html#next">
    <literal>next</literal></ulink> which returns the next right-hand side
    element following the dot, and
    <ulink url="http://nltk.sourceforge.net/ref/nltk.rule.DottedRule.html#shift">
    <literal>shift</literal></ulink>
    which returns a new rule with the dot shifted one position to the right.
    </para>

<programlisting>
&prompt;<command> dr1.pos()</command>
0

&prompt;<command> dr1.next()</command>
'NP'

&prompt;<command> dr1.shift()</command>
S -> NP * VP

&prompt;<command> dr3.shift()</command>
IndexError: Attempt to move dot position past end of rule

</programlisting>

    <para><literal>DottedRule</literal> defines a function
    <ulink url="http://nltk.sourceforge.net/ref/nltk.rule.DottedRule.html#complete">
    <literal>complete</literal></ulink> which tests to see if the dotted rule
    is complete (i.e. the dot is in the rightmost position).</para>

<programlisting>
&prompt;<command> dr1.complete()</command>
0

&prompt;<command> dr3.complete()</command>
0
</programlisting>


    </section>

  </section> <!-- Grammars -->

  <section> <title> Encoding Syntax Trees </title>

    <para> Introductory paragraph(s)... </para>

    <note>
      <para> The <literal>nltk.tree</literal> module currently has
      only minimal support for representing movement, traces, and
      co-indexing.  We plan to extend the class to support these
      features more fully in the future. </para>
    </note>

    <section> <title> Trees </title>

      <para>The <ulink url="http://nltk.sourceforge.net/ref/nltk.tree.html">
      <literal>nltk.tree</literal></ulink> module defines the
      <ulink url="http://nltk.sourceforge.net/ref/nltk.tree.Tree.html">
      <literal>Tree</literal></ulink> class, which is used to
      represent syntax trees.  A <literal>Tree</literal> consists of a
      <glossterm>node value</glossterm>, and one or more
      <glossterm>children</glossterm>. </para>

      <itemizedlist>
        <listitem> <para> The node value is a string containing the
        tree's constituant type (e.g., "NP" or "VP").
        </para></listitem>

        <listitem> <para> The children encode the hierarchical
        contents of the tree.  Each child is either a
        <glossterm>leaf</glossterm> or a
        <glossterm>subtree</glossterm>.</para></listitem>
      </itemizedlist>
    
      <note>
        <para> Although the <literal>Tree</literal> class is usually
        used for encoding syntax trees, it can be used to encode
        <emphasis>any</emphasis> homogenous hierarchical structure
        that spans a text (such as morphological structure or
        discourse structure).  In the general case, leaves and node
        values do not have to be strings. </para>
      </note>

      <para> A <literal>Tree</literal> with node value
      <replaceable>n</replaceable> and children
      <replaceable>c<subscript>1</subscript></replaceable>,
      <replaceable>c<subscript>2</subscript></replaceable>, ...
      <replaceable>c<subscript>n</subscript></replaceable> is written
      <literal>(<replaceable>n</replaceable>:
      <replaceable>c<subscript>1</subscript></replaceable>,
      <replaceable>c<subscript>2</subscript></replaceable>, ...
      <replaceable>c<subscript>n</subscript></replaceable>)</literal>.
      <literal>Tree</literal>s are created with the <ulink
      url="http://nltk.sourceforge.net/ref/nltk.tree.Tree.html#__init__">
      <literal>Tree constructor</literal></ulink>, which takes a node
      value and zero or more children: </para>

<programlisting>
    <emphasis># A tree with one child, a leaf:</emphasis>
    &prompt;<command> tree1 = Tree('NP', 'John')</command>
    ('NP': 'John')

    <emphasis># A tree with two children, both of which are leaves:</emphasis>
    &prompt;<command> tree2 = Tree('NP', 'the', 'man')</command>
    ('NP': 'the' 'man')

    <emphasis># A tree with two children, one leaf and one subtree:</emphasis>
    &prompt;<command> tree3 = Tree('VP', 'saw', tree2)</command>
    ('VP': 'saw' ('NP': 'the' 'man'))
</programlisting>

      <para> A <literal>Tree</literal>'s node value is accessed with
      the <ulink url="http://nltk.sourceforge.net/ref/nltk.tree.Tree.html#node">
      <literal>node</literal></ulink> method: </para>

<programlisting>
    &prompt;<command> tree1.node()</command>
    'NP'
</programlisting>

      <para> A <literal>Tree</literal>'s children are accessed with
      standard sequence operators: </para>

<programlisting>
    &prompt;<command> tree3[0]</command>
    'saw'
    &prompt;<command> tree3[1]</command>
    ('NP': 'the' 'man')
    &prompt;<command> len(tree3)</command>
    2
    &prompt;<command> 'saw' in tree3</command>
    1
    &prompt;<command> for child in tree3: </command>
    &prompt2;<command>     print child</command>
    saw 
    ('NP': 'the' 'man')
    &prompt;<command> [child.upper() for child in tree2] </command>
    ['THE', 'MAN']
    &prompt;<command> tree3[:] </command>
    ('saw', ('NP': 'the' 'man'))
</programlisting>

      <para> The printed representation for complex
      <literal>Tree</literal>s can be difficult to read.  In these
      cases, the <ulink
      url="http://nltk.sourceforge.net/ref/nltk.tree.Tree.html#draw">
      <literal>draw</literal></ulink> method can be very useful.  This
      method opens a new window, containing a graphical representation
      of the tree.  </para>

<programlisting>
    &prompt;<command> tree3.draw()</command>
</programlisting>

      <para> The tree display window allows you to zoom in and out; to
      collapse and expand subtrees; and to print the graphical
      representation to a postscript file. </para>

      <para> The <literal>Tree</literal> class implements a number of
      other useful methods.  See the <ulink
      url="http://nltk.sourceforge.net/ref/nltk.tree.Tree.html">
      <literal>Tree</literal> reference documentation</ulink> for more
      information about these methods. </para>

<programlisting>
    &prompt;<command> tree3.leaves()</command>
    ('saw', 'the', 'man')
    &prompt;<command> tree3.height()</command>
    3
    &prompt;<command> tree3.nodes()</command>
    ('VP': ('NP':))
</programlisting>

    </section> <!-- Trees -->

    <section> <title> Tree Tokens </title>

      <para> NLTK makes a distinction between <glossterm>tree
      type</glossterm>s and <glossterm>tree token</glossterm>s, that
      is analogous to the distinction between word types and word
      tokens.  In particular, a tree token is an individual occurance
      of a tree type in a text; and a tree type is an abstract syntax
      tree, without context. </para>

      <para> Tree tokens are represented with the <ulink
      url="http://nltk.sourceforge.net/ref/nltk.tree.TreeToken.html">
      <literal>TreeToken</literal></ulink> class.
      <literal>TreeToken</literal>s behave very much like
      <literal>Tree</literal>s, except that the leaves of a
      <literal>TreeToken</literal> are word tokens, not word types.  
      </para>

    </section> <!-- TreeTokens -->

  </section> <!-- Encoding Syntax Trees -->

  <section> <title> The Parser Interface </title>

    <para>The <ulink url="http://nltk.sourceforge.net/ref/nltk.parser.html">
    <literal>parser</literal></ulink> module defines the
    <ulink url="http://nltk.sourceforge.net/ref/nltk.parser.ParserI.html">
    <literal>ParserI</literal></ulink> class, which is the standard interface
    which all parsers should support.  This class should only be used in the
    definition of other parser classes, which should inherit from the
    <literal>ParserI</literal> class.</para>

    <para>The <literal>ParserI</literal> class defines
    <ulink url="http://nltk.sourceforge.net/ref/nltk.parser.ParserI.html#parse">
    <literal>parse</literal></ulink>, which takes a list of tokens as its argument
    and returns a list of <literal>TreeToken</literal>s.
    The <literal>parse</literal> function has an optional second argument
    which specifies the maximum number of parses to return.  No program should
    call the <literal>ParserI.parse</literal> method.  Derived classes must
    implement their own <literal>parse</literal> method.</para>

    <para>A parser returns an empty list of trees in the situation where it was
    unable to assign a tree to the list of tokens.  This happens in situations
    where the list of tokens forms an ungrammatical sentence, or when the grammar
    is deficient, or when the search strategy of the parser does not explore the
    section of the search space where the parse tree(s) are found.</para>

    <para>A parser returns
    more than one tree in the case of syntactic ambiguity.  The sentence being
    parsed may be genuinly ambiguous, or the grammar may be deficient.  Statistical
    parsers usually return the most likely parse (based on training data), or the
    set of <replaceable>n</replaceable> most likely parses.  The same interface
    applies to these cases.  (Where the probability of the parse tree needs to
    be returned, we assume this is stored in the root node of the tree.)  When
    asked to return <replaceable>n</replaceable> parses, we assume such a parser
    will rank parses in order of decreasing likelihood, and return the
    <replaceable>n</replaceable>-best parses.</para>

    <para>Parsers may be used anywhere where there is need for processing
    sequences with a grammar.  In the most common case, the sequence consists
    of a string of words forming a sentence.  However, other cases are possible,
    e.g. the string of characters forming a syllable, the string of morphemes
    forming a word, the string of sentences forming a text.  We could also have
    grammars over subsequences.  For example, the collection of XML elements in
    a document forms a subsequence of the document, and we could specify a grammar
    over those elements alone, ignoring document content.</para>

    <para>The <literal>ParserI</literal> class also defines a
    <ulink url="http://nltk.sourceforge.net/ref/nltk.parser.ParserI.html#parse">
    <literal>parse_types</literal></ulink> method, which takes a list of token types
    (e.g. strings) and returns a list of <literal>Tree</literal>s.  This is
    useful in the case where the sentence to be parsed did not come from a
    tokenized text.  This method works by converting the list of types into
    a list of tokens, then calling <literal>parse</literal> as before.</para>

  </section> <!-- The Parser Interface -->

  <section> <title> Simple Parsers </title>

    <para>Simple top-down and bottom-up parsers can easily be defined
    using classes which inherit from <literal>ParserI</literal>.
    Here is some pseudocode to use as the basis of two simple modules.
    Writing these modules is left as an exercise for the reader.
    More work is required in order to return trees.</para>

<programlisting>
# elementary top-down parser
def tdparse(goal, sent): 
    if goal == sent == empty:
        pass # we're finished
    else:
        if goal[0] == sent[0]:
	    tdparse(goal[1:], sent[1:])
        else:
            for rule in grammar:
                if rule.lhs() == goal[0]:
                    make a local copy of the goal list
                    goal[:1] = rule.rhs()
                    tdparse(goal, sent)

# left-corner parser
def lcparse(goal, sent):
    # this is like tdparse, except the step which iterates over the rules
    # of the grammar only considers rules whose "left corner" matches the next
    # word of the input stream.  The left corner of a lexical rule is the
    # content of the rule.  The left corner of a non-lexical rule R is the left
    # corner of R[0], the first element on the RHS of the rule.

# elementary bottom-up parser
def buparse(sent):
    if sent == [S]:
        pass # we're finished
    else:
        for rule in grammar:
	    does rule.rhs() match any sublist of sent?
            if so, replace the substring with the LHS of the rule
            buparse(sent)
</programlisting>

    <para>The <ulink url="http://nltk.sourceforge.net/ref/nltk.srparser_template.html">
    <literal>srparser_template</literal></ulink> module defines the
    <ulink url="http://nltk.sourceforge.net/ref/nltk.srparser_template.SRParser.html">
    <literal>SRParser</literal></ulink> class, which is a template for a
    shift-reduce parser.</para>

  </section>


  <section> <title> Chart Parsing </title>

    <para>The elementary parsers discussed above suffer from a major
    efficiency problem.  During processing, they typically build and
    discard the same structure many times over.  The standard solution
    to this general kind of problem involves dynamic programming in
    which intermediate results are kept on a blackboard (the chart) for
    later reuse.
    </para>

    <para>In general, a parser hypothesizes constituents based on the
    the grammar and on the current state of its knowledge about the
    constituents which are already attested.  Any given constituent may
    be proposed during the search of a blind alley; there is no way of
    knowing at the time whether the constituent will be used in any of
    the final parses which are reported.  Locally, what we know about a
    constituent is the C{Rule} which licenses its node and immediate
    daughter nodes (i.e. the "local tree").  Also, in the case of chart
    parsing (which is related to bottom-up parsing), we know the whole
    subtree of this node, how it connects to the tokens of the sentence
    being parsed, and its span within the sentence (i.e. location).
    In a chart parser, these these three things: rule, subtree and location,
    are stored in a special structure called an edge.</para>

    <section> <title> Edges </title>

      <para>In order to understand how edges work, it is first necessary to
      recall NLTK's notion of <literal>Location</literal>.  A location in
      a list of tokens is analgous to a Python slice.  The third token has
      the location <literal>@[2:3]</literal>.  It is helpful to think of the numbers as
      referring not to tokens but to imaginary points between the tokens
      (the "interstices").  Each location is then like an edge connecting
      two adjacent points.  This is where the name "edge" comes from.
      </para>

      <para>It is easy to generalize the idea of edges.  The location which
      spans the third and fourth tokens <literal>@[2:4]</literal>, is essentially
      a longer edge which connects non-adjacent points.</para>

      <para>The notion of an edge is best communicated graphically.  The following
      code sample creates some edges for the phrase <literal>the park</literal>,
      displaying them in text on the screen, and also using tkinter.</para>

<programlisting>
from nltk.chartparser import *

tok_sent = [Token('the', 0), Token('park', 1)]
loc = Location(0,2)
chart = Chart(loc)

dr0 = DottedRule('Det', ('the',), 1)
tt0 = TreeToken(dr0.lhs(), tok_sent[0])
edge0 = Edge(dr0, tt0, Location(0))
chart.insert(edge0)
    
dr1 = DottedRule('N', ('park',), 1)
tt1 = TreeToken(dr1.lhs(), tok_sent[1])
edge1 = Edge(dr1, tt1, Location(1))
chart.insert(edge1)
    
dr2 = DottedRule('NP', ('Det','N'), 2)
tt2 = TreeToken(dr2.lhs(), tt0, tt1)
edge2 = Edge(dr2, tt2, Location(0,2))
chart.insert(edge2)
    
chart.draw()

from nltk.draw.chart import *
ChartView(Tkinter.Tk(), chart, tok_sent)
Tkinter.mainloop()
</programlisting>

      <para>The purpose of an edge is to store a <emphasis>hypothesis</emphasis>
      about the syntactic structure of the sentence.  Such hypotheses may be
      either complete or partial.  A complete hypothesis is represented as an
      edge decorated with a <literal>DottedRule</literal> where the dot position is
      on the right edge of the rule.  This means that the entire right-hand side
      has been processed and that the associated <literal>TreeToken</literal> is
      complete.  A partial hypothesis is represented as an edge decorated with
      a rule where the dot position is in an internal position, e.g.
      <literal>NP -&gt; Det * N</literal>.  This means that only part of the
      right-hand side has been processed and that the associated tree is
      incomplete.  The symbol immediately to the right of the
      dot position is the next symbol (terminal or non-terminal) to be processed for
      this edge.</para>

      <para>There is a special case where edges have zero width.  Such an edge is
      actually a self-loop, starting and ending at the same index position.
      Zero-width edges represent the hypothesis that a syntactic constituent
      <emphasis>begins</emphasis> at this location.</para>

      <para>In the process of chart parsing, edges are combined with other edges to
      form new edges which are then added to the chart.  (Note that nothing is ever
      removed from the chart, and nothing is ever modified once it is in the chart.)
      The most important way that edges are combined is known as the
      <emphasis>Fundamental Rule</emphasis>.  Suppose that an edge
      <replaceable>e<subscript>1</subscript></replaceable> has a dotted
      rule whose next symbol is <replaceable>X</replaceable>.  Suppose that
      a second edge <replaceable>e<subscript>2</subscript></replaceable>,
      immediately to the right of
      <replaceable>e<subscript>1</subscript></replaceable>,
      represents a complete <replaceable>X</replaceable> constituent.
      Then the Fundamental Rule states that we must add a new edge
      <replaceable>e<subscript>3</subscript></replaceable> spanning both
      <replaceable>e<subscript>1</subscript></replaceable> and
      <replaceable>e<subscript>2</subscript></replaceable>, in which
      the dot is moved one position to the right.  In other words,
      <replaceable>e<subscript>1</subscript></replaceable> was looking for
      an <replaceable>X</replaceable> to its right, which it found on
      <replaceable>e<subscript>2</subscript></replaceable>, and we record
      this fact on <replaceable>e<subscript>3</subscript></replaceable>.
      </para>

      <para>The <literal>Edge</literal> class has a
      <ulink url="http://nltk.sourceforge.net/ref/nltk.chartparser.Edge.html#FR">
      <literal>FR</literal></ulink> method which applies the fundamental
      rule to a pair of edges.  The operation of the rule is accomplished
      in four lines:</para>

<programlisting>
def FR(self, edge):
    loc = self._loc.union(edge.loc())
    dr = self._drule.shift()
    tree = TreeToken(self._tree.node(), *(self._tree.children() + (edge.tree(),)))
    return Edge(dr, tree, loc)                                                       
</programlisting>

      <para>First we create a new location which is the union of the locations
      of the two existing edges.  Next we create a new dotted rule, just the same
      as the existing one but with the dot position shifted one to the right.
      Next we take the existing tree <literal>self._tree</literal>, break it
      apart, and incorporate the tree from the other edge.  Finally, we construct
      a new edge from the new dotted rule, new tree, and new location.</para>
      
    </section> <!-- Edges -->

    <section> <title> Charts </title>

      <para>A chart is a set of edges and a location...</para>

      <para>For full details see
      <ulink url="http://nltk.sourceforge.net/ref/nltk.chartparser.Chart.html">Chart</ulink>.
      </para>

    </section> <!-- Charts -->

    <section> <title> Parsing Strategies </title>

      <para></para>

    </section> <!-- Parsing Strategies -->

  </section> <!-- Chart Parsing -->

  <section> <title> Chunk Parsing </title>

    <para></para>

  </section> <!-- Chunk Parsing -->
</article>
