.. -*- mode: rst -*-
.. include:: ../definitions.txt

.. preface::

=======
Preface
=======

|nopar|
Most human knowledge |mdash| and most human communication |mdash| is
represented and expressed using language.  Language technologies
permit computers to process human language automatically;  handheld
computers support predictive text and handwriting recognition;  web
search engines give access to information locked up in unstructured
text.  By providing more natural human-machine interfaces, and more
sophisticated access to stored information, language processing has
come to play a central role in the multilingual information society.

This textbook provides a comprehensive, hands-on introduction to the field of
natural language processing (|NLP|), covering the major techniques and
theories.  The book provides numerous worked examples and exercises,
and can either be used for self-study or as the main text for
undergraduate and introductory graduate courses on natural language
processing or computational linguistics.

--------
Audience
--------

This book is intended for people who want to learn how to write programs that
analyze written language.  It is accessible to people who are new to programming,
but structured in such a way that experienced programmers can quickly learn
important |NLP| techniques.

**New to Programming?**  The book is suitable for readers with no prior
knowledge of programming, and the early chapters contain many examples that
you can simply copy and try for yourself, together with graded exercises.
If you decide you need a more general introduction to Python, we recommend
you read *Learning Python* (O'Reilly) in conjunction with this book.

**New to Python?**  Experienced programmers can quickly learn enough
Python using this book to get immersed in natural language processing.
All relevant Python features are carefully explained and exemplified,
and you will quickly come to appreciate Python's suitability for this
application area.

**Already dreaming in Python?**  Simply skip the Python
introduction, and dig into the interesting language analysis
material that starts in the following chapter.  Soon you'll
be applying your skills to this exciting new application area.

-------------------
What You Will Learn
-------------------

By the time you have dug into the material presented here, you will
have acquired substantial skills and knowledge in the following areas:

* how simple programs can help you manipulate and analyze
  language data, and how to write these programs;
* key concepts from linguistic description and analysis;
* how linguistic knowledge is used in important language technology components;
* knowledge of the principal data structures and algorithms used in
  |NLP|, and skills in algorithmic problem solving, data modeling,
  and data management;
* understanding of the standard corpora and their use in formal evaluation;
* the organization of the field of |NLP|;
* skills in Python programming for |NLP|.

Depending on your background, and your motivation for being interested in |NLP|,
you will gain different kinds of skills and knowledge from this book, as set out below:

+------------+--------------------------------+--------------------------------+
|            |                           Background                            |
+ Goals      +--------------------------------+--------------------------------+
|            | Arts and Humanities            | Science and Engineering        |
+------------+--------------------------------+--------------------------------+
| Language   | Programming to manage          | Language as a source           |
| Analysis   | language data, explore         | of interesting problems in     |
|            | linguistic models, and         | data modeling, data mining,   |
|            | test empirical claims          | and knowledge discovery        |
+------------+--------------------------------+--------------------------------+
| Language   | Learning to program, with      | Knowledge of linguistic        |
| Technology | applications to familiar       | algorithms and data structures |
|            | problems, to work in language  | for high quality, maintainable |
|            | technology or other technical  | language processing software   |
|            | field                          |                                |
+------------+--------------------------------+--------------------------------+

-----------------------
Download the Toolkit...
-----------------------

This textbook is a companion to the software library *Natural Language
Toolkit* (|NLTK|).
All software, corpora, and documentation are freely downloadable from
|NLTK-URL|.  Distributions are provided for Windows, Macintosh and Unix platforms.
All |NLTK| distributions plus Python and other useful third-party software
are available in the form of an ISO image which can be downloaded
and burnt to CD-ROM for easy local redistribution.
We strongly encourage you to download |NLTK|
before you go beyond the first chapter of the book.

--------
Emphasis
--------

This book is a **practical** introduction to |NLP|.  You will learn by
example, write real programs, and grasp the value of being able to
test an idea through implementation.  If you haven't learnt already,
this book will teach you **programming**.  Unlike other programming
books, we provide extensive illustrations and exercises from |NLP|.  The
approach we have taken is also **principled**, in that we cover the
theoretical underpinnings and don't shy away from careful linguistic
and computational analysis.  We have tried to be **pragmatic** in
striking a balance between theory and application, and alternate
between the two several times each chapter, identifying the
connections but also the tensions.  Finally, we recognize that you
won't get through this unless it is also **pleasurable**, so we have
tried to include many applications and examples that are interesting
and entertaining, sometimes whimsical.

------------
Organization
------------

The book is structured into three parts, as follows:

*Part 1: Basics* 
    In this part, we focus on recognizing simple
    structure in text.  We start with individual words, then explore
    parts of speech and simple syntactic constituents.

*Part 2: Parsing* 
    Here, we deal with syntactic structure, trees, grammars, and
    parsing.


*Part 3: Advanced Topics* 
    This final part of the book contains chapters which address selected
    topics in |NLP| in more depth and to a more advanced level.
    By design, the chapters in this part can be read independently of
    each other.

|nopar|
The three parts have a common structure: they start off with a
chapter on programming, followed by three chapters on various topics in |NLP|.
The programming chapters are *foundational*, and you must master this
material before progressing further.

Each chapter consists of an introduction, a sequence of sections
that progress from elementary to advanced material,
and finally a summary and suggestions for further reading.
Most sections include exercises which are graded according to
the following scheme:
|easy| is for easy exercises that involve minor modifications
to supplied code samples or other simple activities;
|soso| is for intermediate exercises that explore an aspect
of the material in more depth, requiring careful
analysis and design;
|hard| is for difficult, open-ended tasks that will challenge
your understanding of the material and force you to think independently
(readers new to programming are encouraged to skip these).
The exercises are important for consolidating the
material in each section, and we strongly encourage you to try a few
before continuing with the rest of the chapter.

-----------
Why Python?
-----------

Python is a simple yet powerful programming language with excellent
functionality for processing linguistic data.  Python can be
downloaded for free from ``http://www.python.org/``.

Here is a five-line Python program which takes
text input and prints all the words ending in ``ing``:

.. doctest-ignore::
    >>> import sys                         # load the system library
    >>> for line in sys.stdin:             # for each line of input
    ...     for word in line.split():      # for each word in the line
    ...         if word.endswith('ing'):   # does the word end in 'ing'?
    ...             print word             # if so, print the word

This program illustrates some of the main features of Python.  First,
whitespace is used to *nest* lines of code, thus the line starting
with ``if`` falls inside the scope of the previous line starting with
``for``, so the ``ing`` test is performed for each word.  Second,
Python is *object-oriented*; each variable is an entity which has
certain defined attributes and methods.  For example, ``line`` is more
than a sequence of characters.  It is a string object that has a
`method`:dt: (or operation) called ``split`` that we can use to break a line
into its words.  To apply a method to an object, we give the object
name, followed by a period, followed by the method name.  Third,
methods have *arguments* expressed inside parentheses.  For instance,
``split`` had no argument because we were splitting the string
wherever there was white space.  To split a string into sentences
delimited by a period, we could write ``split('.')``.  Finally, and
most importantly, Python is highly readable, so much so that it is
fairly easy to guess what the above program does even if you have
never written a program before.

We chose Python as the implementation language for |NLTK| because it has
a shallow learning curve, its syntax and semantics are transparent,
and it has good string-handling functionality.  As a scripting
language, Python facilitates interactive exploration.  As an
object-oriented language, Python permits data and methods to be
encapsulated and re-used easily.  As a dynamic language, Python
permits attributes to be added to objects on the fly, and permits
variables to be typed dynamically, facilitating rapid development.
Python comes with an extensive
standard library, including components for graphical programming,
numerical processing, and web data processing.

Python is heavily used in industry, scientific research, and education
around the world.  Python is often praised for the way it facilitates
productivity, quality, and maintainability of software.  A collection of
Python success stories is posted at
``http://www.python.org/about/success/``.

|NLTK| defines a basic infrastructure that can be used to build NLP
programs in Python.  It provides:
basic classes for representing data relevant to natural language processing;
standard interfaces for performing tasks such as tokenization, tagging, and parsing;
standard implementations for each task which can be combined to solve complex problems;
and extensive documentation including tutorials and reference documentation.

------------------------
Learning Python and NLTK
------------------------

This book contains self-paced learning materials including many examples and exercises.
An effective way for students to learn is simply to work through the materials, with the
help of other students and instructors.  The program fragments can be cut and pasted directly
from the online tutorials.  The HTML version has a blue bar beside each program fragment;
click on the bar to automatically copy the program fragment to the clipboard (assumes
appropriate browser security settings.)  Note that the examples in each chapter
use a common set of modules; import them all at once with ``from nltk.book import *``
(and look out for variables that may be defined earlier in the section).

**Integrated Development Environments:**
The easiest way to develop Python code, and to perform interactive Python
demonstrations, is to use the simple
editor and interpreter GUI that comes with Python called *IDLE*, the *Integrated
DeveLopment Environment for Python*.  A more sophisticated approach is to use a
full-blown IDE such as *Eclipse* together with a Python plugin such as *PyDEV*
(see the |NLTK-URL| for instructions).

**NLTK Community:**
|NLTK| has a large and growing user base.  There are mailing lists for
announcements about |NLTK|, for developers and for teachers.
The website lists some 50 courses around the world where |NLTK|
and materials from this book have been adopted,
serving as a useful source of associated materials including
slides and exercises.

------------------
The Design of NLTK
------------------

|NLTK| was designed with six requirements in mind:

:Simplicity: We have tried to provide an intuitive and appealing
   framework along with substantial building blocks, for students to gain
   a practical knowledge of NLP without getting bogged down in the
   tedious house-keeping usually associated with processing annotated
   language data.  We have provided software distributions for
   several platforms, along with platform-specific instructions, to
   make the toolkit easy to install.
:Consistency: We have made a significant effort to ensure that all the
   data structures and interfaces are consistent, making it easy to
   carry out a variety of tasks using a uniform framework.
:Extensibility: The toolkit easily accommodates new components,
   whether those components replicate or extend existing functionality.
   Moreover, the toolkit is organized so that it is usually obvious where
   extensions would fit into the toolkit's infrastructure.
:Modularity: The interaction between different components of the
   toolkit uses simple, well-defined interfaces.  It is possible to
   complete individual projects using small parts of the toolkit,
   without needing to understand how they interact with the rest of
   the toolkit.  This allows students to learn how to use the toolkit
   incrementally throughout a course.  Modularity also makes it easier
   to change and extend the toolkit.
:Well-Documented: The toolkit comes with substantial documentation,
   including nomenclature, data structures, and implementations.
    
Contrasting with these requirements are three non-requirements
|mdash| potentially useful features that we have deliberately avoided.
First, while the toolkit provides a wide range of functions, it is not
intended to be encyclopedic.  There should be a wide variety of ways
in which students can extend the toolkit.  Second, while the toolkit
should be efficient enough that students can use their NLP systems to
perform meaningful tasks, it does not need to be highly optimized for
runtime performance.  Such optimizations often involve more complex
algorithms, and sometimes require the use of C or C++.  This would make the
toolkit less accessible and more difficult to install.  Third, we have
avoided clever programming tricks, since clear implementations are
preferable to ingenious yet indecipherable ones.

-------------------------------
NLTK in the Academic Literature
-------------------------------

|NLTK| has been presented at several international
conferences with published proceedings, from 2002 to the
present, as listed below:

Edward Loper and Steven Bird (2002).
NLTK: The Natural Language Toolkit,
*Proceedings of the ACL Workshop on Effective Tools and
Methodologies for Teaching Natural Language Processing and Computational
Linguistics*,
Somerset, NJ: Association for Computational Linguistics,
pp. 62-69, http://arXiv.org/abs/cs/0205028

Steven Bird and Edward Loper (2004).
NLTK: The Natural Language Toolkit,
*Proceedings of the ACL demonstration session*, pp 214-217.
http://eprints.unimelb.edu.au/archive/00001448/

Edward Loper (2004).
NLTK: Building a Pedagogical Toolkit in Python,
*PyCon DC 2004*
Python Software Foundation,
http://www.python.org/pycon/dc2004/papers/

Steven Bird (2005).
NLTK-Lite: Efficient Scripting for Natural Language Processing,
*4th International Conference on Natural Language Processing*, pp 1-8.
http://eprints.unimelb.edu.au/archive/00001453/

Steven Bird (2006).
NLTK: The Natural Language Toolkit,
*Proceedings of the ACL demonstration session*
http://www.ldc.upenn.edu/sb/home/papers/nltk-demo-06.pdf

Ewan Klein (2006).
Computational Semantics in the Natural Language Toolkit,
*Australian Language Technology Workshop*.
http://www.alta.asn.au/events/altw2006/proceedings/Klein.pdf


---------------
For Instructors
---------------

Natural Language Processing (|NLP|) is often taught within the
confines of a single-semester course at advanced undergraduate level
or postgraduate level.  Many instructors have found that it is
difficult to cover both the theoretical and practical sides of the
subject in such a short span of time.  Some courses focus on theory to
the exclusion of practical exercises, and deprive students of the
challenge and excitement of writing programs to automatically process
language.  Other courses are simply designed to teach programming for
linguists, and do not manage to cover any significant |NLP| content.
The *Natural Language Toolkit* (NLTK) was originally developed to address this problem,
making it feasible to cover a substantial amount of theory and
practice within a single-semester course, even if students have no
prior programming experience.
    
A significant fraction of any |NLP| syllabus covers fundamental
data structures and algorithms.  These are usually taught with the
help of formal notations and complex diagrams.  Large trees and charts
are copied onto the board and edited in tedious slow motion, or
laboriously prepared for presentation slides.  It is more effective
to use live demonstrations in which those diagrams are generated
and updated automatically.  |NLTK| provides interactive graphical user
interfaces, making it possible to view program state and to study
program execution step-by-step.  Most |NLTK| components have a
demonstration mode, and will perform an interesting task without
requiring any special input from the user.  It is even possible to
make minor modifications to programs in response to "what if"
questions.  In this way, students learn the mechanics of |NLP| quickly,
gain deeper insights into the data structures and algorithms, and
acquire new problem-solving skills.
    
This material can be used as the basis for lecture presentations,
and some slides are available for download from |NLTK-URL|.
An effective way to deliver the materials is through interactive
presentation of the examples, entering them at the Python prompt,
observing what they do, and modifying them to explore some empirical
or theoretical question.

|NLTK| supports assignments of varying difficulty and scope.  In the
simplest assignments, students experiment with existing components to
perform a wide variety of |NLP| tasks.  This may involve no programming
at all, in the case of the existing demonstrations, or simply changing
a line or two of program code.  As students become more familiar with
the toolkit they can be asked to modify existing components or to
create complete systems out of existing components.  |NLTK| also
provides students with a flexible framework for advanced projects,
such as developing a multi-component system, by integrating and
extending |NLTK| components, and adding on entirely new components.
Here |NLTK| helps by providing standard implementations of all the basic
data structures and algorithms, interfaces to standard corpora,
substantial corpus samples, and a flexible and extensible
architecture.  Thus, as we have seen, |NLTK| offers a fresh approach to
|NLP| pedagogy, in which theoretical content is tightly integrated with
application.

|nopar|  
We believe this book is unique in providing a comprehensive
framework for students to learn about |NLP| in the context of learning
to program.  What sets these
materials apart is the tight coupling of the chapters
and exercises with |NLTK|, giving students |mdash| even those with
no prior programming experience |mdash| a practical introduction to
|NLP|.  Once completing these materials, students will be ready to
attempt one of the more advanced textbooks, such as *Foundations of
Statistical Natural Language Processing*, by Manning and Sch\ |uumlaut|\ tze
(MIT Press, 2000).

=======================================  =========  ===================
Course Plans; Lectures/Lab Sessions per Chapter
-----------------------------------------------------------------------
Chapter                                  Linguists  Computer Scientists
=======================================  =========  ===================
1 Introduction                           1          1
2 Programming                            4          1
3 Words                                  2          2
4 Tagging                                2-3        2
5 Chunking                               0-2        2
6 Structured Programming                 2-4        1
7 Grammars and Parsing                   2-4        2-4
8 Advanced Parsing                       1-4        3
9 Feature Based Grammar                  2-4        2-4
10-14 Advanced Topics                    2-8        2-16
Total                                    18-36      18-36
=======================================  =========  ===================

|nopar|
**Further Reading:**


The Association for Computational Linguistics (ACL) 
   The ACL is the foremost professional body in |NLP|.
   Its journal and conference proceedings,
   approximately 10,000 articles, are available online with a full-text
   search interface, via `<http://www.aclweb.org/anthology/>`_.

Linguistic Terminology
   A comprehensive glossary of linguistic terminology is available at:
   
   `<http://www.sil.org/linguistics/GlossaryOfLinguisticTerms/>`_.

*Language Files*
   *Materials for an Introduction to Language and
   Linguistics (Ninth Edition)*, The Ohio State University Department of
   Linguistics. For more information, see
   `<http://www.ling.ohio-state.edu/publications/files/>`_.

----------------
Acknowledgments
----------------

|NLTK| was originally created as part of a computational linguistics
course in the Department of Computer and Information Science at the
University of Pennsylvania in 2001.  Since then it has been developed
and expanded with the help of dozens of contributors.  It has now been
adopted in courses in dozens of universities, and serves as the basis
of many research projects.

In particular, we're grateful to the following people for their
feedback, comments on earlier drafts, advice, contributions:
Michaela Atterer,
Greg Aumann,
Kenneth Beesley,
Ondrej Bojar,
Trevor Cohn,
Grev Corbett,
James Curran,
Jean Mark Gawron,
Baden Hughes,
Mark Liberman,
Christopher Maloof,
Stefan M\ |uumlaut|\ ller,
Stuart Robinson,
Jussi Salmela,
Rob Speer.
Many others have contributed to the toolkit, and they are listed
at |NLTK-URL|.

We also acknowledge the following sources:
Carpenter and Chu-Carroll's ACL-99 Tutorial on Spoken Dialogue Systems
(example dialogue in chap-introduction_).

-----------------
About the Authors
-----------------

  +---------------------------------------------------+
  | |AuthorsPic|                                      |
  |                                                   |
  | Edward Loper, Ewan Klein, and Steven Bird,        |
  | Stanford, July 2007                               |
  +---------------------------------------------------+

.. |AuthorsPic|  image:: ../images/authors.png
                    :scale: 85

**Steven Bird** is Associate Professor in the
Department of Computer Science and Software Engineering
at the University of Melbourne, and Senior Research Associate in the
Linguistic Data Consortium at the University of Pennsylvania.
After completing his undergraduate training in computer
science and mathematics at the University of Melbourne,
Steven went to the University of Edinburgh to study computational linguistics,
and completed his PhD in 1990 under the supervision of Ewan Klein.
He later moved to Cameroon to conduct linguistic fieldwork on the
Grassfields Bantu languages.  More recently, he spent
several years as Associate Director of the Linguistic Data Consortium
where he led an R&D team to create models and tools for large
databases of annotated text.  Back at Melbourne University,
he leads a language technology research group and lectures
in algorithms and Python programming.  Steven is editor of
*Cambridge Studies in Natural Language Processing*, and
was recently elected president of the Association for
Computational Linguistics.

**Ewan Klein** is Professor of Language Technology in the School of
Informatics at the University of Edinburgh. He completed a PhD on
formal semantics at the University of Cambridge in 1978. After some
years working at the Universities of Sussex and Newcastle upon Tyne,
Ewan took up a teaching position at Edinburgh. He was involved in the
establishment of Edinburgh's Language Technology Group 1993, and has
been closely associated with it ever since.  From 2000\ |ndash|\ 2002,
he took leave from the University to act as Research Manager for the
Edinburgh-based Natural Language Research Group of Edify Corporation,
Santa Clara, and was responsible for spoken dialogue processing.  Ewan
is a past President of the European Chapter of the Association for
Computational Linguistics and was a founding member and Coordinator of
the European Network of Excellence in Human Language Technologies
(ELSNET). He has been involved in leading numerous academic-industrial
collaborative projects, the most recent of which is a biological text
mining initiative funded by ITI Life Sciences, Scotland, in
collaboration with Cognia Corporation, NY.


**Edward Loper** is a doctoral student in the
Department of Computer and Information Sciences
at the University of Pennsylvania, conducting research
on machine learning in natural language processing.
Edward was a student in Steven's graduate course on
computational linguistics in the fall of 2000, and
went on to be a TA and share in the development of
NLTK.  In addition to |NLTK|, he has
helped develop other major packages for documenting and
testing Python software, ``epydoc`` and ``doctest``.

--------------------------------------------------------------------------


.. include:: footer.txt
