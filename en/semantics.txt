.. -*- mode: rst -*-
.. include:: ../definitions.txt

.. standard global imports

    >>> import nltk, re, pprint

.. _chap-semantics:

=====================
12. Logical Semantics
=====================

.. NB chapter structure isn't consistent with rest of book, re exercise subsections.

------------
Introduction
------------

There are many |NLP| applications where it would be useful to have some
representation of the `meaning`:em: of a natural language
sentence. For instance, as
we pointed out in Chapter chap-introduction_, current search engine technology
can only take us so far in giving concise and correct answers to many
questions that we might be interested in. Admittedly, Google does a
good job in answering google1a_, since its first hit is google1b_.

.. _google1:
.. ex::
      
      .. _google1a:
      .. ex:: What is the population of Saudi Arabia?

      .. _google1b:
      .. ex:: Saudi Arabia - Population: 26,417,599

|nopar|
By contrast, the result of sending google2_ to Google is less helpful:

.. _google2:
.. ex:: Which countries border the Mediterranean?

|nopar|
This time, the topmost hit (and the only relevant one in the top ten)
presents the relevant information as a map of the Mediterranean
basin. Since the map is an image file, it is not easy to
extract the required list of countries from the returned page.

Even if Google succeeds in finding documents which contain information
relevant to our question, there is no guarantee that it will be in a
form which can be easily converted into an appropriate answer. One
reason for this is that the information may have to be inferred from more
than one source. This is likely to be the case when we seek an answer
to more complex questions like google3_:

.. _google3:
.. ex:: Which Asian countries border the Mediterranean?

|nopar|
Here, we would probably need to combine the results of two subqueries,
namely google2_ and `Which countries are in Asia?`:lx:.  

The example queries we have just given are based on a paper dating
back to 1982 [Warren1982EEA]_;
this describes a system, *Chat-80*, which converts natural
language questions into a semantic representation, and uses the latter
to retrieve answers from a knowledge base. A knowledge base is usually
taken to be a set of sentences in some formal language; in the case of
Chat-80, it is a set of Prolog clauses. However, we can encode
knowledge in a variety of formats, including relational databases,
various kinds of graph, and first-order models. In |NLTK|, we have
used the third of these options to re-implement a limited version of
Chat-80::

   Sentence: which Asian countries border the_Mediterranean
   ------------------------------
   \x.((contain(asia, x) & country (x)) & border (x, mediterranean)
   set(['turkey', 'syria', 'israel', 'lebanon'])

|nopar| As we will explain later in this chapter, a semantic
representation of the form ``\x.P(x)`` denotes a set of entities
*u* that meet some condition ``P(x)``. We then ask our
knowledge base to enumerate all the entities in this set.

Let's assume more generally that knowledge is available in some
structured fashion, and that it can be interrogated by a suitable
query language. Then the challenge for |NLP| is to find a method for
converting natural language questions into the target query
language. An alternative paradigm for question answering is to take
something like the pages returned by a Google query as our 'knowledge
base' and then to carry out further analysis and processing of the
textual information contained in the returned pages to see whether it does
in fact provide an answer to the question. In either case, it is very
useful to be able to build a semantic representation of questions.
This |NLP| challenge intersects in interesting ways with one of the
key goals of linguistic theory, namely to provide a systematic
correspondence between form and meaning.

A widely adopted approach to representing meaning |mdash| or at least,
some aspects of meaning |mdash| involves translating expressions of
natural language into |fol| (|FOL|). From a computational point of
view, a strong argument in favor of |FOL| is that it strikes a
reasonable balance between expressiveness and logical tractability. On
the one hand, it is flexible enough to represent many aspects of the
logical structure of natural language. On the other hand, automated
theorem proving for |FOL| has been well studied, and although
inference in |FOL| is not decidable, in practice many reasoning
problems are efficiently solvable using modern theorem provers
(cf. [Blackburn2005RIN]_ for discussion).

While there are numerous subtle and difficult issues about how to
translate natural language constructions into |FOL|, we will largely ignore
these. The main focus of our discussion will be on a
different issue, namely building semantic representations which
conform to some version of the `Principle of Compositionality`:dt:.
(See [Partee1995LSC]_ for this formulation.)

Principle of Compositionality:
   The meaning of a whole is a function of the meanings of the parts
   and of the way they are syntactically combined.

|nopar| There is an assumption here that the semantically relevant
parts of a complex expression will be determined by a theory of
syntax. Within this chapter, we will take it for granted that
expressions are parsed against a context-free grammar. However, this
is not entailed by the Principle of Compositionality.  To summarize,
we will be concerned with the task of systematically constructing a
semantic representation in a manner that can be smoothly integrated
with the process of parsing.

The overall framework we are assuming is illustrated in Figure semint_. Given
a syntactic analysis of a sentence, we can build one or more semantic
representations for the sentence. Once we have a semantic
representation, we can also check whether it is true in a model. 

.. _semint:
.. ex::
   .. image:: ../images/semint.png
      :scale: 30

|nopar| A `model`:dt: for a logical language is a set-theoretic
construction which provides a very simplified picture of how the world
is. For example, in this case, the model should contain individuals
(indicated in the diagram by small dots) corresponding to Suzie and
Fido, and it should also specify that these individuals belong to
the `chase`:math: relation.

The order of sections in this chapter is not what you might expect
from looking at the diagram. We will start off in the middle of semint_ by
presenting a logical language that will provide us with
semantic representations in |NLTK|. Next, we will show how formulas in
the language can be systematically evaluated in a model. At the end,
we will bring everything together and describe a simple method for
constructing semantic representations as part of the parse process in
|NLTK|.

..
   This chapter will only scratch the surface of how to carry out
   semantic analysis of natural language, and will be heavily slanted
   towards the approach currently implemented within
   |NLTK|. Consequently, it needs to be read in conjunction with a good
   overall introduction to formal semantics. [Eg., B&B, Gamut, Heim?]

--------------------
Propositional  Logic
--------------------

The language of propositional logic represents certain aspects of
natural language, but at a high level of abstraction. The only
structure that is made explicit involves `logical connectives`:dt:\;
these correspond to 'logically interesting' expressions such as
`and`:lx: and `not`:lx:. The basic expressions of the language are
`propositional variables`:dt:, usually written `p`:math:, `q`:math:,
`r`:math:, etc. Let `A`:math: be a finite set of such variables. There
is a disjoint set of logical connectives which contains the unary
operator |neg| (`not`:lx:), and binary operators |wedge| (`and`:lx:),
|vee| (`or`:lx:), |rarr| (`implies`:lx:) and |iff| (`iff`:lx:).

The set of formulas of `L`:subscript:`prop` is described inductively:

   1. Every element of `A`:math: is a formula of `L`:subscript:`prop`.

   2. If |phi| is a formula of `L`:subscript:`prop` , then so is |neg| |phi|.

   3. If |phi| and |psi| are formulas, then so are
      (|phi| |wedge| |psi|),
      (|phi| |vee| |psi|),
      (|phi| |rarr| |psi|) and
      (|phi| |iff| |psi|).

   4. Nothing else is a formula of `L`:subscript:`prop`.

|nopar| Within `L`:subscript:`prop`, we can construct formulas such as

.. _prop01:
.. ex:: `p`:math: |rarr| `q`:math: |vee| `r`:math:

There are many sentences of English which could be taken to have the 
logical structure shown in prop01_. Here's an example:

.. _prop02:
.. ex:: If it is raining, then Kim will take an umbrella or Lee will
        get wet. 

In order to explain the relation between prop01_ and prop02_, we need
to give a `key`:em: which maps between propositional variables and
English sentences:

.. _prop03:
.. ex::  `p`:math: stands for  `it is raining`:lx:,
          `q`:math: for `Kim will take an umbrella`:lx: and 
          `q`:math: for `Lee will get wet`:lx:.


The Boolean connectives of propositional logic are supported by the
``sem`` package, and are parsed into various kinds of
``Expression``. We use ``-``, ``&``, ``|``, ``->``, ``<->`` to stand,
respectively, for `not`:lx:, `and`:lx:, `or`:lx:, `implies`:lx: and
`iff`:lx:. In the following example, we start off by creating a new
instance ``lp`` of the NLTK ``LogicParser()``.

   >>> lp = nltk.LogicParser()
   >>> lp.parse('-(p & q)')
   <NegatedExpression -(p & q)>
   >>> lp.parse('p & q')
   <AndExpression (p & q)>
   >>> lp.parse('p | (r -> q)')
   <OrExpression (p | (r -> q))>
   >>> lp.parse('p <-> -- p')
   <IffExpression (p <-> --p)>
   

As the name suggests, propositional logic only studies the logical
structure of formulas made up of atomic propositions. We saw, for
example, that propositional variables stood for whole clauses in
English. In order to look at how predicates combine with arguments, we
need to look at a more complex language for semantic representation,
namely |fol|. In order to show how this new language interacts with
the |lambda|-calculus, it will be useful to introduce the notion of
types into our syntactic definition, in departure from the rather
simple approach to defining the clauses of `L`:subscript:`prop`.

In the general case, we interpret sentences of a logical language
relative to a model, which is a very simplified version of the
world. A model for propositional logic needs to assign the values
``True`` or ``False`` to every possible formula. We do this
inductively: first, every propositional variable is assigned a value,
and then we compute the value of complex formulas by consulting the
meanings of the Boolean connectives and applying them to the values of
the formula's components. Let's create a valuation:

    >>> val1 = nltk.sem.Valuation([('p', True), ('q', True), ('r', False)])
    
We initialize a ``Valuation`` with a list of pairs, each of which
consists of a semantic symbol and a semantic value. The resulting
object is essentially just a dictionary that maps logical expressions
(treated as strings) to appropriate values.

   >>> val1['p']
   True

The keys of the dictionary (sorted alphabetically) can also be
accessed via the property ``symbols``:

    >>> val1.symbols
    ['p', 'q', 'r']

As we will see later, our models need to be somewhat more complicated
in order to handle the more complicated expressions discussed in the
next section, so for the time being, just ignore the ``dom1`` and
``g1`` variables in the following declarations.

    >>> dom1 = set([])
    >>> g = nltk.sem.Assignment(dom1)

Now, let's create a model ``m that uses ``val1``:

    >>> m1 = nltk.sem.Model(dom1, val1, prop=True)

The ``prop=True`` is just a flag to say that our models are intended
for propositional logic.

Every instance of Model defines appropriate truth functions for the
Boolean connectives (and in fact they are implemented as functions
named ``AND()``, ``IMPLIES()`` and so on).
 
    >>> m1.AND
    <bound method Model.AND of (set([]), {'q': True, 'p': True, 'r': False})>

We can use these functions to create truth tables:

    >>> for first in [True, False]:
    ...     for second in [True, False]:
    ...	        print "%s %s => %s" % (first, second, m1.AND(first, second))
    True True => True
    True False => False
    False True => False
    False False => False


-----------------
First-Order Logic
-----------------

Predication
-----------

In |fol| (|FOL|), propositions are analyzed into predicates and
arguments, which takes us a step closer to the structure of natural
languages. The standard construction rules for |FOL| recognize
`terms`:dt: such as individual variables and individual constants, and
`predicates`:dt: which take differing numbers of arguments. For
example, `Adam walks`:lx: might be formalized as `walk(adam)`:mathit:
and `Adam sees Betty`:lx: as `see(adam, betty)`:mathit:. We will call
`walk`:mathit: a `unary predicate`:dt:, and `see`:mathit: a `binary
predicate`:dt:. Semantically, `see`:mathit: is usually modeled as a
relation, i.e., a set of pairs, and the proposition is true in a
situation just in case the ordered pair pair |langle|\ `a, b`:math:\
|rangle| belongs to this set.

There is an alternative
approach in which predication is treated as function application.  In
this functional style of representation, `Adam sees Betty`:lx: can be
formalized as `see(j)(m)`:mathit:. That is than being modeled as a
relation, `see`:mathit: denotes a function which applies to one argument to
yield a new function that is then applied to the second argument. In
NLTK, we will in fact treat predications syntactically as function
applications, but we use a concrete syntax that allows them to
represented as `n`:math:-ary relations.

    >>> parsed = lp.parse('see(a, b)')
    >>> parsed.argument
    <IndividualVariableExpression b>   
    >>> parsed.function
    <ApplicationExpression see(a)>
    >>> parsed.function.function
    <VariableExpression see>

Relations are represented semantically in NLTK in the standard
set-theoretic way: as sets of tuples. For example, let's suppose we
have a domain of discourse consisting of the individuals Adam, Betty and Fido,
where Adam is a boy, Betty is a girl and Fido is a dog. For mnemonic
reasons, we use ``b1``, ``g1`` and ``d1`` as the corresponding labels
in the model. We can declare the domain as follows:

    >>> dom2 = set(['b1', 'g1', 'd1'])

As before, we are going to initialize a valuation with a list of (symbol,
value) pairs:

    >>> v = [('adam','b1'),('betty','g1'),('fido','d1'),
    ... ('boy',set(['b1'])),('girl',set(['g1'])), ('dog',set(['d1'])),
    ... ('walk',set(['g1', 'd1'])),
    ... ('see', set([('b1','g1'),('d1','b1'),('g1','d1'),]))]
    >>> val2 = nltk.sem.Valuation(v)
    >>> print val2
    {'adam': 'b1',
     'betty': 'g1',
     'boy': set([('b1',)]),
     'dog': set([('d1',)]),
     'fido': 'd1',
     'girl': set([('g1',)]),
     'see': set([('b1', 'g1'), ('d1', 'b1'), ('g1', 'd1')]),
     'walk': set([('d1',), ('g1',)])}
    
So according to this valuation, the value of ``see`` is a set of
tuples such that Adam sees Betty, Fido sees Adam, and
Betty sees Fido.

You may have noticed that our unary predicates (i.e, ``boy``, ``girl``,
``dog``) also come out represented as sets of singleton tuples, rather
than just sets of individuals. This is a convenience which allows us
to have a uniform treatment of relations of any arity. In order to
combine a unary relation with an argument, we use the function
``app()``. If the input relation is unary, then ``app()`` returns a
Boolean value; if the input is :mathit:`n`-ary, for `n`:mathit: > 1,
then ``app()`` returns an :mathit:`n`-1-ary relation.

    >>> from nltk.sem import app
    >>> boy = val2['boy']
    >>> app(boy, 'b1')
    True
    >>> app(boy, 'g1')
    False
    >>> see = val2['see']
    >>> app(see, 'g1')
    set([('d1',)])
    >>> app(app(see, 'g1'), 'd1')
    True

Individual Variables and Assignments
------------------------------------

In |FOL|, arguments of predicates can also be individual variables
such as ``x``, ``y`` and ``z``. These can be thought of as similar to
personal pronouns like `he`:lx:, `she`:lx: and `it`:lx:, in that we
need to know about the context of use in order to figure out their
denotation. In our models, the counterpart of a context of use is a
variable `Assignment`:dt:. This is a mapping from individual variables to
entities in the domain. 
Assignments are created using the ``Assignment`` constructor, which
also takes the model's domain of discourse as a parameter. We are not
required to actually enter any bindings, but if we do, they are in a
(variable, value) format similar to what we say earlier for valuations.

   >>> g = nltk.sem.Assignment(dom2, [('x', 'b1'), ('y', 'd1')])
   >>> g
   {'y': 'd1', 'x': 'b1'}

|nopar| In addition, there is a ``print()`` format for assignments which
uses a notation closer to that in logic textbooks:
   
   >>> print g
   g[d1/y][b1/x]

Let's now look at how we can evaluate an atomic formula of
|FOL|. First, we create a model, then we use the ``evaluate()`` method
to compute the truth value.

    >>> m2 = nltk.sem.Model(dom2, val2)
    >>> m2.evaluate('see(betty, y)', g)
    True

What's happening here? Essentially, we are making a call to
``app(app(see, 'g1'), 'd1')`` just as in our earlier example.
However, when the interpretation function encounters the variable ``'y'``,
rather than checking for a value in ``val2``, it asks the variable
assignment ``g`` to come up with a value:

  >>> g['y']
  'd1'

Since we already know that 'b1' and 'g1' stand in the `see`:mathit:
relation, the value ``True`` is what we expected. In this case, we can
say that assignment ``g`` `satisfies`:dt: the formula 'see(adam, y)'.
By contrast, the following formula evaluates to ``False`` relative to
``g`` |mdash| check that you see why this is.

    >>> m2.evaluate('see(x, y)', g)
    False

In our approach (though not in standard |fol|), variable assignments
are `partial`:em:. For example, ``g`` says nothing about any variables
apart from ``'x'`` and ``'y'''. The method ``purge()`` clears all
bindings from an assignment.
    
    >>> g.purge()
    >>> g
    {}

If we now try to evaluate a formula such as 'see(adam, y)' relative to
``g``, it is like trying to interpret a sentence containing a `she`:lx: when
we don't know what `she`:lx: refers to. In this case, the evaluation function
fails to deliver a truth value.
 
    >>> m2.evaluate('see(adam, y)', g)
    'Undefined'

Quantification and Scope
------------------------

|Fol| standardly offers us two quantifiers, `all`:lx: (or `every`:lx:)
and `some`:lx:. These are formally written as |forall| and |exists|,
respectively. At the syntactic level, quantifiers are used to bind
individual variables like ``'x'`` and ``'y'``. The following two sets
of examples show a simple English example, a logical representation,
and the encoding which is accepted by the |NLTK| ``logic`` module.

.. _forall1:
.. ex::

   .. _forall1a:
   .. ex:: Every dog barks.

   .. _forall1b:
   .. ex:: |forall|\ `x.(dog(x)`:mathit: |rarr| `bark(x))`:mathit:

   .. _forall1c:
   .. ex:: ``all x.(dog(x) -> bark(x))``

.. _exists1:
.. ex::

   .. ex:: Some girl walks.

   .. ex:: |exists|\ `x.(girl(x)`:mathit: |wedge| `walk(x))`:mathit:

   .. _existsc:
   .. ex:: ``some x.(girl(x) & walk(x))``

In the existsc_, the quantifier ``some`` binds both occurences of the
variable ``'x'``. As a result, existsc_ is said to be a `closed
formula`:dt:. By contrast, if we look at the body of existsc_,
the variables are unbound:

.. _exists2:
.. ex:: girl(x) & walk(x)

exists2_ is said to be an `open formula`:dt:. As we saw earlier, the
interpretation of open formulas depends on the particular variable
assignment that we are using. 

One of the crucial insights of modern
logic is that the notion of variable satisfaction can be used to
provide an interpretation to quantified formulas. Let's continue to
use existsc_ as an example. When is it true? Let's think about all the
individuals in our domain, i.e., in ``dom2``. We want to check whether
any of these individuals have the property of being a girl and
walking. In other words, we want to know if there is some ``u`` in
``dom2`` such that ``g[u/x]`` satisfies the open formula
exists2_. Consider the following:

    >>> m2.evaluate('some x.(girl(x) & walk(x))', g)
    True

``evaluate()`` returns ``True`` here because there is some ``u`` in
``dom2`` such that exists2_ is satisfied by an assigment which binds
``'x'`` to ``u``. In fact, ``g1`` is such a ``u``:
    
    >>> m2.evaluate('girl(x) & walk(x)', g.add('x', 'g1'))
    True

One useful tool offered by NLTK is the ``satisfiers()`` method. This
lists all the individuals that satisfy an open formula. The method
parameters are a parsed formula, a variable, and an assignment. Here
are a few examples:
    
    >>> fmla1 = lp.parse('girl(x) | boy(x)')
    >>> m2.satisfiers(fmla1, 'x', g)
    set(['b1', 'g1'])
    >>> fmla2 = lp.parse('girl(x) -> walk(x)')
    >>> m2.satisfiers(fmla2, 'x', g)
    set(['b1', 'g1', 'd1'])
    >>> fmla3 = lp.parse('walk(x) -> girl(x)')
    >>> m2.satisfiers(fmla3, 'x', g)
    set(['b1', 'g1'])

It's useful to think about why ``fmla2`` and ``fmla3`` receive the
values they do. In particular, recall the truth conditions for ``->``
(encoded via the function ``IMPLIES()`` in every model):

    >>> for first in [True, False]:
    ...     for second in [True, False]:
    ...	        print "%s %s => %s" % (first, second, m2.IMPLIES(first, second))
    True True => True
    True False => False
    False True => True
    False False => True

This means that 
``fmla2`` is equivalent to this:

.. _fmla2or:
.. ex:: ``- girl(x) | walk(x)``

That is, fmla2or_ is satisfied by something which either isn't a girl
or walks. Since neither ``b1`` (Adam) nor ``d1`` (Fido)
are girls, according to model ``m2``, they both satisfy 
the whole formula. And of course ``g1`` satisfies the formula because ``g1``
satisfies both disjuncts. Now, since every member of the domain of
discourse satisfies ``fmla2``, the corresponding universally
quantified formula is also true.

    >>> m2.evaluate('all x.(girl(x) -> walk(x))', g)
    True

In other words, a universally quantified formula |forall|\
`x.`:mathit:\ |phi| is true with respect to ``g`` just in case for
every ``u``, |phi| is true with respect to ``g[u/x]``. 



.. 
   |nopar| The inclusion of first-order quantifiers motivates the final clause of
   the definition of our version of |fol|.

   7. If `x`:mathit: |element|  **Var**\ (**Ind**) and |phi| 
      |element|  **Term**\ (**Bool**), then |forall|\ `x.`:mathit:\
      |phi|, |exists|\ `x.`:mathit:\ |phi|  |element|  **Term**\
    (**Bool**).  

    One important property of forall1b_ often trips people up. The logical
    rendering in effect says that *if* something is a dog, then it barks,
    but makes no commitment to the existence of dogs. So in a situation
    where nothing is a dog, forall1b_ will still come out true. (Remember
    that ``'(p implies q)'`` is true when ``'p'`` is false.) Now you might
    argue that forall1b_ does presuppose the existence of dogs,
    and that the logic formalization is wrong. 
    But it is possible  to find other
    examples which lack such a presupposition.  For instance, we might
    explain that the value of the Python expression ``re.sub('ate', '8',
    astring)`` is the result of replacing all occurrences of ``'ate'`` in
    ``astring`` by ``'8'``, even though there may in fact be no such occurrences.

What happens when we want to give a formal representation of a
sentence with *two* quantifiers, such as the following?

.. _scope1:
.. ex:: Every girl chases a dog.

There are (at least) two ways of expressing scope1_ in |FOL|:

.. _scope2:
.. ex::

   .. _scope2a:
   .. ex:: |forall|\ `x.((girl x)`:mathit: |rarr| |exists|\
           `y.((dog y)`:mathit: |wedge| `(chase y x)))`:mathit:

   .. _scope2b:
   .. ex:: |exists|\ `y.((dog y)`:mathit: |wedge| |forall|\
           `x.((every x)`:mathit: |rarr|  `(chase y x)))`:mathit:

Can we use both of these? Then answer is Yes, but they have different
meanings. scope2b_ is logically stronger than scope2a_: it claims that
there is a unique dog, say Fido, which is chased by every girl.
scope2a_, on the other hand, just requires that for every girl
`g`:mathit:, we can find some dog which `d`:mathit: chases; but this could
be a different dog in each case. We distinguish between scope2a_ and
scope2b_ in terms of the `scope`:dt: of the quantifiers. In the first,
|forall| has wider scope than |exists|, while in scope2b_, the scope ordering
is reversed. So now we have two ways of representing the meaning of
scope1_, and they are both quite legitimate. In other words, we are
claiming that scope1_ is *ambiguous* with respect to quantifier scope,
and the formulas in scope2_ give us a formal means of making the two
readings explicit. However, we are not just interested in associating
two distinct representations with scope1_. We also want to show in
detail how the two representations lead to different conditions for
truth in a formal model.




---------------
Further Reading
---------------

For more examples of semantic analysis with |NLTK|, please see the
guides at
``http://nltk.org/doc/guides/sem.html`` and
``http://nltk.org/doc/guides/logic.html``.

The use of characteristic functions for interpreting expressions of
natural language was primarily due to Richard
Montague. [Dowty1981IMS]_ gives a comprehensive and reasonably
approachable introduction to Montague's grammatical framework.

A more recent and wide-reaching study of the use of a |lambda| based
approach to natural language can be found in [Carpenter1997TLS]_.

[Heim1998SGG]_ is a thorough application of formal semantics to
transformational grammars in the Government-Binding model.

[Blackburn2005RIN]_ is the first textbook devoted to computational
semantics, and provides an excellent introduction to the area.

.. include:: footer.txt
